{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprising-portuguese",
   "metadata": {
    "id": "yellow-condition"
   },
   "source": [
    "# Implementación de DenseNet para una vista (CC/MLO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-leonard",
   "metadata": {
    "id": "crazy-cause"
   },
   "source": [
    "Ajustamos el notebook según estemos trabajando en local o en un entorno de Google Colab. Además, seleccionamos la vista sobre la que queremos entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordinary-arrival",
   "metadata": {
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1621187399023,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "extreme-orleans"
   },
   "outputs": [],
   "source": [
    "google_colab = 0\n",
    "vista = 'MLO' ## 'CC' o 'MLO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-kazakhstan",
   "metadata": {},
   "source": [
    "Importamos todas las librerías necesarias para la implementación del entrenamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bearing-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    !pip install pickle5\n",
    "    import pickle5 as pickle\n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-emission",
   "metadata": {
    "id": "vulnerable-vault"
   },
   "source": [
    "##  Carga y preparación de los dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-vanilla",
   "metadata": {
    "id": "egyptian-baghdad"
   },
   "source": [
    "Definimos una función auxiliar para ayudar con el preprocesamiento de los datos (ajuste de entrada para la DenseNet en el caso de las imágenes y conversión a one-hot encoding para las etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incident-salvation",
   "metadata": {
    "executionInfo": {
     "elapsed": 5558,
     "status": "ok",
     "timestamp": 1621187403837,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "average-contamination"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, Y):\n",
    "    \"\"\"\n",
    "    Pre-processes the data for the model\n",
    "        - X is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the mammography, where m is the number of data points\n",
    "        - Y is a numpy.ndarray of shape (m,) containing\n",
    "         the Bi-Rads labels for X\n",
    "    Returns:\n",
    "        - X_p is a numpy.ndarray containing the preprocessed X\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_p = K.applications.densenet.preprocess_input(X)\n",
    "\n",
    "    Y_p = K.utils.to_categorical(Y, 3)\n",
    "\n",
    "    return X_p, Y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-mobile",
   "metadata": {
    "id": "auburn-program"
   },
   "source": [
    "Cargamos los ficheros de entrada, eligiendo únicamente la vista seleccionada, tanto en el conjunto de entrenamiento-test como en el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "swiss-attitude",
   "metadata": {
    "executionInfo": {
     "elapsed": 34772,
     "status": "ok",
     "timestamp": 1621187433056,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "boolean-seeking"
   },
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "    with open('/content/gdrive/MyDrive/Colab Notebooks/df_INbreast_train.pkl', 'rb') as pickle_file:\n",
    "        df_INbreast_train = pickle.load(pickle_file)\n",
    "    with open('/content/gdrive/MyDrive/Colab Notebooks/df_INbreast_val.pkl', 'rb') as pickle_file:\n",
    "        df_INbreast_val = pickle.load(pickle_file)\n",
    "else:\n",
    "    df_INbreast_train = pd.read_pickle('./df_INbreast_train.pkl')\n",
    "    df_INbreast_val = pd.read_pickle('./df_INbreast_val.pkl')\n",
    "    \n",
    "if vista == 'CC':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "elif vista == 'MLO':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-comparative",
   "metadata": {
    "id": "israeli-sleeping"
   },
   "source": [
    "Cargamos los datos, convertimos las etiquetas a enteros y liberamos espacio de los ficheros que contenían el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prostate-amazon",
   "metadata": {
    "executionInfo": {
     "elapsed": 36348,
     "status": "ok",
     "timestamp": 1621187434635,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "generous-hammer"
   },
   "outputs": [],
   "source": [
    "dict_valores = {'benigno': 0, 'seguimiento': 1, 'maligno': 2}\n",
    "Y_traintest = np.array(df_INbreast_train['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_traintest = np.array(df_INbreast_train['Image'].tolist())\n",
    "Y_val = np.array(df_INbreast_val['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_val = np.array(df_INbreast_val['Image'].tolist())\n",
    "X_val, Y_val = preprocess_data(X_val, Y_val)\n",
    "del df_INbreast_train\n",
    "del df_INbreast_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-empire",
   "metadata": {
    "id": "obvious-lying"
   },
   "source": [
    "## Definición de la arquitectura de red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-verse",
   "metadata": {
    "id": "decreased-ambassador"
   },
   "source": [
    "Definimos la arquitectura de la red neuronal, así como el inicializador y el optimizador que se usarán durante el proceso de entrenamiento. Definimos la capa de entrada de la red, en la cual las imágenes se reescalarán al tamaño definido por la arquitectura DenseNet (256p x 256p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liked-behalf",
   "metadata": {
    "executionInfo": {
     "elapsed": 36349,
     "status": "ok",
     "timestamp": 1621187434638,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "supposed-publisher"
   },
   "outputs": [],
   "source": [
    "def DenseNet_1Rama(vista, input_dim = 512, rand_seed = 2021, learning_rate = 0.0001, momentum = 0.9):\n",
    "    \"\"\"\n",
    "    Define the DenseNet architecture and compile the model\n",
    "        - vista is a mammogram view we want to train\n",
    "        - input_dim is the size of the mammogram in pixels\n",
    "        - rand_seed is a random seed number used during the fc layer initialization\n",
    "        - learning_rate is the learning rate used during the training\n",
    "        - momentum is the parameters that defines the momentun for the SGD optimizer\n",
    "    Returns:\n",
    "        - model_1rama is the output compiled DenseNet model\n",
    "    \"\"\"\n",
    "    # Define the model architecture\n",
    "    densenet = K.applications.DenseNet121(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_tensor = None,\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = 'avg'\n",
    "    )\n",
    "\n",
    "    densenet.trainable = True\n",
    "\n",
    "    for layer in densenet.layers:\n",
    "        if 'conv5' in layer.name:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    input_img = K.Input(shape = (input_dim, input_dim, 3))\n",
    "    preprocess = K.layers.Lambda(lambda x: tf.image.resize(x, (256, 256)), name = 'resize_' + vista)(input_img)\n",
    "\n",
    "    initializer = K.initializers.he_normal(seed = rand_seed)\n",
    "    \n",
    "    fc_layer = densenet(inputs = preprocess)\n",
    "\n",
    "    fc_layer = K.layers.Dense(units = 3,\n",
    "                              activation = 'softmax',\n",
    "                              kernel_initializer = initializer\n",
    "                              )(fc_layer)\n",
    "\n",
    "    model_1rama = K.models.Model(inputs = input_img, outputs = fc_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    opt = K.optimizers.SGD(learning_rate = learning_rate, momentum = momentum)\n",
    "    \n",
    "    model_1rama.compile(loss = 'categorical_crossentropy',\n",
    "                        optimizer = opt,\n",
    "                        metrics = ['accuracy'])\n",
    "    \n",
    "    return model_1rama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-fence",
   "metadata": {
    "id": "starting-reminder"
   },
   "source": [
    "Mostramos por pantalla la arquitectura de la red definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bearing-military",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41270,
     "status": "ok",
     "timestamp": 1621187439562,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "alone-richards",
    "outputId": "3130aa18-7092-4b30-b935-95713d5fa4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resize_MLO (Lambda)          (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "densenet121 (Functional)     (None, 1024)              7037504   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 7,040,579\n",
      "Trainable params: 2,161,155\n",
      "Non-trainable params: 4,879,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DenseNet_1Rama(vista).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-blade",
   "metadata": {
    "id": "african-george"
   },
   "source": [
    "## Entrenamiento de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-chemical",
   "metadata": {
    "id": "tracked-electricity"
   },
   "source": [
    "Definimos una función auxiliar que particiona el conjunto de entrenamiento/test en los dos subconjuntos correspondientes (entrenamiento y test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "silver-stranger",
   "metadata": {
    "executionInfo": {
     "elapsed": 41268,
     "status": "ok",
     "timestamp": 1621187439563,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "pursuant-ownership"
   },
   "outputs": [],
   "source": [
    "def part_traintest(X_traintest, Y_traintest, rand_seed = 2021, frac_test = .2/.8):\n",
    "    \"\"\"\n",
    "    Function that makes a partition for training and testing from the original dataset\n",
    "        - X_traintest is the array of images from the original dataset\n",
    "        - Y_traintest is the array of labels from the original dataset\n",
    "        - rand_seed is a random seed number used during the sampling\n",
    "        - frac_test is the fraction of cases used in the test subset\n",
    "    Returns:\n",
    "        - X_train is the train array of images\n",
    "        - Y_train is the train array of labels\n",
    "        - X_test is the test array of images\n",
    "        - Y_test is the test array of labels\n",
    "    \"\"\"\n",
    "    np.random.seed(rand_seed)\n",
    "    index_test = np.array([], dtype = 'int64')\n",
    "    for i in np.unique(Y_traintest):\n",
    "        index_test = np.append(index_test, \n",
    "                               np.random.choice(list(np.where(Y_traintest == i)[0]), size = int(np.where(Y_traintest == i)[0].shape[0]*frac_test), replace = False))\n",
    "    X_train = np.delete(X_traintest, index_test, axis = 0)\n",
    "    Y_train = np.delete(Y_traintest, index_test)\n",
    "    X_test = np.take(X_traintest, index_test, axis = 0)\n",
    "    Y_test = np.take(Y_traintest, index_test)\n",
    "    X_train, Y_train = preprocess_data(X_train, Y_train)\n",
    "    X_test, Y_test = preprocess_data(X_test, Y_test)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-links",
   "metadata": {
    "id": "stunning-penetration"
   },
   "source": [
    "Definimos los parámetros básicos para el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "roman-aberdeen",
   "metadata": {
    "executionInfo": {
     "elapsed": 41263,
     "status": "ok",
     "timestamp": 1621187439563,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "altered-offer"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "no_epochs = 300\n",
    "rand_seed = 2021\n",
    "learning_rate = 0.001\n",
    "momentum = 0.8\n",
    "n_folds = 10\n",
    "frac_test = .2/.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-oliver",
   "metadata": {
    "id": "sfqqlwccvlgT"
   },
   "source": [
    "Dado el desbalance que sufren las categorías de la muestra de entrenamiento, forzamos el balanceo calculando las proporciones respecto a la clase más representada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colored-lindsay",
   "metadata": {
    "executionInfo": {
     "elapsed": 41262,
     "status": "ok",
     "timestamp": 1621187439564,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "IkILxnOsvlVY"
   },
   "outputs": [],
   "source": [
    "label, counts = np.unique(Y_traintest, return_counts = True)\n",
    "class_weight = {}\n",
    "for lab, con in zip(label, counts):\n",
    "  class_weight.update({lab: round(max(counts)/con, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-screen",
   "metadata": {
    "id": "Dtox57j2wASC"
   },
   "source": [
    "Definimos un callback para el entrenamiento de la red, de tal manera que nos aseguramos que el entrenamiento disminuye el learning rate cuando la pérdida sobre el conjutno de test ya no disminuye y detenemos el entrenamiento cuando dich pérdida tampoco disminuye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "packed-alarm",
   "metadata": {
    "executionInfo": {
     "elapsed": 41260,
     "status": "ok",
     "timestamp": 1621187439564,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "oth4A1bmv_9K"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(factor = 0.5, patience = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-sellers",
   "metadata": {
    "id": "turkish-albany"
   },
   "source": [
    "Iteramos la definición y el entrenamiento de la red para no sesgar los resultados según el conjunto de entrenamiento y de test escogido en cada caso. Almacenamos el output de cada iteración para poder representarlos más adelante, evaluando cada red obtenida mediante el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "entitled-lesbian",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 728203,
     "status": "ok",
     "timestamp": 1621188126509,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "answering-duncan",
    "outputId": "228619ca-6abf-4bea-e8ee-c6e5a2a2c258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 19s 3s/step - loss: 2.2148 - accuracy: 0.1428 - val_loss: 0.9223 - val_accuracy: 0.5577\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 1.7782 - accuracy: 0.4898 - val_loss: 0.8868 - val_accuracy: 0.5577\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 1.4912 - accuracy: 0.5374 - val_loss: 0.9488 - val_accuracy: 0.5962\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 1.2809 - accuracy: 0.5553 - val_loss: 0.7640 - val_accuracy: 0.6346\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 1.1096 - accuracy: 0.7877 - val_loss: 0.7692 - val_accuracy: 0.5962\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.9051 - accuracy: 0.8310 - val_loss: 0.7657 - val_accuracy: 0.6538\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.8141 - accuracy: 0.8189 - val_loss: 0.7094 - val_accuracy: 0.7692\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.7095 - accuracy: 0.8871 - val_loss: 0.6766 - val_accuracy: 0.7115\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.6049 - accuracy: 0.9181 - val_loss: 0.6565 - val_accuracy: 0.7115\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.5715 - accuracy: 0.8954 - val_loss: 0.6440 - val_accuracy: 0.7500\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.4900 - accuracy: 0.9218 - val_loss: 0.6325 - val_accuracy: 0.7885\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.4795 - accuracy: 0.9520 - val_loss: 0.6494 - val_accuracy: 0.7500\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.4178 - accuracy: 0.9532 - val_loss: 0.6155 - val_accuracy: 0.7500\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.3853 - accuracy: 0.9666 - val_loss: 0.5883 - val_accuracy: 0.7692\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.3646 - accuracy: 0.9725 - val_loss: 0.5812 - val_accuracy: 0.7885\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.3258 - accuracy: 0.9654 - val_loss: 0.5772 - val_accuracy: 0.7885\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.3141 - accuracy: 0.9859 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.2914 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.7692\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.2638 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.7692\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.2320 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.7692\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.5514 - val_accuracy: 0.8077\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.7692\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.1994 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.8077\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.1876 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.7692\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 412ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.7885\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.1733 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.7692\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.7885\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 407ms/step - loss: 0.1409 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.8077\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.8077\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.1263 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.7885\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.7885\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 407ms/step - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.8077\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.7885\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.7692\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 407ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.5216 - val_accuracy: 0.7885\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8077\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8077\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 406ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.7885\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.7885\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.7692\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 1s 407ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.7885\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8077\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.7885\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.7692\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.7692\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.7692\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.7692\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.7692\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.7885\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.7885\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.5277 - val_accuracy: 0.7885\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.7885\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.7885\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.7885\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.62; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 8s 1s/step - loss: 2.1008 - accuracy: 0.1382 - val_loss: 0.9412 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 367ms/step - loss: 1.7515 - accuracy: 0.4810 - val_loss: 0.9320 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 1.4677 - accuracy: 0.5185 - val_loss: 0.8859 - val_accuracy: 0.5962\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 1.2821 - accuracy: 0.6218 - val_loss: 0.7847 - val_accuracy: 0.6731\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 367ms/step - loss: 0.9905 - accuracy: 0.8289 - val_loss: 0.7629 - val_accuracy: 0.6731\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 355ms/step - loss: 0.8532 - accuracy: 0.8584 - val_loss: 0.7643 - val_accuracy: 0.6923\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.7560 - accuracy: 0.8679 - val_loss: 0.7225 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.6902 - accuracy: 0.9076 - val_loss: 0.7019 - val_accuracy: 0.6923\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.5786 - accuracy: 0.9386 - val_loss: 0.6825 - val_accuracy: 0.6731\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.5392 - accuracy: 0.9261 - val_loss: 0.6725 - val_accuracy: 0.6923\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.4897 - accuracy: 0.9234 - val_loss: 0.6571 - val_accuracy: 0.6731\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.4207 - accuracy: 0.9473 - val_loss: 0.6503 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.3987 - accuracy: 0.9646 - val_loss: 0.6450 - val_accuracy: 0.6923\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 0.3723 - accuracy: 0.9698 - val_loss: 0.6466 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.3391 - accuracy: 0.9666 - val_loss: 0.6462 - val_accuracy: 0.7115\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.3129 - accuracy: 0.9737 - val_loss: 0.6341 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.2835 - accuracy: 0.9846 - val_loss: 0.6314 - val_accuracy: 0.6923\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.2642 - accuracy: 0.9776 - val_loss: 0.6274 - val_accuracy: 0.6923\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 0.2360 - accuracy: 0.9820 - val_loss: 0.6236 - val_accuracy: 0.6538\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 0.2630 - accuracy: 0.9820 - val_loss: 0.6271 - val_accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.2168 - accuracy: 0.9910 - val_loss: 0.6333 - val_accuracy: 0.7115\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.1930 - accuracy: 0.9968 - val_loss: 0.6330 - val_accuracy: 0.7115\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.1708 - accuracy: 0.9949 - val_loss: 0.6240 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.1800 - accuracy: 0.9949 - val_loss: 0.6242 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.1531 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.1540 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.7115\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.1555 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.6923\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.6923\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.1295 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.1292 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.6923\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.1284 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.6923\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 0.6923\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.6923\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 405ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.67; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 9s 1s/step - loss: 2.2965 - accuracy: 0.1377 - val_loss: 0.9560 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 1.7742 - accuracy: 0.4444 - val_loss: 0.9367 - val_accuracy: 0.5769\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 371ms/step - loss: 1.4823 - accuracy: 0.4657 - val_loss: 0.9682 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 362ms/step - loss: 1.1924 - accuracy: 0.6436 - val_loss: 0.8479 - val_accuracy: 0.4808\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.9421 - accuracy: 0.8184 - val_loss: 0.8320 - val_accuracy: 0.5577\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.8607 - accuracy: 0.8279 - val_loss: 0.8225 - val_accuracy: 0.6154\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.7117 - accuracy: 0.8569 - val_loss: 0.7814 - val_accuracy: 0.5577\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 0.6667 - accuracy: 0.8774 - val_loss: 0.7633 - val_accuracy: 0.5962\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 0.5690 - accuracy: 0.9018 - val_loss: 0.7535 - val_accuracy: 0.7115\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.5340 - accuracy: 0.8932 - val_loss: 0.7530 - val_accuracy: 0.6538\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.4522 - accuracy: 0.9371 - val_loss: 0.7365 - val_accuracy: 0.6731\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.4210 - accuracy: 0.9405 - val_loss: 0.7322 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.3831 - accuracy: 0.9615 - val_loss: 0.7410 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.3435 - accuracy: 0.9705 - val_loss: 0.7396 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.3252 - accuracy: 0.9705 - val_loss: 0.7331 - val_accuracy: 0.6923\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.3056 - accuracy: 0.9627 - val_loss: 0.7334 - val_accuracy: 0.7308\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.2916 - accuracy: 0.9454 - val_loss: 0.7361 - val_accuracy: 0.7308\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.2605 - accuracy: 0.9698 - val_loss: 0.7449 - val_accuracy: 0.7500\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.2362 - accuracy: 0.9686 - val_loss: 0.7365 - val_accuracy: 0.7308\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.2218 - accuracy: 0.9827 - val_loss: 0.7294 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.2284 - accuracy: 0.9968 - val_loss: 0.7280 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.2171 - accuracy: 0.9827 - val_loss: 0.7275 - val_accuracy: 0.7308\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.2101 - accuracy: 0.9917 - val_loss: 0.7285 - val_accuracy: 0.7308\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.2121 - accuracy: 0.9898 - val_loss: 0.7346 - val_accuracy: 0.7308\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.2097 - accuracy: 0.9910 - val_loss: 0.7396 - val_accuracy: 0.7308\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.2198 - accuracy: 0.9729 - val_loss: 0.7491 - val_accuracy: 0.7308\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.1959 - accuracy: 0.9898 - val_loss: 0.7538 - val_accuracy: 0.7308\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.1779 - accuracy: 0.9949 - val_loss: 0.7414 - val_accuracy: 0.7115\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.1731 - accuracy: 1.0000 - val_loss: 0.7330 - val_accuracy: 0.7308\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.1769 - accuracy: 0.9910 - val_loss: 0.7298 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.1670 - accuracy: 1.0000 - val_loss: 0.7301 - val_accuracy: 0.6923\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 0.7312 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.1548 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.7115\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.1623 - accuracy: 1.0000 - val_loss: 0.7340 - val_accuracy: 0.7115\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.7115\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.1610 - accuracy: 0.9905 - val_loss: 0.7361 - val_accuracy: 0.7115\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.1456 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.6731\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.1473 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.6538\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.1557 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.6538\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.1618 - accuracy: 1.0000 - val_loss: 0.7353 - val_accuracy: 0.6538\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.6346\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.7; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 9s 1s/step - loss: 2.2081 - accuracy: 0.1511 - val_loss: 0.9032 - val_accuracy: 0.5769\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 1.8213 - accuracy: 0.4904 - val_loss: 0.8579 - val_accuracy: 0.5769\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 1.4805 - accuracy: 0.6292 - val_loss: 0.9045 - val_accuracy: 0.5577\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 370ms/step - loss: 1.2099 - accuracy: 0.6670 - val_loss: 0.8253 - val_accuracy: 0.5769\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 1.0366 - accuracy: 0.8176 - val_loss: 0.7294 - val_accuracy: 0.7885\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.9007 - accuracy: 0.8172 - val_loss: 0.7365 - val_accuracy: 0.6731\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.7375 - accuracy: 0.8891 - val_loss: 0.7446 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.6986 - accuracy: 0.9037 - val_loss: 0.7142 - val_accuracy: 0.7692\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 370ms/step - loss: 0.6284 - accuracy: 0.9037 - val_loss: 0.6750 - val_accuracy: 0.7692\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 371ms/step - loss: 0.5478 - accuracy: 0.8959 - val_loss: 0.6476 - val_accuracy: 0.8077\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 370ms/step - loss: 0.5087 - accuracy: 0.9030 - val_loss: 0.6458 - val_accuracy: 0.7500\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.4495 - accuracy: 0.9571 - val_loss: 0.6480 - val_accuracy: 0.7500\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.4121 - accuracy: 0.9544 - val_loss: 0.6158 - val_accuracy: 0.8269\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.3825 - accuracy: 0.9595 - val_loss: 0.6048 - val_accuracy: 0.8269\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.3593 - accuracy: 0.9364 - val_loss: 0.6002 - val_accuracy: 0.8269\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 370ms/step - loss: 0.3257 - accuracy: 0.9446 - val_loss: 0.5989 - val_accuracy: 0.8462\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.2880 - accuracy: 0.9846 - val_loss: 0.5957 - val_accuracy: 0.8462\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.2833 - accuracy: 0.9807 - val_loss: 0.5918 - val_accuracy: 0.8269\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.2574 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.8462\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.2431 - accuracy: 0.9878 - val_loss: 0.5793 - val_accuracy: 0.8462\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8269\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.2198 - accuracy: 0.9968 - val_loss: 0.5800 - val_accuracy: 0.8269\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.1943 - accuracy: 0.9968 - val_loss: 0.5803 - val_accuracy: 0.8269\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.1838 - accuracy: 1.0000 - val_loss: 0.5746 - val_accuracy: 0.8269\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.1625 - accuracy: 1.0000 - val_loss: 0.5716 - val_accuracy: 0.8462\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.1616 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 0.8269\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.1532 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.8269\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.1353 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8269\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.1433 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.8269\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.1247 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8269\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.8269\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.1146 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.8269\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.8269\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.8077\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.8077\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.5656 - val_accuracy: 0.8077\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.8077\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.5641 - val_accuracy: 0.8077\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.8077\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.8077\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.8269\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.8077\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8077\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.8077\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.7885\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.7885\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.7885\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.7885\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.7692\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.7692\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.7692\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.7692\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.7692\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 1s 367ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.7692\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.7692\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.7692\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.7692\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 4: loss of 0.74; accuracy of 69.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 8s 1s/step - loss: 2.1298 - accuracy: 0.1908 - val_loss: 0.9926 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 1.8604 - accuracy: 0.4561 - val_loss: 0.9554 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 1.4118 - accuracy: 0.6401 - val_loss: 0.9567 - val_accuracy: 0.5192\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 366ms/step - loss: 1.2469 - accuracy: 0.5850 - val_loss: 0.8902 - val_accuracy: 0.6154\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.9974 - accuracy: 0.7367 - val_loss: 0.8779 - val_accuracy: 0.4615\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 359ms/step - loss: 0.8854 - accuracy: 0.8360 - val_loss: 0.8571 - val_accuracy: 0.5192\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.7628 - accuracy: 0.8683 - val_loss: 0.7591 - val_accuracy: 0.6538\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 370ms/step - loss: 0.6659 - accuracy: 0.8801 - val_loss: 0.7349 - val_accuracy: 0.7308\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.6352 - accuracy: 0.8739 - val_loss: 0.7501 - val_accuracy: 0.6538\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.5387 - accuracy: 0.9457 - val_loss: 0.7227 - val_accuracy: 0.7115\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 371ms/step - loss: 0.4594 - accuracy: 0.9398 - val_loss: 0.7129 - val_accuracy: 0.6923\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.4806 - accuracy: 0.9473 - val_loss: 0.7085 - val_accuracy: 0.6923\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.3937 - accuracy: 0.9630 - val_loss: 0.7062 - val_accuracy: 0.7115\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 0.3461 - accuracy: 0.9866 - val_loss: 0.7018 - val_accuracy: 0.6923\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.3288 - accuracy: 0.9886 - val_loss: 0.6974 - val_accuracy: 0.7115\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.3126 - accuracy: 0.9795 - val_loss: 0.7204 - val_accuracy: 0.7500\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.3016 - accuracy: 0.9576 - val_loss: 0.6947 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.2594 - accuracy: 0.9910 - val_loss: 0.6942 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.2475 - accuracy: 0.9968 - val_loss: 0.6990 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.2405 - accuracy: 0.9910 - val_loss: 0.6927 - val_accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.2158 - accuracy: 0.9898 - val_loss: 0.7000 - val_accuracy: 0.7115\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.1992 - accuracy: 0.9859 - val_loss: 0.6937 - val_accuracy: 0.7115\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.1946 - accuracy: 0.9949 - val_loss: 0.6920 - val_accuracy: 0.7115\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.1731 - accuracy: 0.9949 - val_loss: 0.6877 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.1657 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.7115\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.1430 - accuracy: 0.9949 - val_loss: 0.6817 - val_accuracy: 0.7115\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.7115\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.1429 - accuracy: 0.9949 - val_loss: 0.6826 - val_accuracy: 0.7115\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.1192 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 406ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.7115\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.7115\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.1070 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.7115\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.7115\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.7115\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.7115\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.7115\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.7115\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.7115\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.7115\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.7115\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.7115\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.7115\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.7115\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.7115\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.7115\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 5: loss of 0.7; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 8s 1s/step - loss: 2.1507 - accuracy: 0.1657 - val_loss: 0.9345 - val_accuracy: 0.5385\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 1.8515 - accuracy: 0.5078 - val_loss: 0.9233 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 1.5495 - accuracy: 0.5855 - val_loss: 0.9055 - val_accuracy: 0.6731\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 366ms/step - loss: 1.1893 - accuracy: 0.6655 - val_loss: 0.8485 - val_accuracy: 0.5769\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 1.0229 - accuracy: 0.8035 - val_loss: 0.8460 - val_accuracy: 0.5385\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 0.8619 - accuracy: 0.8715 - val_loss: 0.8130 - val_accuracy: 0.6346\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.7534 - accuracy: 0.8391 - val_loss: 0.8144 - val_accuracy: 0.6346\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.6855 - accuracy: 0.8954 - val_loss: 0.8206 - val_accuracy: 0.5385\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.5933 - accuracy: 0.9057 - val_loss: 0.7696 - val_accuracy: 0.6154\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.5271 - accuracy: 0.9398 - val_loss: 0.7594 - val_accuracy: 0.6538\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 0.5001 - accuracy: 0.8959 - val_loss: 0.7641 - val_accuracy: 0.6538\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.4407 - accuracy: 0.9446 - val_loss: 0.7554 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 0.4043 - accuracy: 0.9564 - val_loss: 0.7662 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.3570 - accuracy: 0.9486 - val_loss: 0.7622 - val_accuracy: 0.6346\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.3142 - accuracy: 0.9795 - val_loss: 0.7638 - val_accuracy: 0.6154\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.2988 - accuracy: 0.9827 - val_loss: 0.7636 - val_accuracy: 0.6154\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.2803 - accuracy: 0.9776 - val_loss: 0.7619 - val_accuracy: 0.6538\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.2674 - accuracy: 0.9768 - val_loss: 0.7601 - val_accuracy: 0.6538\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.2490 - accuracy: 0.9756 - val_loss: 0.7634 - val_accuracy: 0.6923\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.2286 - accuracy: 0.9615 - val_loss: 0.7670 - val_accuracy: 0.6538\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.2169 - accuracy: 0.9898 - val_loss: 0.7717 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.2054 - accuracy: 0.9910 - val_loss: 0.7764 - val_accuracy: 0.6346\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.1989 - accuracy: 0.9878 - val_loss: 0.7747 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.2225 - accuracy: 0.9788 - val_loss: 0.7765 - val_accuracy: 0.6346\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.1925 - accuracy: 0.9949 - val_loss: 0.7711 - val_accuracy: 0.6538\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.2079 - accuracy: 0.9910 - val_loss: 0.7720 - val_accuracy: 0.6538\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.1842 - accuracy: 0.9949 - val_loss: 0.7743 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.1719 - accuracy: 0.9968 - val_loss: 0.7751 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.1750 - accuracy: 0.9949 - val_loss: 0.7764 - val_accuracy: 0.6538\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.1653 - accuracy: 0.9968 - val_loss: 0.7793 - val_accuracy: 0.6538\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.1761 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.6346\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.1700 - accuracy: 0.9949 - val_loss: 0.7854 - val_accuracy: 0.6346\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 6: loss of 0.66; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 9s 1s/step - loss: 2.2326 - accuracy: 0.1350 - val_loss: 0.8938 - val_accuracy: 0.5385\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 1.7384 - accuracy: 0.5317 - val_loss: 0.8844 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 1.4992 - accuracy: 0.4840 - val_loss: 1.0074 - val_accuracy: 0.5769\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 1.3020 - accuracy: 0.4548 - val_loss: 0.8024 - val_accuracy: 0.5962\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 1.0456 - accuracy: 0.8289 - val_loss: 0.7754 - val_accuracy: 0.6346\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.9055 - accuracy: 0.8494 - val_loss: 0.8428 - val_accuracy: 0.5769\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.7631 - accuracy: 0.8664 - val_loss: 0.7658 - val_accuracy: 0.6346\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.6712 - accuracy: 0.8688 - val_loss: 0.7335 - val_accuracy: 0.6923\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 405ms/step - loss: 0.5913 - accuracy: 0.9088 - val_loss: 0.7373 - val_accuracy: 0.6538\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.5063 - accuracy: 0.9205 - val_loss: 0.7355 - val_accuracy: 0.6154\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.5067 - accuracy: 0.9159 - val_loss: 0.7149 - val_accuracy: 0.6731\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.4397 - accuracy: 0.9391 - val_loss: 0.7076 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.3916 - accuracy: 0.9544 - val_loss: 0.7018 - val_accuracy: 0.7115\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.3670 - accuracy: 0.9693 - val_loss: 0.7000 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 366ms/step - loss: 0.3367 - accuracy: 0.9815 - val_loss: 0.7040 - val_accuracy: 0.6538\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.3247 - accuracy: 0.9756 - val_loss: 0.6966 - val_accuracy: 0.6731\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.2973 - accuracy: 0.9717 - val_loss: 0.7035 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.2487 - accuracy: 0.9866 - val_loss: 0.6988 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.2267 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.6923\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.2117 - accuracy: 0.9949 - val_loss: 0.6930 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 405ms/step - loss: 0.2019 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.7500\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.1818 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.7308\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.1604 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.6923\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.1374 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.1391 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.6731\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.1399 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.7115\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.1213 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.7115\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.7115\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.7115\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.1218 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.7115\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.1261 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.6923\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.6731\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.6731\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.6923\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.6923\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.1004 - accuracy: 1.0000 - val_loss: 0.7093 - val_accuracy: 0.7115\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.7115\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.7115\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 7: loss of 0.69; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 8s 1s/step - loss: 2.2106 - accuracy: 0.1358 - val_loss: 1.0274 - val_accuracy: 0.4038\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 1.6175 - accuracy: 0.4671 - val_loss: 1.0165 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 361ms/step - loss: 1.4342 - accuracy: 0.5180 - val_loss: 0.9219 - val_accuracy: 0.5769\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 1.1704 - accuracy: 0.7418 - val_loss: 0.8329 - val_accuracy: 0.5962\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.9927 - accuracy: 0.8094 - val_loss: 0.8432 - val_accuracy: 0.6154\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.8200 - accuracy: 0.8698 - val_loss: 0.8226 - val_accuracy: 0.6154\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.7240 - accuracy: 0.8766 - val_loss: 0.7757 - val_accuracy: 0.6346\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.6540 - accuracy: 0.8781 - val_loss: 0.7468 - val_accuracy: 0.6346\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.5955 - accuracy: 0.8798 - val_loss: 0.7545 - val_accuracy: 0.6538\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.5523 - accuracy: 0.8964 - val_loss: 0.7342 - val_accuracy: 0.6346\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 371ms/step - loss: 0.4808 - accuracy: 0.9061 - val_loss: 0.7197 - val_accuracy: 0.6346\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.4098 - accuracy: 0.9257 - val_loss: 0.7258 - val_accuracy: 0.6346\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.4011 - accuracy: 0.9622 - val_loss: 0.7545 - val_accuracy: 0.6731\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.3436 - accuracy: 0.9686 - val_loss: 0.7341 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.3446 - accuracy: 0.9654 - val_loss: 0.7132 - val_accuracy: 0.6346\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.2895 - accuracy: 0.9764 - val_loss: 0.7116 - val_accuracy: 0.6346\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.2813 - accuracy: 0.9756 - val_loss: 0.7170 - val_accuracy: 0.6538\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.2764 - accuracy: 0.9768 - val_loss: 0.7104 - val_accuracy: 0.6538\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.2490 - accuracy: 0.9949 - val_loss: 0.7156 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.2099 - accuracy: 0.9968 - val_loss: 0.7152 - val_accuracy: 0.6538\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.2154 - accuracy: 0.9910 - val_loss: 0.7122 - val_accuracy: 0.6731\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.1926 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.6731\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.1882 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.1718 - accuracy: 1.0000 - val_loss: 0.7331 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 408ms/step - loss: 0.1630 - accuracy: 1.0000 - val_loss: 0.7348 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.1584 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 408ms/step - loss: 0.1537 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.6731\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.1403 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.6731\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.1391 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 408ms/step - loss: 0.1357 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.6923\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 405ms/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.6923\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 0.7301 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.1290 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.7115\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 0.7340 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 8: loss of 0.73; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 8s 1s/step - loss: 2.1412 - accuracy: 0.1358 - val_loss: 0.9475 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 368ms/step - loss: 1.8354 - accuracy: 0.5193 - val_loss: 0.8891 - val_accuracy: 0.5577\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 1.5484 - accuracy: 0.5960 - val_loss: 0.8876 - val_accuracy: 0.6154\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 1.2376 - accuracy: 0.6652 - val_loss: 0.7713 - val_accuracy: 0.6923\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 1.0384 - accuracy: 0.7996 - val_loss: 0.7748 - val_accuracy: 0.6154\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.9553 - accuracy: 0.8167 - val_loss: 0.7582 - val_accuracy: 0.6538\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 367ms/step - loss: 0.7465 - accuracy: 0.8762 - val_loss: 0.6869 - val_accuracy: 0.7115\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.6868 - accuracy: 0.8825 - val_loss: 0.6720 - val_accuracy: 0.7692\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.5924 - accuracy: 0.8884 - val_loss: 0.6778 - val_accuracy: 0.7885\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.5536 - accuracy: 0.8959 - val_loss: 0.6516 - val_accuracy: 0.7692\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.4801 - accuracy: 0.9193 - val_loss: 0.6351 - val_accuracy: 0.7885\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.4332 - accuracy: 0.9183 - val_loss: 0.6328 - val_accuracy: 0.7692\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.4244 - accuracy: 0.9395 - val_loss: 0.6314 - val_accuracy: 0.7692\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.3602 - accuracy: 0.9481 - val_loss: 0.6126 - val_accuracy: 0.7885\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.3503 - accuracy: 0.9639 - val_loss: 0.6136 - val_accuracy: 0.7692\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.2994 - accuracy: 0.9846 - val_loss: 0.6071 - val_accuracy: 0.7885\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.2949 - accuracy: 0.9698 - val_loss: 0.6016 - val_accuracy: 0.7692\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.2641 - accuracy: 0.9968 - val_loss: 0.5999 - val_accuracy: 0.7885\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.2513 - accuracy: 0.9949 - val_loss: 0.5964 - val_accuracy: 0.7885\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.2440 - accuracy: 0.9815 - val_loss: 0.5944 - val_accuracy: 0.7692\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.2067 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.1987 - accuracy: 0.9968 - val_loss: 0.5949 - val_accuracy: 0.7692\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.1952 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.1754 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.1568 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.1505 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.7500\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.1453 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.7885\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.1318 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.7692\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.1200 - accuracy: 1.0000 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.7692\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.7692\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.7692\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.7692\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.7500\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.7500\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 1s 393ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.7500\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.7500\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.7500\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.7500\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.7500\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.7500\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.7500\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.7500\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.7500\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.7500\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.7500\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.7500\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.7500\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.7500\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.5794 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 9: loss of 0.67; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10/10 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 8s 1s/step - loss: 2.1346 - accuracy: 0.1613 - val_loss: 0.9699 - val_accuracy: 0.3846\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 358ms/step - loss: 1.8755 - accuracy: 0.5166 - val_loss: 0.9512 - val_accuracy: 0.3846\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 371ms/step - loss: 1.4116 - accuracy: 0.6611 - val_loss: 0.9793 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 1.1378 - accuracy: 0.6594 - val_loss: 0.9391 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 1.0433 - accuracy: 0.7696 - val_loss: 0.8670 - val_accuracy: 0.5385\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.8785 - accuracy: 0.8718 - val_loss: 0.8044 - val_accuracy: 0.5577\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.7506 - accuracy: 0.9025 - val_loss: 0.8249 - val_accuracy: 0.5192\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.6765 - accuracy: 0.8903 - val_loss: 0.8116 - val_accuracy: 0.5962\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.6160 - accuracy: 0.9203 - val_loss: 0.7917 - val_accuracy: 0.5769\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.5317 - accuracy: 0.9269 - val_loss: 0.7343 - val_accuracy: 0.6538\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.4999 - accuracy: 0.9242 - val_loss: 0.7169 - val_accuracy: 0.7500\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.4270 - accuracy: 0.9210 - val_loss: 0.7467 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.4357 - accuracy: 0.9286 - val_loss: 0.7062 - val_accuracy: 0.7500\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.3647 - accuracy: 0.9312 - val_loss: 0.6861 - val_accuracy: 0.7308\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.3222 - accuracy: 0.9803 - val_loss: 0.6906 - val_accuracy: 0.6923\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.3179 - accuracy: 0.9768 - val_loss: 0.6754 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.2921 - accuracy: 0.9744 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 406ms/step - loss: 0.2817 - accuracy: 0.9827 - val_loss: 0.6707 - val_accuracy: 0.7308\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.2649 - accuracy: 0.9737 - val_loss: 0.6569 - val_accuracy: 0.7500\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.2350 - accuracy: 0.9859 - val_loss: 0.6523 - val_accuracy: 0.7500\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.2132 - accuracy: 0.9878 - val_loss: 0.6494 - val_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.2063 - accuracy: 0.9949 - val_loss: 0.6436 - val_accuracy: 0.7692\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.1910 - accuracy: 0.9949 - val_loss: 0.6462 - val_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 1s 409ms/step - loss: 0.1816 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 0.7692\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 412ms/step - loss: 0.1704 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.1682 - accuracy: 0.9910 - val_loss: 0.6330 - val_accuracy: 0.7500\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 409ms/step - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.7692\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.1488 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.7500\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 0.1325 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.7308\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.1249 - accuracy: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.7500\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 406ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.7692\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.7500\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.1124 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.7692\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 413ms/step - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.6262 - val_accuracy: 0.7115\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.7308\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.7692\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.7885\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.7692\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 406ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.7308\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 391ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.7308\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.7692\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.6218 - val_accuracy: 0.7308\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 1s 401ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.7500\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.6731\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 1s 400ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.6731\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 1s 407ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.7692\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.7692\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.7500\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.7500\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 0.7500\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.7500\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.7308\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.7308\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.7500\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.7500\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.7500\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 0.7500\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.6428 - val_accuracy: 0.7308\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 0.7308\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.7308\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 10: loss of 0.69; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.62 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.67 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.7 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.74 - Accuracy: 0.69%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.7 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 0.66 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 0.69 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 0.73 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 0.67 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 0.69 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.72 (+- 0.03)\n",
      "> Loss: 0.69 (+- 0.03)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "history_array = np.array([])\n",
    "scores_array = np.empty([n_folds, 2])\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold + 1}/{n_folds} ...')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    # Generate the fold sample for train-test\n",
    "    X_train, Y_train, X_test, Y_test = part_traintest(X_traintest, Y_traintest, rand_seed + fold, frac_test)\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model_1rama = DenseNet_1Rama(vista, X_train.shape[1], rand_seed, learning_rate, momentum)\n",
    "    \n",
    "    # Fit data to model\n",
    "    history = model_1rama.fit(X_train, Y_train,\n",
    "                              batch_size = batch_size,\n",
    "                              epochs = no_epochs,\n",
    "                              validation_data = (X_test, Y_test),\n",
    "                              class_weight = class_weight,\n",
    "                              verbose = 1,\n",
    "                              callbacks = [early_stopping, reduce_lr])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores_array[fold, :] = model_1rama.evaluate(X_val, Y_val, verbose = 0)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Score for fold {fold + 1}: {model_1rama.metrics_names[0]} of {round(scores_array[fold, 0], 2)}; {model_1rama.metrics_names[1]} of {round(scores_array[fold, 1]*100, 2)}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('')\n",
    "    \n",
    "    # Append history callback into array\n",
    "    history_array = np.append(history_array, [history])\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, scores_array.shape[0]):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i + 1} - Loss: {round(scores_array[i, 0], 2)} - Accuracy: {round(scores_array[i, 1], 2)}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {round(np.mean(scores_array[:, 1]), 2)} (+- {round(np.std(scores_array[:, 1]), 2)})')\n",
    "print(f'> Loss: {round(np.mean(scores_array[:, 0]), 2)} (+- {round(np.std(scores_array[:, 0]), 2)})')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-brain",
   "metadata": {
    "id": "consecutive-aberdeen"
   },
   "source": [
    "## Representación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-trouble",
   "metadata": {
    "id": "played-interface"
   },
   "source": [
    "Definimos una serie de funciones auxiliares para facilitar la visualización de resultados (representación de la evolución de las métricas durante el proceso de entrenamiento y resultados de la matriz de confusión finalmente obtenida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brown-adoption",
   "metadata": {
    "executionInfo": {
     "elapsed": 728928,
     "status": "ok",
     "timestamp": 1621188127239,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "soviet-hospital"
   },
   "outputs": [],
   "source": [
    "def get_metrics(history_array, no_epochs):\n",
    "    \"\"\"\n",
    "    Function that extracts the metrics from the k-fold history from the training process\n",
    "        - history_array is the array of histories generated during the training process\n",
    "        - no_epochs is number of epochs fixed for the training process\n",
    "    Returns:\n",
    "        - accuracy is the output array of accuracies\n",
    "        - val_accuracy is the output array of validation accuracies\n",
    "        - loss is the output array of losses\n",
    "        - val_loss is the output array of validation losses\n",
    "    \"\"\"\n",
    "    accuracy = np.empty([no_epochs, len(history_array)])\n",
    "    accuracy[:, :] = np.nan\n",
    "    val_accuracy = np.empty([no_epochs, len(history_array)])\n",
    "    val_accuracy[:, :] = np.nan\n",
    "    loss = np.empty([no_epochs, len(history_array)])\n",
    "    loss[:, :] = np.nan\n",
    "    val_loss = np.empty([no_epochs, len(history_array)])\n",
    "    val_loss[:, :] = np.nan\n",
    "\n",
    "    for idx, fold in enumerate(history_array):\n",
    "        max_epochs = max(fold.epoch)\n",
    "        accuracy[:max_epochs + 1, idx] = fold.history['accuracy']\n",
    "        val_accuracy[:max_epochs + 1, idx] = fold.history['val_accuracy']\n",
    "        loss[:max_epochs + 1, idx] = fold.history['loss']\n",
    "        val_loss[:max_epochs + 1, idx] = fold.history['val_loss']\n",
    "\n",
    "    return accuracy, val_accuracy, loss, val_loss\n",
    "\n",
    "def plot_metrics(history_array, no_epochs):\n",
    "    \"\"\"\n",
    "    Function that plots the metrics from the training process\n",
    "        - history_array is the array of histories generated during the training process\n",
    "        - no_epochs is number of epochs fixed for the training process\n",
    "    Returns:\n",
    "        - accuracy is the output array of accuracies\n",
    "        - val_accuracy is the output array of validation accuracies\n",
    "        - loss is the output array of losses\n",
    "        - val_loss is the output array of validation losses\n",
    "    \"\"\"\n",
    "    accuracy, val_accuracy, loss, val_loss = get_metrics(history_array, no_epochs)\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.mean(accuracy, axis = 1))\n",
    "    plt.plot(np.mean(val_accuracy, axis = 1))\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(np.mean(loss, axis = 1))\n",
    "    plt.plot(np.mean(val_loss, axis = 1))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes = False, hide_diagonal = False, hide_threshold = None):\n",
    "    \"\"\"\n",
    "    Credit to:\n",
    "    https://gist.github.com/zachguo/10296432\n",
    "    \n",
    "    Function that makes a pretty print for confusion matrixes\n",
    "        - cm is the array of histories generated during the training process\n",
    "        - labels is number of epochs fixed for the training process\n",
    "        - hide_zeroes is a boolean that allows the user to hide the zeroes in the matrix\n",
    "        - hide_diagonal is a boolean that allows the user to hide the diagonal in the matrix\n",
    "        - hide_threshold is a number that allows the user to hide results in the matrix below that value\n",
    "    \"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-novelty",
   "metadata": {
    "executionInfo": {
     "elapsed": 2276,
     "status": "ok",
     "timestamp": 1620075964551,
     "user": {
      "displayName": "Duun V",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GipsnLzW9bWFJbKNrxY-F-xi7XKh0HhowJGi0hF9A=s64",
      "userId": "10921869077997462696"
     },
     "user_tz": -120
    },
    "id": "small-mobility"
   },
   "source": [
    "Visualizamos la evolución de las métricas durante el proceso de entrenamiento de las redes, haciendo la media por época de las distintas iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "under-reserve",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 729409,
     "status": "ok",
     "timestamp": 1621188127721,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "fitting-province",
    "outputId": "e821d1e6-c5f0-484c-fa9e-7878de53ff7a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history_array, no_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-singapore",
   "metadata": {
    "id": "5bXsi3jhTHo_"
   },
   "source": [
    "Buscamos el fold con los mejores resultados sobre el conjunto de validación y lo seleccionamos para representar sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minimal-avenue",
   "metadata": {
    "executionInfo": {
     "elapsed": 729407,
     "status": "ok",
     "timestamp": 1621188127722,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "YV9gGPf5TIDj"
   },
   "outputs": [],
   "source": [
    "idx_best = np.argmax(scores_array[:, 1])\n",
    "model_best = history_array[idx_best].model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-aerospace",
   "metadata": {
    "id": "upper-period"
   },
   "source": [
    "Mostramos la matriz de confusión de la última iteración por pantalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "elect-property",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 731793,
     "status": "ok",
     "timestamp": 1621188130112,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "special-burton",
    "outputId": "af326db9-730c-4468-a4be-80604e071e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            benigno seguimiento  maligno \n",
      "    benigno    28.0         0.0      0.0 \n",
      "seguimiento     3.0         1.0      0.0 \n",
      "    maligno    10.0         0.0     10.0 \n"
     ]
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1))\n",
    "print_cm(conf_matrix, list(dict_valores.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-canadian",
   "metadata": {
    "id": "introductory-calculation"
   },
   "source": [
    "Mostramos las métricas de resultados según categoría para poder evaluar el desempeño de la red en cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "residential-pleasure",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 732146,
     "status": "ok",
     "timestamp": 1621188130467,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "continued-mistake",
    "outputId": "edef591d-338c-44ec-e9a9-3141463d9f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.68      1.00      0.81        28\n",
      " seguimiento       1.00      0.25      0.40         4\n",
      "     maligno       1.00      0.50      0.67        20\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.89      0.58      0.63        52\n",
      "weighted avg       0.83      0.75      0.72        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif_report = metrics.classification_report(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1),\n",
    "                                               target_names = list(dict_valores.keys()))\n",
    "print(classif_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-convergence",
   "metadata": {
    "id": "industrial-basics"
   },
   "source": [
    "Guardamos el modelo entrenado para su uso en el modelo de dos ramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "humanitarian-import",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 783169,
     "status": "ok",
     "timestamp": 1621188181492,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "incorporated-wisconsin",
    "outputId": "7eba5860-c390-49be-ed7c-77cf91062e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Colab Notebooks/model_MLO/assets\n"
     ]
    }
   ],
   "source": [
    "if google_colab:\n",
    "    file_path = '/content/gdrive/MyDrive/Colab Notebooks/' + 'model_' + vista\n",
    "else:\n",
    "    file_path = './model_' + vista\n",
    "K.models.save_model(model_best, file_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Entrenamiento_DenseNet_1Rama.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
