{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bottom-flight",
   "metadata": {
    "id": "modular-forth"
   },
   "source": [
    "# Búsqueda de hiperparámetros para el entrenamiento de DenseNet para una vista (CC/MLO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-classroom",
   "metadata": {
    "id": "younger-sentence"
   },
   "source": [
    "Ajustamos el notebook según estemos trabajando en local o en un entorno de Google Colab. Además, seleccionamos la vista sobre la que queremos optimizar el entrenamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "purple-partition",
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1621164258798,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "flying-consciousness"
   },
   "outputs": [],
   "source": [
    "google_colab = 0\n",
    "vista = 'CC' ## 'CC' ó 'MLO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-sacramento",
   "metadata": {},
   "source": [
    "Importamos todas las librerías necesarias para la implementación de la búsqueda de hiperparámetros de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heavy-cassette",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5748,
     "status": "ok",
     "timestamp": 1621164264052,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "atomic-yukon",
    "outputId": "381db5dd-4276-4e31-b71b-0e6d9fc6e25f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    !pip install pickle5\n",
    "    import pickle5 as pickle\n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-kennedy",
   "metadata": {
    "id": "engaging-persian"
   },
   "source": [
    "##  Carga del dataset y preparación de los dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-mention",
   "metadata": {
    "id": "beautiful-monthly"
   },
   "source": [
    "Definimos una función auxiliar para ayudar con el preprocesamiento de los datos (ajuste de entrada para la DenseNet en el caso de las imágenes y conversión a one-hot encoding para las etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "administrative-kitchen",
   "metadata": {
    "executionInfo": {
     "elapsed": 5742,
     "status": "ok",
     "timestamp": 1621164264057,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "traditional-islam"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, Y):\n",
    "    \"\"\"\n",
    "    Pre-processes the data for the model\n",
    "        - X is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the mammography, where m is the number of data points\n",
    "        - Y is a numpy.ndarray of shape (m,) containing\n",
    "         the Bi-Rads labels for X\n",
    "    Returns:\n",
    "        - X_p is a numpy.ndarray containing the preprocessed X\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_p = K.applications.densenet.preprocess_input(X)\n",
    "\n",
    "    Y_p = K.utils.to_categorical(Y, 3)\n",
    "\n",
    "    return X_p, Y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-radio",
   "metadata": {
    "id": "mobile-monroe"
   },
   "source": [
    "Cargamos los ficheros de entrada, tanto el de entrenamiento-test como el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acoustic-tutorial",
   "metadata": {
    "executionInfo": {
     "elapsed": 8243,
     "status": "ok",
     "timestamp": 1621164266567,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "frequent-homework"
   },
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "    with open('/content/gdrive/MyDrive/Colab Notebooks/df_INbreast_train.pkl', 'rb') as pickle_file:\n",
    "        df_INbreast_train = pickle.load(pickle_file)\n",
    "    with open('/content/gdrive/MyDrive/Colab Notebooks/df_INbreast_val.pkl', 'rb') as pickle_file:\n",
    "        df_INbreast_val = pickle.load(pickle_file)\n",
    "else:\n",
    "    df_INbreast_train = pd.read_pickle('./df_INbreast_train.pkl')\n",
    "    df_INbreast_val = pd.read_pickle('./df_INbreast_val.pkl')\n",
    "\n",
    "if vista == 'CC':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "elif vista == 'MLO':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-narrative",
   "metadata": {
    "id": "contained-franchise"
   },
   "source": [
    "Cargamos los datos, convertimos las etiquetas a enteros y liberamos espacio de los ficheros que contenían el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unknown-navigator",
   "metadata": {
    "executionInfo": {
     "elapsed": 8839,
     "status": "ok",
     "timestamp": 1621164267172,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "fatty-forwarding"
   },
   "outputs": [],
   "source": [
    "dict_valores = {'benigno': 0, 'seguimiento': 1, 'maligno': 2}\n",
    "Y_traintest = np.array(df_INbreast_train['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_traintest = np.array(df_INbreast_train['Image'].tolist())\n",
    "Y_val = np.array(df_INbreast_val['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_val = np.array(df_INbreast_val['Image'].tolist())\n",
    "X_val, Y_val = preprocess_data(X_val, Y_val)\n",
    "del df_INbreast_train\n",
    "del df_INbreast_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-response",
   "metadata": {
    "id": "W4IVXDMAOplr"
   },
   "source": [
    "## Definición de la arquitectura de red neuronal de dos ramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-sword",
   "metadata": {
    "id": "5moG-NYZcICz"
   },
   "source": [
    "Definimos la arquitectura de la red neuronal, así como el inicializador y el optimizador que se usarán durante el proceso de entrenamiento. Definimos la capa de entrada de la red, en la cual las imágenes se reescalarán al tamaño definido por la arquitectura DenseNet (256p x 256p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "little-texture",
   "metadata": {
    "executionInfo": {
     "elapsed": 8844,
     "status": "ok",
     "timestamp": 1621164267184,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "7UvQIbcNPxqL"
   },
   "outputs": [],
   "source": [
    "def DenseNet_1Rama(vista, input_dim = 512, rand_seed = 2021, learning_rate = 0.0001, momentum = 0.9):\n",
    "    \"\"\"\n",
    "    Define the DenseNet architecture and compile the model\n",
    "        - vista is a mammogram view we want to train\n",
    "        - input_dim is the size of the mammogram in pixels\n",
    "        - rand_seed is a random seed number used during the fc layer initialization\n",
    "        - learning_rate is the learning rate used during the training\n",
    "        - momentum is the parameters that defines the momentun for the SGD optimizer\n",
    "    Returns:\n",
    "        - model_1rama is the output compiled DenseNet model\n",
    "    \"\"\"\n",
    "    # Define the model architecture\n",
    "    densenet = K.applications.DenseNet121(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_tensor = None,\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = 'avg'\n",
    "    )\n",
    "\n",
    "    densenet.trainable = True\n",
    "\n",
    "    for layer in densenet.layers:\n",
    "        if 'conv5' in layer.name:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    input_img = K.Input(shape = (input_dim, input_dim, 3))\n",
    "    preprocess = K.layers.Lambda(lambda x: tf.image.resize(x, (256, 256)), name = 'resize_' + vista)(input_img)\n",
    "\n",
    "    initializer = K.initializers.he_normal(seed = rand_seed)\n",
    "    \n",
    "    fc_layer = densenet(inputs = preprocess)\n",
    "\n",
    "    fc_layer = K.layers.Dense(units = 3,\n",
    "                              activation = 'softmax',\n",
    "                              kernel_initializer = initializer\n",
    "                              )(fc_layer)\n",
    "\n",
    "    model_1rama = K.models.Model(inputs = input_img, outputs = fc_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    opt = K.optimizers.SGD(learning_rate = learning_rate, momentum = momentum)\n",
    "    \n",
    "    model_1rama.compile(loss = 'categorical_crossentropy',\n",
    "                        optimizer = opt,\n",
    "                        metrics = ['accuracy'])\n",
    "    \n",
    "    return model_1rama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-network",
   "metadata": {
    "id": "LNizgVEZ5ENX"
   },
   "source": [
    "Mostramos por pantalla la arquitectura de la red definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "perfect-thinking",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13092,
     "status": "ok",
     "timestamp": 1621164271439,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "M_Sbv12gckjn",
    "outputId": "b79b9b9a-6249-4119-924b-8f905265ada6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resize_CC (Lambda)           (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "densenet121 (Functional)     (None, 1024)              7037504   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 7,040,579\n",
      "Trainable params: 2,161,155\n",
      "Non-trainable params: 4,879,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DenseNet_1Rama(vista).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-corner",
   "metadata": {
    "id": "daily-secretariat"
   },
   "source": [
    "## Entrenamiento de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-corruption",
   "metadata": {
    "id": "FuMQgi36S0eV"
   },
   "source": [
    "Definimos una función auxiliar que particiona el conjunto de entrenamiento/test en los dos subconjuntos correspondientes (entrenamiento y test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liked-promotion",
   "metadata": {
    "executionInfo": {
     "elapsed": 13091,
     "status": "ok",
     "timestamp": 1621164271442,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "ZtW8KGwSS0eZ"
   },
   "outputs": [],
   "source": [
    "def part_traintest(X_traintest, Y_traintest, rand_seed = 2021, frac_test = .2/.8):\n",
    "    \"\"\"\n",
    "    Function that makes a partition for training and testing from the original dataset\n",
    "        - X_traintest is the array of images from the original dataset\n",
    "        - Y_traintest is the array of labels from the original dataset\n",
    "        - rand_seed is a random seed number used during the sampling\n",
    "        - frac_test is the fraction of cases used in the test subset\n",
    "    Returns:\n",
    "        - X_train is the train array of images\n",
    "        - Y_train is the train array of labels\n",
    "        - X_test is the test array of images\n",
    "        - Y_test is the test array of labels\n",
    "    \"\"\"\n",
    "    np.random.seed(rand_seed)\n",
    "    index_test = np.array([], dtype = 'int64')\n",
    "    for i in np.unique(Y_traintest):\n",
    "        index_test = np.append(index_test, \n",
    "                               np.random.choice(list(np.where(Y_traintest == i)[0]), size = int(np.where(Y_traintest == i)[0].shape[0]*frac_test), replace = False))\n",
    "    X_train = np.delete(X_traintest, index_test, axis = 0)\n",
    "    Y_train = np.delete(Y_traintest, index_test)\n",
    "    X_test = np.take(X_traintest, index_test, axis = 0)\n",
    "    Y_test = np.take(Y_traintest, index_test)\n",
    "    X_train, Y_train = preprocess_data(X_train, Y_train)\n",
    "    X_test, Y_test = preprocess_data(X_test, Y_test)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-communications",
   "metadata": {
    "id": "korean-press"
   },
   "source": [
    "Definimos los parámetros básicos para el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attractive-worcester",
   "metadata": {
    "executionInfo": {
     "elapsed": 13089,
     "status": "ok",
     "timestamp": 1621164271445,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "incident-sender"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "no_epochs = 300\n",
    "input_dim = X_traintest.shape[1]\n",
    "rand_seed = 2021\n",
    "n_folds = 3\n",
    "frac_test = .2/.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-index",
   "metadata": {
    "id": "0j95AaVx5bCa"
   },
   "source": [
    "Dado el desbalance que sufren las categorías de la muestra de entrenamiento, forzamos el balanceo calculando las proporciones respecto a la clase más representada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "composed-programmer",
   "metadata": {
    "executionInfo": {
     "elapsed": 13087,
     "status": "ok",
     "timestamp": 1621164271448,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "pb5VnDmd5bCe"
   },
   "outputs": [],
   "source": [
    "label, counts = np.unique(Y_traintest, return_counts = True)\n",
    "class_weight = {}\n",
    "for lab, con in zip(label, counts):\n",
    "  class_weight.update({lab: round(max(counts)/con, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-section",
   "metadata": {
    "id": "GKOHQP5Q5e47"
   },
   "source": [
    "Definimos un callback para el entrenamiento de la red, de tal manera que nos aseguramos que el entrenamiento disminuye el learning rate cuando la pérdida sobre el conjutno de test ya no disminuye y detenemos el entrenamiento cuando dich pérdida tampoco disminuye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "printable-remainder",
   "metadata": {
    "executionInfo": {
     "elapsed": 13083,
     "status": "ok",
     "timestamp": 1621164271449,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "s_zS0yCB5gZ0"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(factor = 0.5, patience = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-meaning",
   "metadata": {
    "id": "yVvCVm45MlNh"
   },
   "source": [
    "Iteramos la definición y el entrenamiento de la red para no sesgar los resultados según el conjunto de entrenamiento y de test escogido en cada caso. Almacenamos el output de cada iteración para poder representarlos más adelante, evaluando cada red obtenida mediante el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "future-gathering",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4555958,
     "status": "ok",
     "timestamp": 1621168814331,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "studied-billy",
    "outputId": "9cd00ec1-781c-4472-8e60-950608f23cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.6708 - accuracy: 0.8005 - val_loss: 2.6796 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.9473 - accuracy: 0.7809 - val_loss: 6.3153 - val_accuracy: 0.4423\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.5332 - accuracy: 0.7646 - val_loss: 1.3170 - val_accuracy: 0.6538\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1188 - accuracy: 0.9455 - val_loss: 1.3774 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2337 - accuracy: 0.9933 - val_loss: 1.7600 - val_accuracy: 0.5962\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 1.5245 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.7115\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.7308\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.3225 - val_accuracy: 0.7308\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.4159 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3879 - val_accuracy: 0.7308\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3849 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.3835 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.3829 - val_accuracy: 0.7308\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.3871 - val_accuracy: 0.7308\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3746 - val_accuracy: 0.7308\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.3594 - val_accuracy: 0.7308\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.9; accuracy of 57.69%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.75 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.9 - Accuracy: 0.48%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.9 - Accuracy: 0.58%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.005, mtm = 0.8):\n",
      "> Accuracy: 0.6 (+- 0.1)\n",
      "> Loss: 0.85 (+- 0.07)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 10/25 ...\n",
      "Learning rate = 0.005\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 318ms/step - loss: 3.5158 - accuracy: 0.3144 - val_loss: 1.1059 - val_accuracy: 0.3846\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 2.4292 - accuracy: 0.3438 - val_loss: 1.3500 - val_accuracy: 0.3846\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.3812 - accuracy: 0.5634 - val_loss: 1.6137 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9618 - accuracy: 0.6792 - val_loss: 2.1091 - val_accuracy: 0.3654\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.7482 - accuracy: 0.7743 - val_loss: 4.1169 - val_accuracy: 0.2115\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3860 - accuracy: 0.9206 - val_loss: 3.3984 - val_accuracy: 0.2308\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5935 - accuracy: 0.8521 - val_loss: 1.2327 - val_accuracy: 0.5769\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1965 - accuracy: 0.9421 - val_loss: 2.4346 - val_accuracy: 0.5769\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0949 - accuracy: 0.9988 - val_loss: 1.1644 - val_accuracy: 0.6923\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0659 - accuracy: 0.9778 - val_loss: 1.6742 - val_accuracy: 0.6346\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0407 - accuracy: 0.9957 - val_loss: 2.1892 - val_accuracy: 0.7115\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 3.0197 - val_accuracy: 0.6346\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3834 - val_accuracy: 0.7500\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.7885\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1655 - val_accuracy: 0.8269\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.8269\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1950 - val_accuracy: 0.7885\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.8269\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3461 - val_accuracy: 0.7885\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.0749 - val_accuracy: 0.8077\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.8269\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.8269\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.8269\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.8269\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 0.8269\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.8269\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9222 - val_accuracy: 0.8077\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0051 - val_accuracy: 0.7885\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.9998 - val_accuracy: 0.7885\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0061 - val_accuracy: 0.7115\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 1.1907 - val_accuracy: 0.7500\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.7885\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2133 - val_accuracy: 0.7115\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.7115\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.7308\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.7692\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0511 - val_accuracy: 0.7692\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.7692\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.7692\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.8269\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9386 - val_accuracy: 0.8462\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.8462\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.8462\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.8462\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9343 - val_accuracy: 0.8462\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 7.9477e-04 - accuracy: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.8462\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.8462\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 2.2; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 306ms/step - loss: 2.5637 - accuracy: 0.2694 - val_loss: 0.8975 - val_accuracy: 0.5577\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5715 - accuracy: 0.6065 - val_loss: 1.2051 - val_accuracy: 0.5385\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9126 - accuracy: 0.7274 - val_loss: 0.9487 - val_accuracy: 0.5385\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3808 - accuracy: 0.9091 - val_loss: 1.6031 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1939 - accuracy: 0.9332 - val_loss: 3.4220 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2117 - accuracy: 0.9107 - val_loss: 5.3775 - val_accuracy: 0.4231\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4720 - accuracy: 0.8555 - val_loss: 0.9187 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3129 - accuracy: 0.9117 - val_loss: 3.7636 - val_accuracy: 0.4038\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0708 - accuracy: 0.9752 - val_loss: 1.8096 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0647 - accuracy: 0.9828 - val_loss: 1.8455 - val_accuracy: 0.5192\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0399 - accuracy: 0.9932 - val_loss: 1.6682 - val_accuracy: 0.6154\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6673 - val_accuracy: 0.6154\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.7102 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7229 - val_accuracy: 0.6538\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6885 - val_accuracy: 0.5962\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6028 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.6154\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6002 - val_accuracy: 0.6154\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.5962\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5998 - val_accuracy: 0.6154\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5999 - val_accuracy: 0.5962\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.83; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 10s 315ms/step - loss: 2.6105 - accuracy: 0.3006 - val_loss: 0.9271 - val_accuracy: 0.6346\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7148 - accuracy: 0.4877 - val_loss: 0.8976 - val_accuracy: 0.5769\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5658 - accuracy: 0.6377 - val_loss: 1.0021 - val_accuracy: 0.6346\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.0675 - accuracy: 0.7177 - val_loss: 1.1450 - val_accuracy: 0.6346\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.4175 - accuracy: 0.8450 - val_loss: 5.7441 - val_accuracy: 0.2115\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.4976 - accuracy: 0.8454 - val_loss: 1.3101 - val_accuracy: 0.6346\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7096 - accuracy: 0.8335 - val_loss: 58.4303 - val_accuracy: 0.0769\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.7140 - accuracy: 0.8229 - val_loss: 36.4121 - val_accuracy: 0.1154\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.6878 - accuracy: 0.7545 - val_loss: 2.2318 - val_accuracy: 0.4423\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.1903 - accuracy: 0.9586 - val_loss: 3.7823 - val_accuracy: 0.2692\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0626 - accuracy: 0.9828 - val_loss: 1.4444 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0443 - accuracy: 0.9885 - val_loss: 1.8361 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.0167 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.5776 - val_accuracy: 0.6346\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.4816 - val_accuracy: 0.6538\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4664 - val_accuracy: 0.6923\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.4409 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4095 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3820 - val_accuracy: 0.7308\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.3879 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3474 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3065 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.89; accuracy of 55.77%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 2.2 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.83 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.89 - Accuracy: 0.56%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.005, mtm = 0.9):\n",
      "> Accuracy: 0.6 (+- 0.03)\n",
      "> Loss: 1.31 (+- 0.63)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 11/25 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 8s 299ms/step - loss: 2.0919 - accuracy: 0.2608 - val_loss: 1.0218 - val_accuracy: 0.4038\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.7613 - accuracy: 0.4084 - val_loss: 1.0121 - val_accuracy: 0.3846\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.5526 - accuracy: 0.5194 - val_loss: 0.9949 - val_accuracy: 0.3654\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5633 - accuracy: 0.5397 - val_loss: 0.9488 - val_accuracy: 0.5577\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.2802 - accuracy: 0.6744 - val_loss: 0.9184 - val_accuracy: 0.5385\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.0857 - accuracy: 0.7493 - val_loss: 1.0262 - val_accuracy: 0.4038\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.0791 - accuracy: 0.7210 - val_loss: 0.9445 - val_accuracy: 0.4038\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.9654 - accuracy: 0.7712 - val_loss: 0.9229 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.9705 - accuracy: 0.7664 - val_loss: 0.8809 - val_accuracy: 0.5577\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.8482 - accuracy: 0.8579 - val_loss: 0.9229 - val_accuracy: 0.5192\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.8252 - accuracy: 0.8267 - val_loss: 0.8725 - val_accuracy: 0.5192\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.7208 - accuracy: 0.9058 - val_loss: 0.8018 - val_accuracy: 0.6154\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7094 - accuracy: 0.8776 - val_loss: 0.8296 - val_accuracy: 0.5769\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.6319 - accuracy: 0.8955 - val_loss: 0.7911 - val_accuracy: 0.6154\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.5772 - accuracy: 0.9348 - val_loss: 0.8314 - val_accuracy: 0.5962\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5487 - accuracy: 0.9289 - val_loss: 0.8395 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.5424 - accuracy: 0.9265 - val_loss: 0.7873 - val_accuracy: 0.6346\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5078 - accuracy: 0.9221 - val_loss: 0.7549 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4270 - accuracy: 0.9619 - val_loss: 0.7389 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4087 - accuracy: 0.9464 - val_loss: 0.7725 - val_accuracy: 0.6731\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4230 - accuracy: 0.9374 - val_loss: 0.8366 - val_accuracy: 0.5577\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3721 - accuracy: 0.9507 - val_loss: 0.7430 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3542 - accuracy: 0.9760 - val_loss: 0.7730 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3256 - accuracy: 0.9707 - val_loss: 0.8080 - val_accuracy: 0.5769\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3191 - accuracy: 0.9682 - val_loss: 0.7425 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.2754 - accuracy: 0.9895 - val_loss: 0.7255 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3074 - accuracy: 0.9946 - val_loss: 0.7241 - val_accuracy: 0.6923\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2750 - accuracy: 0.9803 - val_loss: 0.7291 - val_accuracy: 0.6731\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2815 - accuracy: 0.9794 - val_loss: 0.7119 - val_accuracy: 0.6923\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3024 - accuracy: 0.9567 - val_loss: 0.7107 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2867 - accuracy: 0.9718 - val_loss: 0.7142 - val_accuracy: 0.7115\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.2814 - accuracy: 0.9774 - val_loss: 0.7203 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.2315 - accuracy: 0.9870 - val_loss: 0.7083 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2297 - accuracy: 0.9780 - val_loss: 0.7072 - val_accuracy: 0.6923\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2571 - accuracy: 0.9837 - val_loss: 0.7071 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2435 - accuracy: 0.9877 - val_loss: 0.6999 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2803 - accuracy: 0.9913 - val_loss: 0.6995 - val_accuracy: 0.6923\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.2030 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.7115\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1972 - accuracy: 0.9895 - val_loss: 0.7046 - val_accuracy: 0.6923\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2007 - accuracy: 0.9788 - val_loss: 0.7063 - val_accuracy: 0.7115\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.2026 - accuracy: 0.9932 - val_loss: 0.7188 - val_accuracy: 0.6923\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.1789 - accuracy: 0.9967 - val_loss: 0.7213 - val_accuracy: 0.6731\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.1877 - accuracy: 0.9885 - val_loss: 0.7109 - val_accuracy: 0.7115\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1829 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.7115\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1959 - accuracy: 0.9946 - val_loss: 0.7031 - val_accuracy: 0.6923\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1964 - accuracy: 0.9917 - val_loss: 0.6999 - val_accuracy: 0.6731\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1580 - accuracy: 0.9982 - val_loss: 0.7028 - val_accuracy: 0.7115\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1762 - accuracy: 0.9913 - val_loss: 0.7034 - val_accuracy: 0.7115\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1811 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.7115\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2073 - accuracy: 0.9828 - val_loss: 0.7030 - val_accuracy: 0.7115\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1778 - accuracy: 0.9957 - val_loss: 0.7018 - val_accuracy: 0.7115\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1585 - accuracy: 0.9982 - val_loss: 0.7015 - val_accuracy: 0.7115\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.7115\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1719 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.7115\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1589 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.7115\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1704 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.7115\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1634 - accuracy: 0.9932 - val_loss: 0.7016 - val_accuracy: 0.7115\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 8s 302ms/step - loss: 2.1425 - accuracy: 0.1844 - val_loss: 1.0237 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6316 - accuracy: 0.4579 - val_loss: 1.0132 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.4590 - accuracy: 0.6088 - val_loss: 1.0842 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.3838 - accuracy: 0.4953 - val_loss: 0.9448 - val_accuracy: 0.4615\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.4129 - accuracy: 0.6464 - val_loss: 0.9478 - val_accuracy: 0.5000\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.1521 - accuracy: 0.7725 - val_loss: 0.9704 - val_accuracy: 0.4231\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.0293 - accuracy: 0.8340 - val_loss: 0.9478 - val_accuracy: 0.4808\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.0985 - accuracy: 0.7950 - val_loss: 0.9715 - val_accuracy: 0.4423\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.8646 - accuracy: 0.8544 - val_loss: 0.9523 - val_accuracy: 0.4615\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.7810 - accuracy: 0.8958 - val_loss: 0.9170 - val_accuracy: 0.4808\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.7339 - accuracy: 0.9389 - val_loss: 0.9003 - val_accuracy: 0.4423\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7318 - accuracy: 0.8909 - val_loss: 0.9022 - val_accuracy: 0.4423\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6375 - accuracy: 0.9143 - val_loss: 0.9096 - val_accuracy: 0.5000\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6805 - accuracy: 0.8841 - val_loss: 0.9042 - val_accuracy: 0.4615\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6303 - accuracy: 0.9002 - val_loss: 0.9020 - val_accuracy: 0.4615\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6074 - accuracy: 0.9266 - val_loss: 0.8913 - val_accuracy: 0.4615\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.5824 - accuracy: 0.9311 - val_loss: 0.8831 - val_accuracy: 0.5192\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6032 - accuracy: 0.9056 - val_loss: 0.9087 - val_accuracy: 0.4615\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5400 - accuracy: 0.9379 - val_loss: 0.9425 - val_accuracy: 0.4808\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.5457 - accuracy: 0.9448 - val_loss: 0.8892 - val_accuracy: 0.5192\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5205 - accuracy: 0.9456 - val_loss: 0.8938 - val_accuracy: 0.5192\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4797 - accuracy: 0.9596 - val_loss: 0.9028 - val_accuracy: 0.5385\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4602 - accuracy: 0.9617 - val_loss: 0.8856 - val_accuracy: 0.5192\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4667 - accuracy: 0.9314 - val_loss: 0.8874 - val_accuracy: 0.5192\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4659 - accuracy: 0.9438 - val_loss: 0.8890 - val_accuracy: 0.5192\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4431 - accuracy: 0.9588 - val_loss: 0.8879 - val_accuracy: 0.5385\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4569 - accuracy: 0.9568 - val_loss: 0.8834 - val_accuracy: 0.5385\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.4331 - accuracy: 0.9705 - val_loss: 0.8832 - val_accuracy: 0.5385\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4118 - accuracy: 0.9691 - val_loss: 0.8831 - val_accuracy: 0.5385\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4653 - accuracy: 0.9420 - val_loss: 0.8857 - val_accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4236 - accuracy: 0.9680 - val_loss: 0.8851 - val_accuracy: 0.5385\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.4184 - accuracy: 0.9489 - val_loss: 0.8837 - val_accuracy: 0.5385\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4101 - accuracy: 0.9535 - val_loss: 0.8839 - val_accuracy: 0.5385\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3779 - accuracy: 0.9723 - val_loss: 0.8844 - val_accuracy: 0.5385\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3930 - accuracy: 0.9601 - val_loss: 0.8845 - val_accuracy: 0.5385\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3822 - accuracy: 0.9687 - val_loss: 0.8840 - val_accuracy: 0.5385\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3911 - accuracy: 0.9586 - val_loss: 0.8838 - val_accuracy: 0.5385\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3935 - accuracy: 0.9605 - val_loss: 0.8844 - val_accuracy: 0.5385\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4133 - accuracy: 0.9672 - val_loss: 0.8844 - val_accuracy: 0.5385\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4247 - accuracy: 0.9438 - val_loss: 0.8850 - val_accuracy: 0.5385\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3949 - accuracy: 0.9601 - val_loss: 0.8852 - val_accuracy: 0.5385\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3793 - accuracy: 0.9801 - val_loss: 0.8851 - val_accuracy: 0.5385\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3589 - accuracy: 0.9866 - val_loss: 0.8854 - val_accuracy: 0.5385\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3864 - accuracy: 0.9622 - val_loss: 0.8855 - val_accuracy: 0.5385\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3923 - accuracy: 0.9729 - val_loss: 0.8857 - val_accuracy: 0.5385\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4045 - accuracy: 0.9713 - val_loss: 0.8857 - val_accuracy: 0.5385\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3735 - accuracy: 0.9799 - val_loss: 0.8856 - val_accuracy: 0.5385\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4389 - accuracy: 0.9414 - val_loss: 0.8859 - val_accuracy: 0.5385\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3981 - accuracy: 0.9615 - val_loss: 0.8861 - val_accuracy: 0.5385\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.81; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 10s 325ms/step - loss: 2.0485 - accuracy: 0.2508 - val_loss: 1.0077 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7879 - accuracy: 0.3831 - val_loss: 1.0288 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.5333 - accuracy: 0.5470 - val_loss: 0.9974 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.3717 - accuracy: 0.5485 - val_loss: 0.9890 - val_accuracy: 0.4615\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.4568 - accuracy: 0.6091 - val_loss: 0.9527 - val_accuracy: 0.4808\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1781 - accuracy: 0.7557 - val_loss: 1.0007 - val_accuracy: 0.4423\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1825 - accuracy: 0.6795 - val_loss: 0.9497 - val_accuracy: 0.5385\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9877 - accuracy: 0.7494 - val_loss: 0.9376 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.9459 - accuracy: 0.8132 - val_loss: 0.9140 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.8350 - accuracy: 0.8885 - val_loss: 0.9164 - val_accuracy: 0.5962\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.7403 - accuracy: 0.8737 - val_loss: 0.8888 - val_accuracy: 0.5577\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7190 - accuracy: 0.8608 - val_loss: 0.8865 - val_accuracy: 0.5962\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.6551 - accuracy: 0.9327 - val_loss: 0.8570 - val_accuracy: 0.5962\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5991 - accuracy: 0.9459 - val_loss: 0.8587 - val_accuracy: 0.5385\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6002 - accuracy: 0.9031 - val_loss: 0.8383 - val_accuracy: 0.6154\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5131 - accuracy: 0.9214 - val_loss: 0.8551 - val_accuracy: 0.5769\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4794 - accuracy: 0.9710 - val_loss: 0.8417 - val_accuracy: 0.5962\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3952 - accuracy: 0.9802 - val_loss: 0.8406 - val_accuracy: 0.5962\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.4193 - accuracy: 0.9746 - val_loss: 0.8285 - val_accuracy: 0.5962\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3555 - accuracy: 0.9959 - val_loss: 0.8219 - val_accuracy: 0.6154\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3249 - accuracy: 0.9895 - val_loss: 0.8516 - val_accuracy: 0.6346\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.3758 - accuracy: 0.9647 - val_loss: 0.8187 - val_accuracy: 0.6154\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3308 - accuracy: 0.9821 - val_loss: 0.8133 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3173 - accuracy: 0.9870 - val_loss: 0.8092 - val_accuracy: 0.6346\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2855 - accuracy: 0.9864 - val_loss: 0.8233 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2779 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.6538\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2618 - accuracy: 0.9967 - val_loss: 0.8094 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.6731\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2554 - accuracy: 0.9760 - val_loss: 0.8331 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2198 - accuracy: 0.9896 - val_loss: 0.8228 - val_accuracy: 0.6731\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2021 - accuracy: 0.9975 - val_loss: 0.8195 - val_accuracy: 0.6731\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1809 - accuracy: 0.9880 - val_loss: 0.8132 - val_accuracy: 0.6346\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1920 - accuracy: 0.9982 - val_loss: 0.8135 - val_accuracy: 0.6154\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1865 - accuracy: 0.9828 - val_loss: 0.8142 - val_accuracy: 0.6346\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2171 - accuracy: 0.9816 - val_loss: 0.8126 - val_accuracy: 0.6346\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1645 - accuracy: 0.9967 - val_loss: 0.8124 - val_accuracy: 0.6346\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1632 - accuracy: 0.9982 - val_loss: 0.8129 - val_accuracy: 0.6346\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1599 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.6154\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1628 - accuracy: 1.0000 - val_loss: 0.8147 - val_accuracy: 0.6154\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.1720 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.6346\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1716 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.6346\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1732 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.6346\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1972 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.6346\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.81; accuracy of 59.62%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.81 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.81 - Accuracy: 0.6%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0):\n",
      "> Accuracy: 0.62 (+- 0.02)\n",
      "> Loss: 0.8 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 12/25 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.2\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 308ms/step - loss: 1.9701 - accuracy: 0.3045 - val_loss: 1.0632 - val_accuracy: 0.4038\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6367 - accuracy: 0.4435 - val_loss: 1.0747 - val_accuracy: 0.3846\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.3695 - accuracy: 0.5195 - val_loss: 1.0428 - val_accuracy: 0.4231\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.3620 - accuracy: 0.4811 - val_loss: 0.9275 - val_accuracy: 0.5385\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.1293 - accuracy: 0.7392 - val_loss: 0.9922 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.1339 - accuracy: 0.6475 - val_loss: 0.8781 - val_accuracy: 0.5385\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.0608 - accuracy: 0.8151 - val_loss: 0.9326 - val_accuracy: 0.4231\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.7999 - accuracy: 0.8687 - val_loss: 0.8686 - val_accuracy: 0.6346\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.8195 - accuracy: 0.8801 - val_loss: 0.8473 - val_accuracy: 0.5577\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7512 - accuracy: 0.8950 - val_loss: 0.8134 - val_accuracy: 0.5962\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.7087 - accuracy: 0.9122 - val_loss: 0.8040 - val_accuracy: 0.5962\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.5988 - accuracy: 0.9389 - val_loss: 0.8141 - val_accuracy: 0.5769\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5669 - accuracy: 0.9122 - val_loss: 0.7802 - val_accuracy: 0.6923\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5422 - accuracy: 0.9144 - val_loss: 0.7705 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4944 - accuracy: 0.9111 - val_loss: 0.8154 - val_accuracy: 0.5962\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4277 - accuracy: 0.9563 - val_loss: 0.7457 - val_accuracy: 0.6538\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4080 - accuracy: 0.9441 - val_loss: 0.7675 - val_accuracy: 0.6346\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4014 - accuracy: 0.9744 - val_loss: 0.8441 - val_accuracy: 0.5769\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3345 - accuracy: 0.9932 - val_loss: 0.7285 - val_accuracy: 0.6923\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2938 - accuracy: 0.9727 - val_loss: 0.7434 - val_accuracy: 0.6923\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3226 - accuracy: 0.9585 - val_loss: 0.7287 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2954 - accuracy: 0.9819 - val_loss: 0.7283 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2735 - accuracy: 0.9795 - val_loss: 0.7789 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.2337 - accuracy: 0.9798 - val_loss: 0.7185 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2385 - accuracy: 0.9760 - val_loss: 0.7149 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1945 - accuracy: 0.9915 - val_loss: 0.7106 - val_accuracy: 0.7308\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2190 - accuracy: 0.9885 - val_loss: 0.7222 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1793 - accuracy: 0.9895 - val_loss: 0.7022 - val_accuracy: 0.7308\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2237 - accuracy: 0.9712 - val_loss: 0.7505 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1823 - accuracy: 0.9885 - val_loss: 0.7184 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1558 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.7115\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.1771 - accuracy: 0.9946 - val_loss: 0.7019 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1364 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.6731\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1317 - accuracy: 1.0000 - val_loss: 0.7454 - val_accuracy: 0.6538\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1335 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.6731\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.7115\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.6538\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.7308\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.7308\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.7115\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0931 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.7115\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.7115\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.7308\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.6923\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.7322 - val_accuracy: 0.6923\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.6923\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 0.6731\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.6731\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.6731\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.6923\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.7342 - val_accuracy: 0.6923\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 310ms/step - loss: 2.0162 - accuracy: 0.2436 - val_loss: 1.0367 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6251 - accuracy: 0.4482 - val_loss: 0.9944 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.5124 - accuracy: 0.6186 - val_loss: 0.9336 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.2496 - accuracy: 0.7218 - val_loss: 0.9680 - val_accuracy: 0.4231\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.2893 - accuracy: 0.6390 - val_loss: 0.9378 - val_accuracy: 0.4423\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.0068 - accuracy: 0.7573 - val_loss: 0.9280 - val_accuracy: 0.4808\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9389 - accuracy: 0.8901 - val_loss: 0.9532 - val_accuracy: 0.4615\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8334 - accuracy: 0.8793 - val_loss: 0.9247 - val_accuracy: 0.4615\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7200 - accuracy: 0.8921 - val_loss: 0.9594 - val_accuracy: 0.4808\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6750 - accuracy: 0.9035 - val_loss: 0.8653 - val_accuracy: 0.5192\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6529 - accuracy: 0.8669 - val_loss: 0.8797 - val_accuracy: 0.4808\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5365 - accuracy: 0.9297 - val_loss: 0.9297 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4678 - accuracy: 0.9711 - val_loss: 0.9311 - val_accuracy: 0.5192\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4400 - accuracy: 0.9451 - val_loss: 0.8350 - val_accuracy: 0.5192\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.4190 - accuracy: 0.9592 - val_loss: 0.8414 - val_accuracy: 0.5385\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3975 - accuracy: 0.9435 - val_loss: 0.8899 - val_accuracy: 0.5385\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3624 - accuracy: 0.9743 - val_loss: 0.8611 - val_accuracy: 0.5577\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3210 - accuracy: 0.9887 - val_loss: 0.8591 - val_accuracy: 0.5577\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3092 - accuracy: 0.9667 - val_loss: 0.8420 - val_accuracy: 0.5769\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3026 - accuracy: 0.9942 - val_loss: 0.8524 - val_accuracy: 0.5769\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2612 - accuracy: 0.9915 - val_loss: 0.8512 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2548 - accuracy: 0.9863 - val_loss: 0.8528 - val_accuracy: 0.5577\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2501 - accuracy: 0.9860 - val_loss: 0.8594 - val_accuracy: 0.5769\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2620 - accuracy: 0.9799 - val_loss: 0.8562 - val_accuracy: 0.5577\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2044 - accuracy: 0.9982 - val_loss: 0.8569 - val_accuracy: 0.5577\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2544 - accuracy: 0.9913 - val_loss: 0.8616 - val_accuracy: 0.5577\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2113 - accuracy: 0.9861 - val_loss: 0.8676 - val_accuracy: 0.5577\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2201 - accuracy: 0.9882 - val_loss: 0.8658 - val_accuracy: 0.5577\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2287 - accuracy: 0.9895 - val_loss: 0.8665 - val_accuracy: 0.5385\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2088 - accuracy: 0.9950 - val_loss: 0.8685 - val_accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2008 - accuracy: 0.9967 - val_loss: 0.8685 - val_accuracy: 0.5192\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.2114 - accuracy: 0.9932 - val_loss: 0.8687 - val_accuracy: 0.5385\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1991 - accuracy: 0.9932 - val_loss: 0.8695 - val_accuracy: 0.5385\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2088 - accuracy: 0.9957 - val_loss: 0.8696 - val_accuracy: 0.5385\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.79; accuracy of 59.62%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 11s 326ms/step - loss: 2.0252 - accuracy: 0.2884 - val_loss: 1.0223 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5918 - accuracy: 0.4441 - val_loss: 1.0983 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.4918 - accuracy: 0.4154 - val_loss: 0.9437 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.2680 - accuracy: 0.6735 - val_loss: 0.9513 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.1643 - accuracy: 0.7222 - val_loss: 0.9651 - val_accuracy: 0.4423\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.0374 - accuracy: 0.7421 - val_loss: 0.9710 - val_accuracy: 0.5577\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9616 - accuracy: 0.8135 - val_loss: 0.9127 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8322 - accuracy: 0.8556 - val_loss: 0.9050 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.7913 - accuracy: 0.8373 - val_loss: 0.9204 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6797 - accuracy: 0.9075 - val_loss: 0.9338 - val_accuracy: 0.5192\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6343 - accuracy: 0.8949 - val_loss: 0.8489 - val_accuracy: 0.6154\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5440 - accuracy: 0.9520 - val_loss: 0.9077 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4883 - accuracy: 0.9307 - val_loss: 0.8592 - val_accuracy: 0.5962\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4708 - accuracy: 0.9569 - val_loss: 0.8401 - val_accuracy: 0.5962\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4474 - accuracy: 0.9355 - val_loss: 0.8351 - val_accuracy: 0.6154\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4266 - accuracy: 0.9712 - val_loss: 0.8321 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3917 - accuracy: 0.9716 - val_loss: 0.8450 - val_accuracy: 0.6154\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3658 - accuracy: 0.9571 - val_loss: 0.8308 - val_accuracy: 0.6154\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2930 - accuracy: 0.9868 - val_loss: 0.8462 - val_accuracy: 0.6346\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2789 - accuracy: 0.9975 - val_loss: 0.8518 - val_accuracy: 0.6154\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3125 - accuracy: 0.9864 - val_loss: 0.8264 - val_accuracy: 0.6346\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2432 - accuracy: 0.9762 - val_loss: 0.8479 - val_accuracy: 0.6346\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2182 - accuracy: 0.9903 - val_loss: 0.8368 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2144 - accuracy: 0.9852 - val_loss: 0.8404 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2370 - accuracy: 0.9885 - val_loss: 0.8344 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1816 - accuracy: 0.9942 - val_loss: 0.8361 - val_accuracy: 0.6346\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1779 - accuracy: 0.9885 - val_loss: 0.8402 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1822 - accuracy: 0.9967 - val_loss: 0.8414 - val_accuracy: 0.6346\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1825 - accuracy: 0.9901 - val_loss: 0.8394 - val_accuracy: 0.6154\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.6154\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.6154\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1689 - accuracy: 1.0000 - val_loss: 0.8469 - val_accuracy: 0.6346\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1494 - accuracy: 1.0000 - val_loss: 0.8476 - val_accuracy: 0.6346\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1463 - accuracy: 0.9967 - val_loss: 0.8501 - val_accuracy: 0.6346\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1822 - accuracy: 0.9828 - val_loss: 0.8496 - val_accuracy: 0.6346\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1420 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.6154\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1279 - accuracy: 1.0000 - val_loss: 0.8477 - val_accuracy: 0.6154\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.6154\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.6154\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1287 - accuracy: 1.0000 - val_loss: 0.8469 - val_accuracy: 0.6154\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1339 - accuracy: 1.0000 - val_loss: 0.8474 - val_accuracy: 0.6154\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.81; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.79 - Accuracy: 0.6%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.81 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.2):\n",
      "> Accuracy: 0.64 (+- 0.03)\n",
      "> Loss: 0.79 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 13/25 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 303ms/step - loss: 1.9786 - accuracy: 0.2991 - val_loss: 0.9415 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6298 - accuracy: 0.5740 - val_loss: 0.9675 - val_accuracy: 0.4808\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.2949 - accuracy: 0.6000 - val_loss: 0.9379 - val_accuracy: 0.5769\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1230 - accuracy: 0.7411 - val_loss: 0.9309 - val_accuracy: 0.5385\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.0029 - accuracy: 0.6979 - val_loss: 0.9007 - val_accuracy: 0.5192\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8349 - accuracy: 0.8764 - val_loss: 0.8298 - val_accuracy: 0.5769\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6818 - accuracy: 0.8800 - val_loss: 0.9180 - val_accuracy: 0.4423\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6448 - accuracy: 0.9140 - val_loss: 0.8621 - val_accuracy: 0.5385\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5288 - accuracy: 0.9214 - val_loss: 0.8029 - val_accuracy: 0.5962\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4891 - accuracy: 0.9269 - val_loss: 0.9255 - val_accuracy: 0.5000\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4152 - accuracy: 0.9565 - val_loss: 0.7873 - val_accuracy: 0.6346\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3652 - accuracy: 0.9725 - val_loss: 0.7401 - val_accuracy: 0.6346\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2991 - accuracy: 0.9859 - val_loss: 0.7459 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3103 - accuracy: 0.9751 - val_loss: 0.7296 - val_accuracy: 0.6923\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2723 - accuracy: 0.9799 - val_loss: 0.7499 - val_accuracy: 0.6538\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2316 - accuracy: 0.9907 - val_loss: 0.8639 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2113 - accuracy: 0.9785 - val_loss: 0.7803 - val_accuracy: 0.6346\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1957 - accuracy: 0.9783 - val_loss: 0.8244 - val_accuracy: 0.6346\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1838 - accuracy: 1.0000 - val_loss: 0.8374 - val_accuracy: 0.6346\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1389 - accuracy: 0.9957 - val_loss: 0.7147 - val_accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.7115\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1277 - accuracy: 0.9885 - val_loss: 0.7285 - val_accuracy: 0.6731\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1576 - accuracy: 0.9913 - val_loss: 0.7140 - val_accuracy: 0.6923\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.6923\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1542 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.6538\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.6538\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.6538\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.6538\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0860 - accuracy: 0.9982 - val_loss: 0.7443 - val_accuracy: 0.6538\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.6538\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.6731\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.6538\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.6538\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.6538\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.6731\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.7469 - val_accuracy: 0.6731\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.6731\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.6731\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.6731\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.6731\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 302ms/step - loss: 2.0155 - accuracy: 0.2400 - val_loss: 0.9495 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7367 - accuracy: 0.4994 - val_loss: 0.9275 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.3649 - accuracy: 0.6790 - val_loss: 1.0227 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.0961 - accuracy: 0.7080 - val_loss: 0.9122 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9191 - accuracy: 0.8554 - val_loss: 0.9768 - val_accuracy: 0.4423\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7164 - accuracy: 0.8912 - val_loss: 0.9355 - val_accuracy: 0.5000\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.6777 - accuracy: 0.8659 - val_loss: 1.0194 - val_accuracy: 0.4423\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.5628 - accuracy: 0.9170 - val_loss: 0.8560 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4785 - accuracy: 0.9459 - val_loss: 0.8735 - val_accuracy: 0.4615\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4311 - accuracy: 0.9418 - val_loss: 0.8678 - val_accuracy: 0.4615\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3494 - accuracy: 0.9644 - val_loss: 0.9608 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3531 - accuracy: 0.9546 - val_loss: 0.8243 - val_accuracy: 0.5385\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3571 - accuracy: 0.9204 - val_loss: 0.8540 - val_accuracy: 0.5000\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2739 - accuracy: 0.9652 - val_loss: 0.8240 - val_accuracy: 0.5769\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2793 - accuracy: 0.9506 - val_loss: 0.8256 - val_accuracy: 0.5577\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2190 - accuracy: 0.9862 - val_loss: 0.8275 - val_accuracy: 0.6346\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1925 - accuracy: 0.9988 - val_loss: 0.9147 - val_accuracy: 0.5192\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.8399 - val_accuracy: 0.6346\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 0.8398 - val_accuracy: 0.6154\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1399 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.5962\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1335 - accuracy: 0.9964 - val_loss: 0.8941 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1197 - accuracy: 1.0000 - val_loss: 0.8718 - val_accuracy: 0.6154\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.5962\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1220 - accuracy: 1.0000 - val_loss: 0.8760 - val_accuracy: 0.6154\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 0.8855 - val_accuracy: 0.5962\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.8896 - val_accuracy: 0.5962\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.6154\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.8945 - val_accuracy: 0.6154\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.8930 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.6346\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.6346\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.8947 - val_accuracy: 0.6154\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1039 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.5962\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.6154\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.76; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 303ms/step - loss: 2.0754 - accuracy: 0.2203 - val_loss: 0.9626 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6079 - accuracy: 0.5297 - val_loss: 0.9750 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.2608 - accuracy: 0.6241 - val_loss: 0.9089 - val_accuracy: 0.5192\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.0402 - accuracy: 0.8118 - val_loss: 1.0149 - val_accuracy: 0.4808\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.9882 - accuracy: 0.7338 - val_loss: 0.9098 - val_accuracy: 0.5192\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7737 - accuracy: 0.8473 - val_loss: 0.8835 - val_accuracy: 0.4808\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6461 - accuracy: 0.9017 - val_loss: 0.8544 - val_accuracy: 0.5962\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5380 - accuracy: 0.9253 - val_loss: 0.8762 - val_accuracy: 0.5577\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.4976 - accuracy: 0.9629 - val_loss: 0.8687 - val_accuracy: 0.4808\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4302 - accuracy: 0.9669 - val_loss: 0.8553 - val_accuracy: 0.5769\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3726 - accuracy: 0.9777 - val_loss: 0.8406 - val_accuracy: 0.5962\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3319 - accuracy: 0.9830 - val_loss: 0.8445 - val_accuracy: 0.6154\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.3272 - accuracy: 0.9439 - val_loss: 0.8422 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2529 - accuracy: 0.9805 - val_loss: 0.8576 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2188 - accuracy: 0.9885 - val_loss: 0.8722 - val_accuracy: 0.6731\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2189 - accuracy: 0.9885 - val_loss: 0.8480 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1835 - accuracy: 0.9913 - val_loss: 0.8448 - val_accuracy: 0.6731\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1629 - accuracy: 1.0000 - val_loss: 0.8533 - val_accuracy: 0.6923\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.1638 - accuracy: 0.9988 - val_loss: 0.8549 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1756 - accuracy: 0.9828 - val_loss: 0.8604 - val_accuracy: 0.6923\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1765 - accuracy: 0.9828 - val_loss: 0.8523 - val_accuracy: 0.6538\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1337 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1258 - accuracy: 0.9946 - val_loss: 0.8543 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1453 - accuracy: 1.0000 - val_loss: 0.8478 - val_accuracy: 0.6538\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1501 - accuracy: 1.0000 - val_loss: 0.8497 - val_accuracy: 0.6538\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.8496 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.8490 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1288 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.6538\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.8490 - val_accuracy: 0.6538\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1351 - accuracy: 1.0000 - val_loss: 0.8495 - val_accuracy: 0.6538\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.82; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.76 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.82 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.5):\n",
      "> Accuracy: 0.65 (+- 0.02)\n",
      "> Loss: 0.78 (+- 0.03)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 14/25 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.8\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 307ms/step - loss: 2.0593 - accuracy: 0.2699 - val_loss: 1.0461 - val_accuracy: 0.3846\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.2435 - accuracy: 0.6837 - val_loss: 0.9257 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9339 - accuracy: 0.7407 - val_loss: 0.8995 - val_accuracy: 0.5769\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.6926 - accuracy: 0.8646 - val_loss: 0.8588 - val_accuracy: 0.5769\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6340 - accuracy: 0.8336 - val_loss: 0.8218 - val_accuracy: 0.6538\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.3640 - accuracy: 0.9614 - val_loss: 0.7512 - val_accuracy: 0.6154\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2539 - accuracy: 0.9558 - val_loss: 0.7743 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2407 - accuracy: 0.9364 - val_loss: 0.7325 - val_accuracy: 0.7308\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1744 - accuracy: 0.9842 - val_loss: 0.9467 - val_accuracy: 0.5577\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1850 - accuracy: 0.9828 - val_loss: 0.6878 - val_accuracy: 0.7308\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1278 - accuracy: 0.9789 - val_loss: 0.6837 - val_accuracy: 0.6923\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.7115\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.6923\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.6923\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.6923\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.6923\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 0.6346\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.6538\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.7115\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.7115\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.7529 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.7115\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.7115\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.74; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 303ms/step - loss: 2.1717 - accuracy: 0.2848 - val_loss: 0.9895 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.4441 - accuracy: 0.6474 - val_loss: 0.9188 - val_accuracy: 0.5192\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.0742 - accuracy: 0.7776 - val_loss: 0.9618 - val_accuracy: 0.4231\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6283 - accuracy: 0.8609 - val_loss: 0.8660 - val_accuracy: 0.5385\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4588 - accuracy: 0.9508 - val_loss: 0.8564 - val_accuracy: 0.5192\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3386 - accuracy: 0.9440 - val_loss: 0.8640 - val_accuracy: 0.5769\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2723 - accuracy: 0.9732 - val_loss: 0.8364 - val_accuracy: 0.5577\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2141 - accuracy: 0.9793 - val_loss: 0.8586 - val_accuracy: 0.5577\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1789 - accuracy: 1.0000 - val_loss: 0.8443 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1287 - accuracy: 1.0000 - val_loss: 0.8657 - val_accuracy: 0.5769\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.1195 - accuracy: 0.9932 - val_loss: 0.8130 - val_accuracy: 0.6154\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0881 - accuracy: 0.9957 - val_loss: 0.8360 - val_accuracy: 0.5769\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.5962\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.8706 - val_accuracy: 0.5962\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.8982 - val_accuracy: 0.5577\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.5577\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.6346\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.9189 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.6154\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.6731\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.9512 - val_accuracy: 0.6731\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.9595 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.9784 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.9771 - val_accuracy: 0.6538\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.75; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 302ms/step - loss: 1.9729 - accuracy: 0.3185 - val_loss: 1.1404 - val_accuracy: 0.3462\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.4429 - accuracy: 0.5044 - val_loss: 1.0462 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.1160 - accuracy: 0.6115 - val_loss: 1.0475 - val_accuracy: 0.5385\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.8377 - accuracy: 0.7925 - val_loss: 0.9042 - val_accuracy: 0.5577\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.5392 - accuracy: 0.8930 - val_loss: 0.8504 - val_accuracy: 0.4808\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3758 - accuracy: 0.9654 - val_loss: 0.8122 - val_accuracy: 0.5769\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2748 - accuracy: 0.9755 - val_loss: 0.8464 - val_accuracy: 0.5962\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.2468 - accuracy: 0.9530 - val_loss: 0.8355 - val_accuracy: 0.5962\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1590 - accuracy: 0.9938 - val_loss: 0.8667 - val_accuracy: 0.6346\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1218 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.6538\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.1139 - accuracy: 1.0000 - val_loss: 0.9084 - val_accuracy: 0.6154\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.8937 - val_accuracy: 0.7115\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.9110 - val_accuracy: 0.6923\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.9058 - val_accuracy: 0.6923\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.9148 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.6923\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.9289 - val_accuracy: 0.6731\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.9289 - val_accuracy: 0.6731\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.9273 - val_accuracy: 0.6923\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.79; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.74 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.75 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.79 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.8):\n",
      "> Accuracy: 0.67 (+- 0.01)\n",
      "> Loss: 0.76 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 15/25 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 11s 322ms/step - loss: 2.0628 - accuracy: 0.2753 - val_loss: 0.9107 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1193 - accuracy: 0.7116 - val_loss: 1.0229 - val_accuracy: 0.5385\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.9463 - accuracy: 0.7207 - val_loss: 0.8100 - val_accuracy: 0.5962\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5171 - accuracy: 0.8975 - val_loss: 0.8593 - val_accuracy: 0.6538\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4030 - accuracy: 0.9221 - val_loss: 0.7438 - val_accuracy: 0.6538\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2066 - accuracy: 0.9731 - val_loss: 0.8228 - val_accuracy: 0.5769\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.1478 - accuracy: 0.9673 - val_loss: 0.7227 - val_accuracy: 0.8077\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.7889 - val_accuracy: 0.6731\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.7115\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.6731\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.8403 - val_accuracy: 0.6923\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.6923\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.7500\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.7500\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.0278 - val_accuracy: 0.5962\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7748 - val_accuracy: 0.7308\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.7308\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.7500\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.8085 - val_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.7692\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7308\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.7308\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.7308\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.7308\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7308\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.7115\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.78; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 311ms/step - loss: 2.0032 - accuracy: 0.3197 - val_loss: 1.0321 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.2802 - accuracy: 0.6970 - val_loss: 1.7069 - val_accuracy: 0.1154\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.6476 - accuracy: 0.4792 - val_loss: 0.9151 - val_accuracy: 0.5577\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6390 - accuracy: 0.8242 - val_loss: 0.9175 - val_accuracy: 0.5577\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3425 - accuracy: 0.9727 - val_loss: 0.8294 - val_accuracy: 0.5385\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1937 - accuracy: 0.9595 - val_loss: 0.8713 - val_accuracy: 0.5385\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1845 - accuracy: 0.9474 - val_loss: 1.0607 - val_accuracy: 0.5962\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 1.0609 - val_accuracy: 0.5577\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.9147 - val_accuracy: 0.6154\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.5769\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0221 - accuracy: 0.9975 - val_loss: 0.9235 - val_accuracy: 0.6154\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.0485 - val_accuracy: 0.5577\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.0842 - val_accuracy: 0.5769\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.6731\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.0093 - val_accuracy: 0.6923\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.6538\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.6923\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.0250 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.0228 - val_accuracy: 0.7115\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.0335 - val_accuracy: 0.7308\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.0317 - val_accuracy: 0.7115\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.0346 - val_accuracy: 0.7115\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.81; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 299ms/step - loss: 2.1102 - accuracy: 0.2986 - val_loss: 1.0752 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6008 - accuracy: 0.4336 - val_loss: 0.9575 - val_accuracy: 0.5385\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8181 - accuracy: 0.7466 - val_loss: 0.8377 - val_accuracy: 0.5962\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3922 - accuracy: 0.9214 - val_loss: 0.9212 - val_accuracy: 0.5769\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2391 - accuracy: 0.9643 - val_loss: 0.8401 - val_accuracy: 0.6538\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2265 - accuracy: 0.9562 - val_loss: 0.8006 - val_accuracy: 0.6346\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1029 - accuracy: 0.9967 - val_loss: 1.1254 - val_accuracy: 0.6154\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1139 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.6538\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.6346\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0388 - accuracy: 0.9988 - val_loss: 0.9435 - val_accuracy: 0.6731\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.6731\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.6923\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.7308\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.7308\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.9863 - val_accuracy: 0.7115\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.9864 - val_accuracy: 0.7115\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.7308\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.77; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.78 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.81 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.77 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.9):\n",
      "> Accuracy: 0.65 (+- 0.0)\n",
      "> Loss: 0.79 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 16/25 ...\n",
      "Learning rate = 0.0005\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 8s 304ms/step - loss: 2.0707 - accuracy: 0.1991 - val_loss: 1.0239 - val_accuracy: 0.4038\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.8135 - accuracy: 0.3830 - val_loss: 1.0022 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5991 - accuracy: 0.4428 - val_loss: 1.0229 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.8740 - accuracy: 0.4076 - val_loss: 1.0134 - val_accuracy: 0.3654\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.4547 - accuracy: 0.5640 - val_loss: 0.9932 - val_accuracy: 0.4038\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5442 - accuracy: 0.5385 - val_loss: 0.9886 - val_accuracy: 0.4038\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.4335 - accuracy: 0.5583 - val_loss: 0.9514 - val_accuracy: 0.5192\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.4156 - accuracy: 0.6565 - val_loss: 0.9911 - val_accuracy: 0.3846\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2565 - accuracy: 0.6785 - val_loss: 0.9617 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.2046 - accuracy: 0.7279 - val_loss: 0.9628 - val_accuracy: 0.4615\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.1181 - accuracy: 0.7456 - val_loss: 0.9459 - val_accuracy: 0.5000\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1610 - accuracy: 0.7616 - val_loss: 0.9439 - val_accuracy: 0.4423\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1066 - accuracy: 0.7514 - val_loss: 0.9111 - val_accuracy: 0.5385\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.0116 - accuracy: 0.7887 - val_loss: 0.9254 - val_accuracy: 0.5192\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.0485 - accuracy: 0.7894 - val_loss: 0.8862 - val_accuracy: 0.5577\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.9904 - accuracy: 0.7926 - val_loss: 0.8943 - val_accuracy: 0.5192\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8722 - accuracy: 0.8413 - val_loss: 0.9358 - val_accuracy: 0.5192\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.8859 - accuracy: 0.8239 - val_loss: 0.9013 - val_accuracy: 0.5192\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.8627 - accuracy: 0.8435 - val_loss: 0.8736 - val_accuracy: 0.5769\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.7940 - accuracy: 0.8600 - val_loss: 0.8818 - val_accuracy: 0.5962\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8309 - accuracy: 0.8753 - val_loss: 0.8688 - val_accuracy: 0.5577\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7854 - accuracy: 0.8905 - val_loss: 0.8477 - val_accuracy: 0.6538\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7238 - accuracy: 0.9187 - val_loss: 0.8419 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.6673 - accuracy: 0.9189 - val_loss: 0.8370 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6936 - accuracy: 0.8736 - val_loss: 0.8207 - val_accuracy: 0.6154\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6376 - accuracy: 0.9074 - val_loss: 0.8299 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5968 - accuracy: 0.9242 - val_loss: 0.8004 - val_accuracy: 0.6346\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6039 - accuracy: 0.9218 - val_loss: 0.7898 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6313 - accuracy: 0.9070 - val_loss: 0.8172 - val_accuracy: 0.6731\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5478 - accuracy: 0.9435 - val_loss: 0.7899 - val_accuracy: 0.6538\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5236 - accuracy: 0.9165 - val_loss: 0.7803 - val_accuracy: 0.6538\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5908 - accuracy: 0.8562 - val_loss: 0.7824 - val_accuracy: 0.6538\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5485 - accuracy: 0.9245 - val_loss: 0.7574 - val_accuracy: 0.6346\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.5545 - accuracy: 0.9556 - val_loss: 0.7810 - val_accuracy: 0.6731\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4722 - accuracy: 0.9317 - val_loss: 0.7565 - val_accuracy: 0.6538\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4655 - accuracy: 0.9711 - val_loss: 0.7568 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4386 - accuracy: 0.9349 - val_loss: 0.7522 - val_accuracy: 0.6731\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4391 - accuracy: 0.9749 - val_loss: 0.7414 - val_accuracy: 0.6538\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3822 - accuracy: 0.9562 - val_loss: 0.7407 - val_accuracy: 0.6731\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4214 - accuracy: 0.9696 - val_loss: 0.7354 - val_accuracy: 0.6538\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.4076 - accuracy: 0.9601 - val_loss: 0.7371 - val_accuracy: 0.6923\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4069 - accuracy: 0.9508 - val_loss: 0.7390 - val_accuracy: 0.6923\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3517 - accuracy: 0.9854 - val_loss: 0.7275 - val_accuracy: 0.6538\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3615 - accuracy: 0.9559 - val_loss: 0.7268 - val_accuracy: 0.6923\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3451 - accuracy: 0.9635 - val_loss: 0.7375 - val_accuracy: 0.6731\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3066 - accuracy: 0.9784 - val_loss: 0.7305 - val_accuracy: 0.6538\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3758 - accuracy: 0.9536 - val_loss: 0.7303 - val_accuracy: 0.6923\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3205 - accuracy: 0.9876 - val_loss: 0.7267 - val_accuracy: 0.6731\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3184 - accuracy: 0.9781 - val_loss: 0.7169 - val_accuracy: 0.6538\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3060 - accuracy: 0.9553 - val_loss: 0.7259 - val_accuracy: 0.6731\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2994 - accuracy: 0.9874 - val_loss: 0.7391 - val_accuracy: 0.6538\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2762 - accuracy: 0.9821 - val_loss: 0.7253 - val_accuracy: 0.6731\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2623 - accuracy: 0.9914 - val_loss: 0.7321 - val_accuracy: 0.6923\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2572 - accuracy: 0.9785 - val_loss: 0.7151 - val_accuracy: 0.6731\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2503 - accuracy: 0.9888 - val_loss: 0.7117 - val_accuracy: 0.6538\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2700 - accuracy: 0.9727 - val_loss: 0.7136 - val_accuracy: 0.6731\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2082 - accuracy: 0.9975 - val_loss: 0.7193 - val_accuracy: 0.6538\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2528 - accuracy: 0.9982 - val_loss: 0.7288 - val_accuracy: 0.6923\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2364 - accuracy: 0.9783 - val_loss: 0.7427 - val_accuracy: 0.6731\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2273 - accuracy: 0.9793 - val_loss: 0.7202 - val_accuracy: 0.7115\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1956 - accuracy: 0.9988 - val_loss: 0.7154 - val_accuracy: 0.6923\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1949 - accuracy: 0.9982 - val_loss: 0.7166 - val_accuracy: 0.6923\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2030 - accuracy: 0.9949 - val_loss: 0.7164 - val_accuracy: 0.6923\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2098 - accuracy: 0.9679 - val_loss: 0.7139 - val_accuracy: 0.6923\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2156 - accuracy: 0.9805 - val_loss: 0.7123 - val_accuracy: 0.6731\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1958 - accuracy: 0.9988 - val_loss: 0.7134 - val_accuracy: 0.6731\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1862 - accuracy: 0.9982 - val_loss: 0.7136 - val_accuracy: 0.6731\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2088 - accuracy: 0.9967 - val_loss: 0.7136 - val_accuracy: 0.6731\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1952 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.6731\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1815 - accuracy: 0.9913 - val_loss: 0.7135 - val_accuracy: 0.6731\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2239 - accuracy: 0.9928 - val_loss: 0.7135 - val_accuracy: 0.6923\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1888 - accuracy: 0.9932 - val_loss: 0.7135 - val_accuracy: 0.6923\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2161 - accuracy: 0.9870 - val_loss: 0.7136 - val_accuracy: 0.6923\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1675 - accuracy: 0.9982 - val_loss: 0.7135 - val_accuracy: 0.6923\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2144 - accuracy: 0.9932 - val_loss: 0.7133 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 316ms/step - loss: 2.0596 - accuracy: 0.1816 - val_loss: 1.0046 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.7979 - accuracy: 0.4088 - val_loss: 1.0009 - val_accuracy: 0.4808\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.4581 - accuracy: 0.5436 - val_loss: 1.0658 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.5983 - accuracy: 0.3989 - val_loss: 1.0260 - val_accuracy: 0.4615\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.4195 - accuracy: 0.6030 - val_loss: 1.0275 - val_accuracy: 0.4808\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.4328 - accuracy: 0.5629 - val_loss: 1.0033 - val_accuracy: 0.4808\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.3693 - accuracy: 0.6042 - val_loss: 0.9996 - val_accuracy: 0.5192\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.2104 - accuracy: 0.7059 - val_loss: 1.0090 - val_accuracy: 0.4231\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2180 - accuracy: 0.7475 - val_loss: 1.0244 - val_accuracy: 0.4231\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1120 - accuracy: 0.7095 - val_loss: 1.0111 - val_accuracy: 0.4423\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.0874 - accuracy: 0.7303 - val_loss: 1.0425 - val_accuracy: 0.4038\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.0517 - accuracy: 0.7670 - val_loss: 0.9609 - val_accuracy: 0.4423\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.0307 - accuracy: 0.7919 - val_loss: 0.9883 - val_accuracy: 0.4615\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.9693 - accuracy: 0.8277 - val_loss: 1.0120 - val_accuracy: 0.4615\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.9417 - accuracy: 0.8014 - val_loss: 0.9912 - val_accuracy: 0.4423\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9423 - accuracy: 0.8291 - val_loss: 0.9568 - val_accuracy: 0.4231\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.8342 - accuracy: 0.8836 - val_loss: 0.9688 - val_accuracy: 0.4615\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8317 - accuracy: 0.8656 - val_loss: 0.9345 - val_accuracy: 0.4423\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.7691 - accuracy: 0.8514 - val_loss: 0.9880 - val_accuracy: 0.4423\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7913 - accuracy: 0.8601 - val_loss: 0.9279 - val_accuracy: 0.5192\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.7276 - accuracy: 0.9044 - val_loss: 0.9025 - val_accuracy: 0.5192\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6671 - accuracy: 0.9212 - val_loss: 0.9155 - val_accuracy: 0.4423\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6557 - accuracy: 0.8733 - val_loss: 0.9626 - val_accuracy: 0.4231\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6197 - accuracy: 0.9046 - val_loss: 0.9343 - val_accuracy: 0.4615\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5843 - accuracy: 0.9195 - val_loss: 0.9144 - val_accuracy: 0.5000\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.6644 - accuracy: 0.9198 - val_loss: 0.8935 - val_accuracy: 0.5192\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5416 - accuracy: 0.9294 - val_loss: 0.8959 - val_accuracy: 0.5192\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5471 - accuracy: 0.9097 - val_loss: 0.8970 - val_accuracy: 0.5385\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4923 - accuracy: 0.9373 - val_loss: 0.8919 - val_accuracy: 0.5192\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5318 - accuracy: 0.9431 - val_loss: 0.8821 - val_accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5058 - accuracy: 0.9240 - val_loss: 0.8865 - val_accuracy: 0.5385\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4846 - accuracy: 0.9343 - val_loss: 0.8896 - val_accuracy: 0.5385\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5724 - accuracy: 0.9132 - val_loss: 0.8855 - val_accuracy: 0.5192\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4502 - accuracy: 0.9011 - val_loss: 0.8814 - val_accuracy: 0.5192\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4214 - accuracy: 0.9258 - val_loss: 0.8767 - val_accuracy: 0.5192\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4087 - accuracy: 0.9707 - val_loss: 0.8717 - val_accuracy: 0.5192\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3757 - accuracy: 0.9722 - val_loss: 0.8713 - val_accuracy: 0.5192\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3726 - accuracy: 0.9640 - val_loss: 0.8751 - val_accuracy: 0.5385\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3973 - accuracy: 0.9459 - val_loss: 0.8786 - val_accuracy: 0.5192\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3614 - accuracy: 0.9555 - val_loss: 0.8791 - val_accuracy: 0.5192\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3409 - accuracy: 0.9536 - val_loss: 0.8775 - val_accuracy: 0.5000\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3295 - accuracy: 0.9701 - val_loss: 0.8740 - val_accuracy: 0.5192\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3066 - accuracy: 0.9611 - val_loss: 0.8755 - val_accuracy: 0.5192\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3314 - accuracy: 0.9657 - val_loss: 0.8752 - val_accuracy: 0.5192\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3132 - accuracy: 0.9657 - val_loss: 0.8763 - val_accuracy: 0.5192\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2946 - accuracy: 0.9955 - val_loss: 0.8750 - val_accuracy: 0.5385\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2974 - accuracy: 0.9878 - val_loss: 0.8755 - val_accuracy: 0.5385\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2829 - accuracy: 0.9798 - val_loss: 0.8759 - val_accuracy: 0.5385\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2721 - accuracy: 0.9867 - val_loss: 0.8762 - val_accuracy: 0.5192\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3156 - accuracy: 0.9762 - val_loss: 0.8768 - val_accuracy: 0.5192\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3305 - accuracy: 0.9456 - val_loss: 0.8770 - val_accuracy: 0.5385\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2811 - accuracy: 0.9833 - val_loss: 0.8774 - val_accuracy: 0.5385\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3008 - accuracy: 0.9783 - val_loss: 0.8775 - val_accuracy: 0.5385\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.5192\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2767 - accuracy: 0.9808 - val_loss: 0.8782 - val_accuracy: 0.5192\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2902 - accuracy: 0.9822 - val_loss: 0.8787 - val_accuracy: 0.5385\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2656 - accuracy: 0.9790 - val_loss: 0.8791 - val_accuracy: 0.5192\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.8; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 8s 304ms/step - loss: 2.1199 - accuracy: 0.1776 - val_loss: 0.9940 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.6246 - accuracy: 0.4561 - val_loss: 1.0486 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6714 - accuracy: 0.3892 - val_loss: 1.0325 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5718 - accuracy: 0.5587 - val_loss: 1.0441 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.4801 - accuracy: 0.4999 - val_loss: 1.0472 - val_accuracy: 0.4615\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.4687 - accuracy: 0.5332 - val_loss: 0.9923 - val_accuracy: 0.4423\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.3843 - accuracy: 0.6096 - val_loss: 1.0069 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.3307 - accuracy: 0.6504 - val_loss: 0.9814 - val_accuracy: 0.5000\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.2644 - accuracy: 0.6646 - val_loss: 0.9913 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.1154 - accuracy: 0.7925 - val_loss: 1.0188 - val_accuracy: 0.4615\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.1760 - accuracy: 0.7395 - val_loss: 0.9889 - val_accuracy: 0.5000\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.0152 - accuracy: 0.8034 - val_loss: 0.9787 - val_accuracy: 0.5385\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.0631 - accuracy: 0.8463 - val_loss: 0.9676 - val_accuracy: 0.5192\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.9405 - accuracy: 0.7955 - val_loss: 0.9903 - val_accuracy: 0.4808\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.9553 - accuracy: 0.7569 - val_loss: 0.9288 - val_accuracy: 0.5577\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.8937 - accuracy: 0.8506 - val_loss: 0.9402 - val_accuracy: 0.5192\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.8614 - accuracy: 0.8781 - val_loss: 0.9157 - val_accuracy: 0.6346\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8605 - accuracy: 0.8295 - val_loss: 0.9037 - val_accuracy: 0.5769\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8296 - accuracy: 0.8846 - val_loss: 0.8946 - val_accuracy: 0.6154\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7695 - accuracy: 0.8484 - val_loss: 0.9175 - val_accuracy: 0.5192\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6855 - accuracy: 0.9110 - val_loss: 0.9094 - val_accuracy: 0.5769\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7078 - accuracy: 0.9094 - val_loss: 0.8696 - val_accuracy: 0.5962\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7079 - accuracy: 0.9151 - val_loss: 0.8565 - val_accuracy: 0.6154\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6973 - accuracy: 0.9079 - val_loss: 0.8477 - val_accuracy: 0.6154\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6303 - accuracy: 0.9320 - val_loss: 0.8521 - val_accuracy: 0.5962\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5790 - accuracy: 0.9409 - val_loss: 0.8433 - val_accuracy: 0.6154\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5947 - accuracy: 0.9382 - val_loss: 0.8475 - val_accuracy: 0.6154\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5468 - accuracy: 0.9243 - val_loss: 0.8462 - val_accuracy: 0.5962\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5497 - accuracy: 0.9370 - val_loss: 0.8249 - val_accuracy: 0.6154\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4812 - accuracy: 0.9697 - val_loss: 0.8236 - val_accuracy: 0.6154\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4486 - accuracy: 0.9827 - val_loss: 0.8188 - val_accuracy: 0.6538\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4635 - accuracy: 0.9631 - val_loss: 0.8149 - val_accuracy: 0.6346\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4577 - accuracy: 0.9750 - val_loss: 0.8120 - val_accuracy: 0.6346\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4505 - accuracy: 0.9715 - val_loss: 0.8100 - val_accuracy: 0.6346\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4369 - accuracy: 0.9759 - val_loss: 0.8070 - val_accuracy: 0.6154\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.4123 - accuracy: 0.9797 - val_loss: 0.8081 - val_accuracy: 0.6154\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3586 - accuracy: 0.9838 - val_loss: 0.8072 - val_accuracy: 0.6154\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4164 - accuracy: 0.9678 - val_loss: 0.8075 - val_accuracy: 0.6346\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3817 - accuracy: 0.9957 - val_loss: 0.8028 - val_accuracy: 0.6154\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3440 - accuracy: 0.9842 - val_loss: 0.8036 - val_accuracy: 0.6154\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3255 - accuracy: 0.9741 - val_loss: 0.8077 - val_accuracy: 0.6154\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3241 - accuracy: 0.9760 - val_loss: 0.8107 - val_accuracy: 0.6154\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3084 - accuracy: 0.9741 - val_loss: 0.8101 - val_accuracy: 0.6154\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2996 - accuracy: 0.9732 - val_loss: 0.8065 - val_accuracy: 0.6154\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2959 - accuracy: 0.9964 - val_loss: 0.8083 - val_accuracy: 0.6154\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3315 - accuracy: 0.9760 - val_loss: 0.8065 - val_accuracy: 0.6154\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2868 - accuracy: 0.9758 - val_loss: 0.8060 - val_accuracy: 0.6154\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2781 - accuracy: 0.9826 - val_loss: 0.8073 - val_accuracy: 0.6154\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2835 - accuracy: 0.9805 - val_loss: 0.8072 - val_accuracy: 0.6154\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2713 - accuracy: 0.9768 - val_loss: 0.8076 - val_accuracy: 0.6154\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2956 - accuracy: 0.9799 - val_loss: 0.8074 - val_accuracy: 0.6154\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2920 - accuracy: 0.9942 - val_loss: 0.8064 - val_accuracy: 0.6154\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2709 - accuracy: 0.9828 - val_loss: 0.8064 - val_accuracy: 0.6154\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2706 - accuracy: 0.9816 - val_loss: 0.8064 - val_accuracy: 0.6154\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3056 - accuracy: 0.9932 - val_loss: 0.8059 - val_accuracy: 0.6154\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2637 - accuracy: 0.9967 - val_loss: 0.8062 - val_accuracy: 0.6154\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2557 - accuracy: 0.9855 - val_loss: 0.8061 - val_accuracy: 0.6154\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2470 - accuracy: 0.9975 - val_loss: 0.8061 - val_accuracy: 0.6154\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2895 - accuracy: 0.9774 - val_loss: 0.8059 - val_accuracy: 0.6154\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.8 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0005, mtm = 0):\n",
      "> Accuracy: 0.63 (+- 0.02)\n",
      "> Loss: 0.79 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 17/25 ...\n",
      "Learning rate = 0.0005\n",
      "Momentum = 0.2\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 310ms/step - loss: 2.0419 - accuracy: 0.2173 - val_loss: 1.0158 - val_accuracy: 0.5385\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.8557 - accuracy: 0.3435 - val_loss: 0.9867 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.7870 - accuracy: 0.4611 - val_loss: 1.0195 - val_accuracy: 0.3846\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.5021 - accuracy: 0.5177 - val_loss: 1.0066 - val_accuracy: 0.4038\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.4553 - accuracy: 0.5664 - val_loss: 0.9785 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.3625 - accuracy: 0.6441 - val_loss: 0.9929 - val_accuracy: 0.4038\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.2387 - accuracy: 0.6765 - val_loss: 0.9938 - val_accuracy: 0.4038\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.3169 - accuracy: 0.6122 - val_loss: 0.9279 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.1524 - accuracy: 0.7667 - val_loss: 0.9371 - val_accuracy: 0.4423\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.1364 - accuracy: 0.7412 - val_loss: 0.9108 - val_accuracy: 0.5385\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.0766 - accuracy: 0.7358 - val_loss: 0.9063 - val_accuracy: 0.5192\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9934 - accuracy: 0.8194 - val_loss: 0.9166 - val_accuracy: 0.5000\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9484 - accuracy: 0.8389 - val_loss: 0.8871 - val_accuracy: 0.5577\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.8627 - accuracy: 0.8934 - val_loss: 0.9139 - val_accuracy: 0.5192\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8784 - accuracy: 0.8572 - val_loss: 0.9006 - val_accuracy: 0.5192\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8030 - accuracy: 0.8439 - val_loss: 0.8753 - val_accuracy: 0.5385\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.8234 - accuracy: 0.8599 - val_loss: 0.8288 - val_accuracy: 0.5769\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7523 - accuracy: 0.8614 - val_loss: 0.8667 - val_accuracy: 0.5385\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.7319 - accuracy: 0.8809 - val_loss: 0.8353 - val_accuracy: 0.5962\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.6726 - accuracy: 0.9271 - val_loss: 0.8239 - val_accuracy: 0.5769\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6532 - accuracy: 0.9286 - val_loss: 0.8085 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6200 - accuracy: 0.8772 - val_loss: 0.8027 - val_accuracy: 0.6538\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5849 - accuracy: 0.9424 - val_loss: 0.7693 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5752 - accuracy: 0.9331 - val_loss: 0.7744 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5379 - accuracy: 0.9249 - val_loss: 0.8075 - val_accuracy: 0.6538\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4838 - accuracy: 0.9600 - val_loss: 0.7777 - val_accuracy: 0.6923\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5278 - accuracy: 0.9258 - val_loss: 0.7649 - val_accuracy: 0.6923\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4835 - accuracy: 0.9279 - val_loss: 0.7662 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.4258 - accuracy: 0.9729 - val_loss: 0.8115 - val_accuracy: 0.6538\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4037 - accuracy: 0.9483 - val_loss: 0.7523 - val_accuracy: 0.6731\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4552 - accuracy: 0.9541 - val_loss: 0.7404 - val_accuracy: 0.6538\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4264 - accuracy: 0.9666 - val_loss: 0.7367 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3558 - accuracy: 0.9682 - val_loss: 0.7429 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3737 - accuracy: 0.9651 - val_loss: 0.7279 - val_accuracy: 0.6538\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3912 - accuracy: 0.9755 - val_loss: 0.7541 - val_accuracy: 0.6731\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3597 - accuracy: 0.9709 - val_loss: 0.7330 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3003 - accuracy: 0.9896 - val_loss: 0.7339 - val_accuracy: 0.6923\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3267 - accuracy: 0.9781 - val_loss: 0.7206 - val_accuracy: 0.6731\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3173 - accuracy: 0.9712 - val_loss: 0.7359 - val_accuracy: 0.6731\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3400 - accuracy: 0.9381 - val_loss: 0.7362 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2817 - accuracy: 0.9774 - val_loss: 0.7228 - val_accuracy: 0.6731\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2936 - accuracy: 0.9816 - val_loss: 0.7100 - val_accuracy: 0.6538\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2532 - accuracy: 0.9860 - val_loss: 0.7168 - val_accuracy: 0.6731\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2627 - accuracy: 0.9745 - val_loss: 0.7105 - val_accuracy: 0.6731\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2524 - accuracy: 0.9811 - val_loss: 0.7212 - val_accuracy: 0.6731\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2257 - accuracy: 0.9988 - val_loss: 0.7236 - val_accuracy: 0.6731\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2207 - accuracy: 0.9727 - val_loss: 0.7092 - val_accuracy: 0.6731\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2187 - accuracy: 0.9899 - val_loss: 0.7130 - val_accuracy: 0.6731\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1992 - accuracy: 0.9932 - val_loss: 0.7151 - val_accuracy: 0.6923\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2498 - accuracy: 0.9957 - val_loss: 0.7155 - val_accuracy: 0.6923\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2449 - accuracy: 0.9741 - val_loss: 0.7076 - val_accuracy: 0.6731\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1717 - accuracy: 0.9932 - val_loss: 0.7105 - val_accuracy: 0.6923\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2104 - accuracy: 0.9878 - val_loss: 0.7203 - val_accuracy: 0.6731\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1662 - accuracy: 0.9988 - val_loss: 0.7140 - val_accuracy: 0.6923\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1715 - accuracy: 0.9982 - val_loss: 0.7141 - val_accuracy: 0.7115\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.6923\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1663 - accuracy: 0.9975 - val_loss: 0.7153 - val_accuracy: 0.6923\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1718 - accuracy: 0.9982 - val_loss: 0.7124 - val_accuracy: 0.6923\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1551 - accuracy: 0.9949 - val_loss: 0.7141 - val_accuracy: 0.6923\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.6923\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.6923\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1517 - accuracy: 0.9932 - val_loss: 0.7182 - val_accuracy: 0.6731\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.6923\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1426 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.6923\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1602 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.6923\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.1648 - accuracy: 0.9975 - val_loss: 0.7140 - val_accuracy: 0.6923\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.1612 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.6923\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1422 - accuracy: 0.9946 - val_loss: 0.7146 - val_accuracy: 0.6923\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1290 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.6923\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1667 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.6923\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.1456 - accuracy: 0.9982 - val_loss: 0.7144 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 11s 586ms/step - loss: 2.0795 - accuracy: 0.1871 - val_loss: 1.0410 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.7312 - accuracy: 0.3747 - val_loss: 1.0388 - val_accuracy: 0.4808\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.6398 - accuracy: 0.5323 - val_loss: 1.0088 - val_accuracy: 0.4808\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.5082 - accuracy: 0.5708 - val_loss: 0.9954 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5463 - accuracy: 0.4777 - val_loss: 0.9904 - val_accuracy: 0.5192\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.2957 - accuracy: 0.6975 - val_loss: 1.0030 - val_accuracy: 0.4808\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1775 - accuracy: 0.7392 - val_loss: 1.0670 - val_accuracy: 0.4038\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2145 - accuracy: 0.6834 - val_loss: 0.9966 - val_accuracy: 0.4423\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1151 - accuracy: 0.7857 - val_loss: 0.9632 - val_accuracy: 0.4808\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.0885 - accuracy: 0.7965 - val_loss: 0.9533 - val_accuracy: 0.4615\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.0012 - accuracy: 0.8180 - val_loss: 0.9453 - val_accuracy: 0.4808\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.9429 - accuracy: 0.8303 - val_loss: 0.9366 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8772 - accuracy: 0.8654 - val_loss: 0.9455 - val_accuracy: 0.4808\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8840 - accuracy: 0.8621 - val_loss: 0.9418 - val_accuracy: 0.4615\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8180 - accuracy: 0.8582 - val_loss: 0.9185 - val_accuracy: 0.4808\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7781 - accuracy: 0.8967 - val_loss: 0.9088 - val_accuracy: 0.5577\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6943 - accuracy: 0.8982 - val_loss: 0.9290 - val_accuracy: 0.4808\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.7424 - accuracy: 0.8776 - val_loss: 0.9141 - val_accuracy: 0.4615\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.7220 - accuracy: 0.8980 - val_loss: 0.8885 - val_accuracy: 0.4615\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6243 - accuracy: 0.9156 - val_loss: 0.9206 - val_accuracy: 0.4615\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6060 - accuracy: 0.9218 - val_loss: 0.8734 - val_accuracy: 0.5385\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5554 - accuracy: 0.9009 - val_loss: 0.8838 - val_accuracy: 0.5192\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5469 - accuracy: 0.9360 - val_loss: 0.8845 - val_accuracy: 0.5192\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5026 - accuracy: 0.9591 - val_loss: 0.8993 - val_accuracy: 0.5385\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5023 - accuracy: 0.9552 - val_loss: 0.8878 - val_accuracy: 0.5192\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5013 - accuracy: 0.9450 - val_loss: 0.8860 - val_accuracy: 0.5385\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4089 - accuracy: 0.9763 - val_loss: 0.8843 - val_accuracy: 0.5385\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4163 - accuracy: 0.9694 - val_loss: 0.8821 - val_accuracy: 0.5385\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4816 - accuracy: 0.9781 - val_loss: 0.8745 - val_accuracy: 0.5385\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.4538 - accuracy: 0.9379 - val_loss: 0.8715 - val_accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4059 - accuracy: 0.9219 - val_loss: 0.8808 - val_accuracy: 0.5385\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4021 - accuracy: 0.9633 - val_loss: 0.8728 - val_accuracy: 0.5385\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4019 - accuracy: 0.9571 - val_loss: 0.8756 - val_accuracy: 0.5385\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3590 - accuracy: 0.9669 - val_loss: 0.8739 - val_accuracy: 0.5385\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3895 - accuracy: 0.9693 - val_loss: 0.8700 - val_accuracy: 0.5385\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3515 - accuracy: 0.9762 - val_loss: 0.8687 - val_accuracy: 0.5000\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3893 - accuracy: 0.9606 - val_loss: 0.8679 - val_accuracy: 0.5192\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3549 - accuracy: 0.9586 - val_loss: 0.8692 - val_accuracy: 0.5000\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3527 - accuracy: 0.9773 - val_loss: 0.8713 - val_accuracy: 0.5192\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3830 - accuracy: 0.9101 - val_loss: 0.8705 - val_accuracy: 0.5192\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3296 - accuracy: 0.9624 - val_loss: 0.8722 - val_accuracy: 0.5192\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3317 - accuracy: 0.9892 - val_loss: 0.8713 - val_accuracy: 0.5192\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3296 - accuracy: 0.9795 - val_loss: 0.8712 - val_accuracy: 0.5385\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3255 - accuracy: 0.9680 - val_loss: 0.8721 - val_accuracy: 0.5192\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3088 - accuracy: 0.9682 - val_loss: 0.8718 - val_accuracy: 0.5192\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3428 - accuracy: 0.9559 - val_loss: 0.8711 - val_accuracy: 0.5192\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3006 - accuracy: 0.9810 - val_loss: 0.8702 - val_accuracy: 0.5385\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2929 - accuracy: 0.9695 - val_loss: 0.8702 - val_accuracy: 0.5385\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2880 - accuracy: 0.9749 - val_loss: 0.8707 - val_accuracy: 0.5385\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3176 - accuracy: 0.9677 - val_loss: 0.8708 - val_accuracy: 0.5385\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3461 - accuracy: 0.9654 - val_loss: 0.8712 - val_accuracy: 0.5385\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2784 - accuracy: 0.9944 - val_loss: 0.8716 - val_accuracy: 0.5385\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3047 - accuracy: 0.9695 - val_loss: 0.8717 - val_accuracy: 0.5385\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3015 - accuracy: 0.9796 - val_loss: 0.8719 - val_accuracy: 0.5385\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3093 - accuracy: 0.9640 - val_loss: 0.8719 - val_accuracy: 0.5385\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2924 - accuracy: 0.9822 - val_loss: 0.8721 - val_accuracy: 0.5385\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3281 - accuracy: 0.9834 - val_loss: 0.8722 - val_accuracy: 0.5385\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.79; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 319ms/step - loss: 2.0383 - accuracy: 0.2260 - val_loss: 1.0113 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7767 - accuracy: 0.4379 - val_loss: 1.0090 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6805 - accuracy: 0.4424 - val_loss: 1.0139 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.4755 - accuracy: 0.5113 - val_loss: 1.0244 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.3877 - accuracy: 0.6427 - val_loss: 1.0180 - val_accuracy: 0.4615\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.3451 - accuracy: 0.6059 - val_loss: 1.0096 - val_accuracy: 0.5000\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.2076 - accuracy: 0.6641 - val_loss: 1.0097 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2967 - accuracy: 0.6784 - val_loss: 0.9719 - val_accuracy: 0.5000\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.1598 - accuracy: 0.7192 - val_loss: 0.9694 - val_accuracy: 0.5192\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.1704 - accuracy: 0.7904 - val_loss: 0.9725 - val_accuracy: 0.5385\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.1043 - accuracy: 0.7950 - val_loss: 0.9692 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.0024 - accuracy: 0.8206 - val_loss: 0.9738 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9384 - accuracy: 0.8460 - val_loss: 0.9687 - val_accuracy: 0.5769\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.9970 - accuracy: 0.8408 - val_loss: 0.9681 - val_accuracy: 0.5769\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.0002 - accuracy: 0.8276 - val_loss: 0.9507 - val_accuracy: 0.5385\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.9616 - accuracy: 0.8075 - val_loss: 0.9447 - val_accuracy: 0.5769\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9284 - accuracy: 0.8258 - val_loss: 0.9393 - val_accuracy: 0.5577\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8453 - accuracy: 0.8882 - val_loss: 0.9375 - val_accuracy: 0.5769\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8733 - accuracy: 0.8655 - val_loss: 0.9234 - val_accuracy: 0.5769\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.8413 - accuracy: 0.8922 - val_loss: 0.9203 - val_accuracy: 0.5769\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.8515 - accuracy: 0.7965 - val_loss: 0.9112 - val_accuracy: 0.6154\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7759 - accuracy: 0.8693 - val_loss: 0.9058 - val_accuracy: 0.5962\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8529 - accuracy: 0.8970 - val_loss: 0.8920 - val_accuracy: 0.6154\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.7589 - accuracy: 0.8711 - val_loss: 0.8916 - val_accuracy: 0.6154\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6829 - accuracy: 0.9211 - val_loss: 0.8832 - val_accuracy: 0.5962\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7319 - accuracy: 0.8960 - val_loss: 0.8713 - val_accuracy: 0.6154\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.7082 - accuracy: 0.9033 - val_loss: 0.8741 - val_accuracy: 0.6154\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.7453 - accuracy: 0.9446 - val_loss: 0.8572 - val_accuracy: 0.6154\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.6245 - accuracy: 0.9375 - val_loss: 0.8570 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6463 - accuracy: 0.9193 - val_loss: 0.8682 - val_accuracy: 0.5769\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6640 - accuracy: 0.9183 - val_loss: 0.8518 - val_accuracy: 0.5962\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6415 - accuracy: 0.8925 - val_loss: 0.8448 - val_accuracy: 0.6346\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5948 - accuracy: 0.9366 - val_loss: 0.8398 - val_accuracy: 0.6346\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5766 - accuracy: 0.9641 - val_loss: 0.8356 - val_accuracy: 0.5962\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5667 - accuracy: 0.9574 - val_loss: 0.8341 - val_accuracy: 0.5962\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.6361 - accuracy: 0.9245 - val_loss: 0.8282 - val_accuracy: 0.6346\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.5395 - accuracy: 0.9287 - val_loss: 0.8310 - val_accuracy: 0.6346\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5369 - accuracy: 0.9427 - val_loss: 0.8280 - val_accuracy: 0.6346\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5277 - accuracy: 0.9450 - val_loss: 0.8213 - val_accuracy: 0.6346\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4781 - accuracy: 0.9888 - val_loss: 0.8160 - val_accuracy: 0.6346\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4982 - accuracy: 0.9572 - val_loss: 0.8130 - val_accuracy: 0.6538\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5280 - accuracy: 0.9339 - val_loss: 0.8142 - val_accuracy: 0.6154\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4899 - accuracy: 0.9675 - val_loss: 0.8138 - val_accuracy: 0.6346\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4498 - accuracy: 0.9676 - val_loss: 0.8103 - val_accuracy: 0.6538\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4756 - accuracy: 0.9454 - val_loss: 0.8076 - val_accuracy: 0.6538\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4375 - accuracy: 0.9677 - val_loss: 0.8062 - val_accuracy: 0.6538\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4110 - accuracy: 0.9617 - val_loss: 0.8040 - val_accuracy: 0.6538\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4529 - accuracy: 0.9760 - val_loss: 0.8021 - val_accuracy: 0.6538\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4303 - accuracy: 0.9513 - val_loss: 0.8014 - val_accuracy: 0.6538\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4249 - accuracy: 0.9707 - val_loss: 0.8004 - val_accuracy: 0.6538\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3859 - accuracy: 0.9867 - val_loss: 0.7993 - val_accuracy: 0.6538\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4228 - accuracy: 0.9758 - val_loss: 0.7991 - val_accuracy: 0.6346\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3840 - accuracy: 0.9679 - val_loss: 0.7975 - val_accuracy: 0.6154\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3713 - accuracy: 0.9827 - val_loss: 0.7975 - val_accuracy: 0.6154\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3683 - accuracy: 0.9752 - val_loss: 0.7973 - val_accuracy: 0.6346\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.4352 - accuracy: 0.9564 - val_loss: 0.7974 - val_accuracy: 0.6346\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3643 - accuracy: 0.9449 - val_loss: 0.7988 - val_accuracy: 0.6346\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3765 - accuracy: 0.9878 - val_loss: 0.7969 - val_accuracy: 0.6154\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3468 - accuracy: 0.9786 - val_loss: 0.7969 - val_accuracy: 0.6154\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3248 - accuracy: 0.9749 - val_loss: 0.7983 - val_accuracy: 0.6154\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3174 - accuracy: 0.9935 - val_loss: 0.7981 - val_accuracy: 0.6154\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.3315 - accuracy: 0.9748 - val_loss: 0.7974 - val_accuracy: 0.6154\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2937 - accuracy: 0.9880 - val_loss: 0.7973 - val_accuracy: 0.6154\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2873 - accuracy: 0.9762 - val_loss: 0.7975 - val_accuracy: 0.6154\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2978 - accuracy: 0.9852 - val_loss: 0.7982 - val_accuracy: 0.6346\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2908 - accuracy: 0.9921 - val_loss: 0.7980 - val_accuracy: 0.6346\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2898 - accuracy: 0.9880 - val_loss: 0.7982 - val_accuracy: 0.6154\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2893 - accuracy: 0.9928 - val_loss: 0.7992 - val_accuracy: 0.6346\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.3091 - accuracy: 0.9889 - val_loss: 0.7993 - val_accuracy: 0.6346\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2918 - accuracy: 0.9975 - val_loss: 0.7994 - val_accuracy: 0.6346\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2862 - accuracy: 0.9889 - val_loss: 0.7994 - val_accuracy: 0.6346\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2797 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.6346\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2857 - accuracy: 0.9777 - val_loss: 0.7993 - val_accuracy: 0.6346\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2798 - accuracy: 0.9774 - val_loss: 0.7994 - val_accuracy: 0.6346\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2753 - accuracy: 0.9946 - val_loss: 0.7996 - val_accuracy: 0.6346\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2817 - accuracy: 0.9889 - val_loss: 0.7996 - val_accuracy: 0.6346\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2719 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.6346\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2840 - accuracy: 0.9859 - val_loss: 0.8000 - val_accuracy: 0.6346\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2545 - accuracy: 0.9798 - val_loss: 0.8001 - val_accuracy: 0.6346\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.79 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0005, mtm = 0.2):\n",
      "> Accuracy: 0.65 (+- 0.03)\n",
      "> Loss: 0.79 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 18/25 ...\n",
      "Learning rate = 0.0005\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 318ms/step - loss: 2.0642 - accuracy: 0.2497 - val_loss: 1.0600 - val_accuracy: 0.3846\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.7303 - accuracy: 0.3806 - val_loss: 0.9727 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6186 - accuracy: 0.5443 - val_loss: 1.0057 - val_accuracy: 0.3846\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4019 - accuracy: 0.5892 - val_loss: 0.9696 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.2498 - accuracy: 0.7093 - val_loss: 1.0257 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.1362 - accuracy: 0.7421 - val_loss: 0.9785 - val_accuracy: 0.3846\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9717 - accuracy: 0.7712 - val_loss: 0.9503 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.9551 - accuracy: 0.8344 - val_loss: 0.9040 - val_accuracy: 0.5577\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.8811 - accuracy: 0.8523 - val_loss: 0.8916 - val_accuracy: 0.5577\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8098 - accuracy: 0.9014 - val_loss: 0.9191 - val_accuracy: 0.4231\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8218 - accuracy: 0.8620 - val_loss: 0.8684 - val_accuracy: 0.5000\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7012 - accuracy: 0.8990 - val_loss: 0.8339 - val_accuracy: 0.5962\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6505 - accuracy: 0.9239 - val_loss: 0.8280 - val_accuracy: 0.5962\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6376 - accuracy: 0.8953 - val_loss: 0.8101 - val_accuracy: 0.6154\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6491 - accuracy: 0.9294 - val_loss: 0.7983 - val_accuracy: 0.6154\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5707 - accuracy: 0.9003 - val_loss: 0.8083 - val_accuracy: 0.6346\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4901 - accuracy: 0.9495 - val_loss: 0.7742 - val_accuracy: 0.5962\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4881 - accuracy: 0.9615 - val_loss: 0.7565 - val_accuracy: 0.6346\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4513 - accuracy: 0.9587 - val_loss: 0.7389 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4240 - accuracy: 0.9768 - val_loss: 0.7486 - val_accuracy: 0.6731\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.4548 - accuracy: 0.9494 - val_loss: 0.7378 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3860 - accuracy: 0.9696 - val_loss: 0.7288 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3583 - accuracy: 0.9538 - val_loss: 0.7727 - val_accuracy: 0.6923\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3355 - accuracy: 0.9749 - val_loss: 0.7236 - val_accuracy: 0.6923\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2930 - accuracy: 0.9668 - val_loss: 0.7287 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2697 - accuracy: 0.9917 - val_loss: 0.7064 - val_accuracy: 0.6923\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2761 - accuracy: 0.9855 - val_loss: 0.7205 - val_accuracy: 0.6923\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2722 - accuracy: 0.9756 - val_loss: 0.7034 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2722 - accuracy: 0.9621 - val_loss: 0.7027 - val_accuracy: 0.7115\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2247 - accuracy: 0.9834 - val_loss: 0.7062 - val_accuracy: 0.7115\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2198 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.7115\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2016 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.7115\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2092 - accuracy: 0.9889 - val_loss: 0.7267 - val_accuracy: 0.6538\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1708 - accuracy: 0.9988 - val_loss: 0.6998 - val_accuracy: 0.7115\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1717 - accuracy: 0.9946 - val_loss: 0.7119 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1583 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.7115\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1415 - accuracy: 0.9988 - val_loss: 0.7111 - val_accuracy: 0.7115\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1583 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.6923\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1557 - accuracy: 0.9828 - val_loss: 0.7041 - val_accuracy: 0.7115\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.6538\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.7115\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1606 - accuracy: 0.9913 - val_loss: 0.7072 - val_accuracy: 0.6923\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.7308\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1405 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.7115\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.7308\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.7115\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1140 - accuracy: 0.9932 - val_loss: 0.7177 - val_accuracy: 0.6923\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.7115\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1084 - accuracy: 0.9828 - val_loss: 0.7193 - val_accuracy: 0.7115\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.6923\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.6731\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.6923\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.6538\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.6538\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.6538\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1309 - accuracy: 0.9913 - val_loss: 0.7230 - val_accuracy: 0.6538\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.6538\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.6538\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 300ms/step - loss: 2.0208 - accuracy: 0.2218 - val_loss: 1.0287 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7327 - accuracy: 0.4976 - val_loss: 1.0004 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.5029 - accuracy: 0.5830 - val_loss: 0.9677 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.3298 - accuracy: 0.6581 - val_loss: 0.9753 - val_accuracy: 0.5385\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.2607 - accuracy: 0.7458 - val_loss: 0.9921 - val_accuracy: 0.5000\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.1303 - accuracy: 0.7715 - val_loss: 0.9599 - val_accuracy: 0.4808\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.0375 - accuracy: 0.8262 - val_loss: 0.9486 - val_accuracy: 0.4808\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9252 - accuracy: 0.8196 - val_loss: 0.9728 - val_accuracy: 0.5385\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9098 - accuracy: 0.7836 - val_loss: 0.9423 - val_accuracy: 0.4423\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.7532 - accuracy: 0.8461 - val_loss: 1.0017 - val_accuracy: 0.4808\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7251 - accuracy: 0.8703 - val_loss: 0.9134 - val_accuracy: 0.4423\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6640 - accuracy: 0.8786 - val_loss: 0.9100 - val_accuracy: 0.4423\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6342 - accuracy: 0.9006 - val_loss: 0.8949 - val_accuracy: 0.5000\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6230 - accuracy: 0.9076 - val_loss: 0.8640 - val_accuracy: 0.5192\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5257 - accuracy: 0.9302 - val_loss: 0.8974 - val_accuracy: 0.5000\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.4575 - accuracy: 0.9559 - val_loss: 0.8627 - val_accuracy: 0.5000\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4395 - accuracy: 0.9697 - val_loss: 0.8816 - val_accuracy: 0.5192\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4216 - accuracy: 0.9572 - val_loss: 0.8445 - val_accuracy: 0.5769\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4073 - accuracy: 0.9658 - val_loss: 0.8488 - val_accuracy: 0.5577\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3911 - accuracy: 0.9590 - val_loss: 0.8682 - val_accuracy: 0.5385\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3772 - accuracy: 0.9205 - val_loss: 0.8516 - val_accuracy: 0.5385\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2869 - accuracy: 0.9880 - val_loss: 0.8587 - val_accuracy: 0.5577\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3283 - accuracy: 0.9864 - val_loss: 0.8937 - val_accuracy: 0.5962\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3278 - accuracy: 0.9605 - val_loss: 0.8931 - val_accuracy: 0.5577\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3000 - accuracy: 0.9808 - val_loss: 0.8725 - val_accuracy: 0.5769\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2653 - accuracy: 0.9834 - val_loss: 0.8733 - val_accuracy: 0.5769\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2703 - accuracy: 0.9548 - val_loss: 0.8735 - val_accuracy: 0.5577\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2618 - accuracy: 0.9805 - val_loss: 0.8742 - val_accuracy: 0.5577\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2574 - accuracy: 0.9798 - val_loss: 0.8700 - val_accuracy: 0.5385\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2252 - accuracy: 0.9955 - val_loss: 0.8726 - val_accuracy: 0.5577\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2383 - accuracy: 0.9913 - val_loss: 0.8729 - val_accuracy: 0.5385\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2421 - accuracy: 0.9852 - val_loss: 0.8765 - val_accuracy: 0.5577\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2203 - accuracy: 0.9904 - val_loss: 0.8779 - val_accuracy: 0.5385\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2403 - accuracy: 0.9785 - val_loss: 0.8774 - val_accuracy: 0.5192\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2400 - accuracy: 0.9932 - val_loss: 0.8772 - val_accuracy: 0.5385\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2255 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.5385\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.2605 - accuracy: 0.9750 - val_loss: 0.8777 - val_accuracy: 0.5385\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2318 - accuracy: 0.9904 - val_loss: 0.8773 - val_accuracy: 0.5385\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.81; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 309ms/step - loss: 1.9621 - accuracy: 0.2481 - val_loss: 1.0645 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.7069 - accuracy: 0.3319 - val_loss: 1.0622 - val_accuracy: 0.4231\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.5133 - accuracy: 0.3943 - val_loss: 1.0071 - val_accuracy: 0.4231\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.3134 - accuracy: 0.6312 - val_loss: 1.0215 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.2655 - accuracy: 0.6062 - val_loss: 0.9841 - val_accuracy: 0.4808\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.1299 - accuracy: 0.7718 - val_loss: 0.9342 - val_accuracy: 0.4423\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.0193 - accuracy: 0.7793 - val_loss: 0.9478 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9477 - accuracy: 0.8060 - val_loss: 0.9678 - val_accuracy: 0.4808\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9272 - accuracy: 0.8639 - val_loss: 0.9082 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.8516 - accuracy: 0.8692 - val_loss: 0.9191 - val_accuracy: 0.5385\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7166 - accuracy: 0.8849 - val_loss: 0.9456 - val_accuracy: 0.5192\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7180 - accuracy: 0.8312 - val_loss: 0.8961 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6728 - accuracy: 0.8615 - val_loss: 0.8616 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5851 - accuracy: 0.9362 - val_loss: 0.8634 - val_accuracy: 0.5385\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5547 - accuracy: 0.9503 - val_loss: 0.8426 - val_accuracy: 0.5962\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5075 - accuracy: 0.9319 - val_loss: 0.8633 - val_accuracy: 0.5769\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5043 - accuracy: 0.9306 - val_loss: 0.8332 - val_accuracy: 0.5962\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4463 - accuracy: 0.9468 - val_loss: 0.8430 - val_accuracy: 0.5962\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4184 - accuracy: 0.9469 - val_loss: 0.8229 - val_accuracy: 0.6346\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4586 - accuracy: 0.9350 - val_loss: 0.8171 - val_accuracy: 0.6154\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3414 - accuracy: 0.9774 - val_loss: 0.8229 - val_accuracy: 0.6154\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3798 - accuracy: 0.9375 - val_loss: 0.8250 - val_accuracy: 0.6154\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3221 - accuracy: 0.9780 - val_loss: 0.8237 - val_accuracy: 0.6154\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.2910 - accuracy: 0.9828 - val_loss: 0.8131 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2772 - accuracy: 0.9913 - val_loss: 0.8276 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2711 - accuracy: 0.9774 - val_loss: 0.8111 - val_accuracy: 0.6346\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2214 - accuracy: 0.9859 - val_loss: 0.8150 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2409 - accuracy: 0.9885 - val_loss: 0.8179 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2170 - accuracy: 0.9828 - val_loss: 0.8166 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1897 - accuracy: 0.9967 - val_loss: 0.8198 - val_accuracy: 0.6346\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2159 - accuracy: 0.9698 - val_loss: 0.8203 - val_accuracy: 0.6154\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1802 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.6346\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1998 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.6731\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2220 - accuracy: 0.9928 - val_loss: 0.8159 - val_accuracy: 0.6346\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1758 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.6346\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1820 - accuracy: 1.0000 - val_loss: 0.8249 - val_accuracy: 0.6346\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1558 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.6346\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1620 - accuracy: 1.0000 - val_loss: 0.8249 - val_accuracy: 0.6346\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1788 - accuracy: 0.9932 - val_loss: 0.8242 - val_accuracy: 0.6346\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1706 - accuracy: 1.0000 - val_loss: 0.8251 - val_accuracy: 0.6346\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1450 - accuracy: 1.0000 - val_loss: 0.8274 - val_accuracy: 0.6346\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1506 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.6346\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1409 - accuracy: 0.9913 - val_loss: 0.8276 - val_accuracy: 0.6154\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1438 - accuracy: 1.0000 - val_loss: 0.8282 - val_accuracy: 0.6154\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1472 - accuracy: 0.9982 - val_loss: 0.8285 - val_accuracy: 0.6154\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1506 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.6154\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.81 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0005, mtm = 0.5):\n",
      "> Accuracy: 0.63 (+- 0.02)\n",
      "> Loss: 0.79 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 19/25 ...\n",
      "Learning rate = 0.0005\n",
      "Momentum = 0.8\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 323ms/step - loss: 2.0756 - accuracy: 0.2432 - val_loss: 1.0222 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5934 - accuracy: 0.4244 - val_loss: 0.9872 - val_accuracy: 0.3846\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.2477 - accuracy: 0.7097 - val_loss: 0.9679 - val_accuracy: 0.3654\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.9996 - accuracy: 0.7988 - val_loss: 0.9381 - val_accuracy: 0.5192\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8680 - accuracy: 0.8161 - val_loss: 0.8521 - val_accuracy: 0.5385\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6606 - accuracy: 0.9137 - val_loss: 0.8369 - val_accuracy: 0.5769\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5826 - accuracy: 0.9362 - val_loss: 0.8229 - val_accuracy: 0.5385\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5132 - accuracy: 0.9377 - val_loss: 0.8227 - val_accuracy: 0.5769\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4521 - accuracy: 0.9634 - val_loss: 0.7762 - val_accuracy: 0.6538\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3865 - accuracy: 0.9394 - val_loss: 0.7519 - val_accuracy: 0.7308\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3121 - accuracy: 0.9762 - val_loss: 0.7477 - val_accuracy: 0.6538\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2864 - accuracy: 0.9658 - val_loss: 0.7641 - val_accuracy: 0.6346\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2326 - accuracy: 0.9913 - val_loss: 0.7966 - val_accuracy: 0.6346\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2085 - accuracy: 0.9818 - val_loss: 0.7485 - val_accuracy: 0.6346\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1864 - accuracy: 0.9765 - val_loss: 0.7134 - val_accuracy: 0.7308\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1566 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.6538\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1398 - accuracy: 0.9988 - val_loss: 0.7622 - val_accuracy: 0.6346\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1360 - accuracy: 0.9880 - val_loss: 0.7184 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.7910 - val_accuracy: 0.6538\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.7749 - val_accuracy: 0.6154\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.7689 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.6538\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.6731\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.7776 - val_accuracy: 0.6731\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.7686 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.7723 - val_accuracy: 0.6731\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.7733 - val_accuracy: 0.6731\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.6731\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.6538\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.6538\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.7784 - val_accuracy: 0.6731\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 311ms/step - loss: 2.0357 - accuracy: 0.2645 - val_loss: 1.0281 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5778 - accuracy: 0.4371 - val_loss: 0.9842 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.2337 - accuracy: 0.6233 - val_loss: 0.9172 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9601 - accuracy: 0.8210 - val_loss: 0.9294 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7853 - accuracy: 0.8404 - val_loss: 0.9430 - val_accuracy: 0.4808\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7431 - accuracy: 0.8299 - val_loss: 0.9116 - val_accuracy: 0.5000\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.5570 - accuracy: 0.9138 - val_loss: 0.8791 - val_accuracy: 0.4423\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4057 - accuracy: 0.9650 - val_loss: 0.8331 - val_accuracy: 0.5385\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.3627 - accuracy: 0.9416 - val_loss: 0.9292 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3339 - accuracy: 0.9694 - val_loss: 0.8218 - val_accuracy: 0.5577\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2472 - accuracy: 0.9707 - val_loss: 0.8335 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2459 - accuracy: 0.9932 - val_loss: 0.8321 - val_accuracy: 0.5385\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2263 - accuracy: 0.9885 - val_loss: 0.8605 - val_accuracy: 0.5385\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2099 - accuracy: 0.9921 - val_loss: 0.8415 - val_accuracy: 0.5962\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1682 - accuracy: 0.9892 - val_loss: 0.9073 - val_accuracy: 0.5385\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1505 - accuracy: 1.0000 - val_loss: 0.8553 - val_accuracy: 0.5769\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1415 - accuracy: 1.0000 - val_loss: 0.8651 - val_accuracy: 0.5769\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1503 - accuracy: 0.9828 - val_loss: 0.8517 - val_accuracy: 0.6154\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.5962\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.5962\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1091 - accuracy: 1.0000 - val_loss: 0.8945 - val_accuracy: 0.5962\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.6154\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.8821 - val_accuracy: 0.6346\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.6346\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0921 - accuracy: 0.9988 - val_loss: 0.8974 - val_accuracy: 0.6154\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.9014 - val_accuracy: 0.6154\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.6154\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.78; accuracy of 69.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 313ms/step - loss: 2.0488 - accuracy: 0.1983 - val_loss: 1.0325 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.4973 - accuracy: 0.4326 - val_loss: 0.9427 - val_accuracy: 0.5192\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2469 - accuracy: 0.7165 - val_loss: 0.9122 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9828 - accuracy: 0.8142 - val_loss: 0.9129 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.8343 - accuracy: 0.8787 - val_loss: 0.8695 - val_accuracy: 0.5000\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7160 - accuracy: 0.9078 - val_loss: 0.8475 - val_accuracy: 0.6154\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5815 - accuracy: 0.9223 - val_loss: 0.8427 - val_accuracy: 0.5577\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4891 - accuracy: 0.9646 - val_loss: 0.8269 - val_accuracy: 0.6154\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4159 - accuracy: 0.9652 - val_loss: 0.8168 - val_accuracy: 0.5962\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3330 - accuracy: 0.9848 - val_loss: 0.8282 - val_accuracy: 0.6154\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2961 - accuracy: 0.9888 - val_loss: 0.8419 - val_accuracy: 0.6154\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2759 - accuracy: 0.9928 - val_loss: 0.8440 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2255 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.6731\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2089 - accuracy: 0.9769 - val_loss: 0.8398 - val_accuracy: 0.6538\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1758 - accuracy: 1.0000 - val_loss: 0.8439 - val_accuracy: 0.6731\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1403 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.6923\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1333 - accuracy: 0.9975 - val_loss: 0.8595 - val_accuracy: 0.6731\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1236 - accuracy: 1.0000 - val_loss: 0.8524 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1382 - accuracy: 0.9982 - val_loss: 0.8678 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1455 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.6346\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1371 - accuracy: 0.9885 - val_loss: 0.8567 - val_accuracy: 0.6731\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1027 - accuracy: 0.9982 - val_loss: 0.8590 - val_accuracy: 0.6538\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.6731\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.8625 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1263 - accuracy: 1.0000 - val_loss: 0.8618 - val_accuracy: 0.6538\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.8589 - val_accuracy: 0.6538\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1206 - accuracy: 1.0000 - val_loss: 0.8575 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.6538\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.78 - Accuracy: 0.69%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0005, mtm = 0.8):\n",
      "> Accuracy: 0.66 (+- 0.02)\n",
      "> Loss: 0.78 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 20/25 ...\n",
      "Learning rate = 0.0005\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 302ms/step - loss: 2.0368 - accuracy: 0.2780 - val_loss: 1.0767 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.7911 - accuracy: 0.2067 - val_loss: 0.8923 - val_accuracy: 0.5577\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.1479 - accuracy: 0.7368 - val_loss: 0.9491 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8364 - accuracy: 0.7694 - val_loss: 0.9197 - val_accuracy: 0.4615\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6027 - accuracy: 0.8174 - val_loss: 0.8671 - val_accuracy: 0.5962\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5674 - accuracy: 0.8614 - val_loss: 0.8654 - val_accuracy: 0.5577\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3847 - accuracy: 0.9058 - val_loss: 0.7627 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2367 - accuracy: 0.9660 - val_loss: 0.7110 - val_accuracy: 0.7115\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2107 - accuracy: 0.9877 - val_loss: 0.9388 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1909 - accuracy: 0.9676 - val_loss: 0.7243 - val_accuracy: 0.6731\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1499 - accuracy: 0.9828 - val_loss: 0.8977 - val_accuracy: 0.5769\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.7620 - val_accuracy: 0.6923\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.6923\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 0.6538\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.6923\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.7322 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.6538\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.6731\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.7652 - val_accuracy: 0.6731\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.6731\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.7781 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.8317 - val_accuracy: 0.6538\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.8132 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.6538\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.6538\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 12s 325ms/step - loss: 2.0102 - accuracy: 0.2506 - val_loss: 1.1023 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.5983 - accuracy: 0.2504 - val_loss: 0.9982 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.1094 - accuracy: 0.5976 - val_loss: 0.9120 - val_accuracy: 0.5192\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7567 - accuracy: 0.9013 - val_loss: 0.8792 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.5150 - accuracy: 0.9044 - val_loss: 0.9554 - val_accuracy: 0.5000\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4299 - accuracy: 0.8963 - val_loss: 0.8603 - val_accuracy: 0.5577\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2798 - accuracy: 0.9539 - val_loss: 0.8434 - val_accuracy: 0.5962\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2032 - accuracy: 0.9886 - val_loss: 0.8788 - val_accuracy: 0.5385\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1817 - accuracy: 0.9967 - val_loss: 0.8372 - val_accuracy: 0.6154\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1314 - accuracy: 1.0000 - val_loss: 0.8379 - val_accuracy: 0.5769\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1387 - accuracy: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 0.6154\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.9156 - val_accuracy: 0.5577\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.8268 - val_accuracy: 0.6538\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 0.6346\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.6538\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.6538\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.6154\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.6346\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.9358 - val_accuracy: 0.6346\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.9474 - val_accuracy: 0.6923\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.6346\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.9675 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.6923\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.9890 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.6731\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.77; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 307ms/step - loss: 1.9826 - accuracy: 0.2899 - val_loss: 0.9739 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.5138 - accuracy: 0.4288 - val_loss: 0.8920 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1558 - accuracy: 0.7192 - val_loss: 0.8589 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6525 - accuracy: 0.8819 - val_loss: 0.8955 - val_accuracy: 0.5385\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6192 - accuracy: 0.8410 - val_loss: 0.8433 - val_accuracy: 0.6346\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3748 - accuracy: 0.9718 - val_loss: 0.7968 - val_accuracy: 0.5962\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3066 - accuracy: 0.9673 - val_loss: 0.8362 - val_accuracy: 0.6538\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3098 - accuracy: 0.9170 - val_loss: 0.8023 - val_accuracy: 0.5962\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1856 - accuracy: 0.9878 - val_loss: 0.8275 - val_accuracy: 0.6154\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1903 - accuracy: 0.9818 - val_loss: 0.8556 - val_accuracy: 0.6731\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1420 - accuracy: 0.9901 - val_loss: 0.9363 - val_accuracy: 0.6346\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1202 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.6346\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1070 - accuracy: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.8747 - val_accuracy: 0.6923\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0631 - accuracy: 0.9967 - val_loss: 0.9138 - val_accuracy: 0.6731\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.6731\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.8584 - val_accuracy: 0.6731\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.8691 - val_accuracy: 0.6923\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.8913 - val_accuracy: 0.6923\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.6923\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.8922 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.6923\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.8938 - val_accuracy: 0.6923\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.8972 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.78; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.77 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.78 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0005, mtm = 0.9):\n",
      "> Accuracy: 0.65 (+- 0.01)\n",
      "> Loss: 0.77 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 21/25 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 8s 299ms/step - loss: 2.1352 - accuracy: 0.1609 - val_loss: 1.0813 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.9745 - accuracy: 0.2236 - val_loss: 1.0501 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.7719 - accuracy: 0.3112 - val_loss: 1.0441 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.8567 - accuracy: 0.3055 - val_loss: 1.0409 - val_accuracy: 0.3654\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.8681 - accuracy: 0.3520 - val_loss: 1.0437 - val_accuracy: 0.3654\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.7971 - accuracy: 0.3403 - val_loss: 1.0443 - val_accuracy: 0.3846\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7289 - accuracy: 0.4298 - val_loss: 1.0462 - val_accuracy: 0.3462\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.6142 - accuracy: 0.4480 - val_loss: 1.0515 - val_accuracy: 0.3654\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5765 - accuracy: 0.4651 - val_loss: 1.0572 - val_accuracy: 0.3654\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 1.6223 - accuracy: 0.4731 - val_loss: 1.0593 - val_accuracy: 0.4038\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.7853 - accuracy: 0.4379 - val_loss: 1.0619 - val_accuracy: 0.4038\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6834 - accuracy: 0.4299 - val_loss: 1.0665 - val_accuracy: 0.4038\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6686 - accuracy: 0.4156 - val_loss: 1.0699 - val_accuracy: 0.4038\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6312 - accuracy: 0.4976 - val_loss: 1.0725 - val_accuracy: 0.3846\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.4787 - accuracy: 0.4469 - val_loss: 1.0766 - val_accuracy: 0.3654\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6536 - accuracy: 0.4413 - val_loss: 1.0789 - val_accuracy: 0.3462\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6971 - accuracy: 0.5112 - val_loss: 1.0805 - val_accuracy: 0.3462\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.5833 - accuracy: 0.5038 - val_loss: 1.0825 - val_accuracy: 0.3269\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.5523 - accuracy: 0.5028 - val_loss: 1.0847 - val_accuracy: 0.3654\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6670 - accuracy: 0.4400 - val_loss: 1.0873 - val_accuracy: 0.3654\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5949 - accuracy: 0.4422 - val_loss: 1.0892 - val_accuracy: 0.3654\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.5322 - accuracy: 0.5013 - val_loss: 1.0905 - val_accuracy: 0.3654\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.7728 - accuracy: 0.4723 - val_loss: 1.0914 - val_accuracy: 0.3654\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6230 - accuracy: 0.5152 - val_loss: 1.0916 - val_accuracy: 0.3462\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 1.04; accuracy of 34.62%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 8s 300ms/step - loss: 2.0042 - accuracy: 0.1408 - val_loss: 1.0944 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 1.8812 - accuracy: 0.2341 - val_loss: 1.0633 - val_accuracy: 0.4423\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7623 - accuracy: 0.2986 - val_loss: 1.0526 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.8527 - accuracy: 0.3040 - val_loss: 1.0550 - val_accuracy: 0.4808\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.7957 - accuracy: 0.3736 - val_loss: 1.0589 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7253 - accuracy: 0.3896 - val_loss: 1.0629 - val_accuracy: 0.4231\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 1.6627 - accuracy: 0.4046 - val_loss: 1.0662 - val_accuracy: 0.4038\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.7280 - accuracy: 0.3676 - val_loss: 1.0670 - val_accuracy: 0.4231\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.6229 - accuracy: 0.4107 - val_loss: 1.0706 - val_accuracy: 0.4231\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.7363 - accuracy: 0.4025 - val_loss: 1.0743 - val_accuracy: 0.4231\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 1.7562 - accuracy: 0.3843 - val_loss: 1.0776 - val_accuracy: 0.4423\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 1.6526 - accuracy: 0.4095 - val_loss: 1.0823 - val_accuracy: 0.4231\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5079 - accuracy: 0.4789 - val_loss: 1.0889 - val_accuracy: 0.4231\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7350 - accuracy: 0.4613 - val_loss: 1.0936 - val_accuracy: 0.4231\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.7455 - accuracy: 0.4082 - val_loss: 1.0988 - val_accuracy: 0.4423\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6096 - accuracy: 0.4494 - val_loss: 1.1029 - val_accuracy: 0.4423\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5667 - accuracy: 0.4577 - val_loss: 1.1071 - val_accuracy: 0.4231\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6473 - accuracy: 0.4386 - val_loss: 1.1107 - val_accuracy: 0.4231\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5623 - accuracy: 0.4568 - val_loss: 1.1151 - val_accuracy: 0.4231\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5913 - accuracy: 0.4697 - val_loss: 1.1192 - val_accuracy: 0.4231\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.5330 - accuracy: 0.4152 - val_loss: 1.1238 - val_accuracy: 0.4231\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6800 - accuracy: 0.4673 - val_loss: 1.1271 - val_accuracy: 0.3846\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6589 - accuracy: 0.4257 - val_loss: 1.1303 - val_accuracy: 0.4231\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 1.04; accuracy of 40.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 8s 299ms/step - loss: 2.1305 - accuracy: 0.1449 - val_loss: 1.0991 - val_accuracy: 0.3846\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.9320 - accuracy: 0.1910 - val_loss: 1.0705 - val_accuracy: 0.3846\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.8737 - accuracy: 0.3013 - val_loss: 1.0625 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.8009 - accuracy: 0.3356 - val_loss: 1.0648 - val_accuracy: 0.4231\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.9125 - accuracy: 0.3540 - val_loss: 1.0687 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.7121 - accuracy: 0.3862 - val_loss: 1.0711 - val_accuracy: 0.4038\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.6008 - accuracy: 0.4126 - val_loss: 1.0768 - val_accuracy: 0.3654\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.6340 - accuracy: 0.4474 - val_loss: 1.0803 - val_accuracy: 0.3846\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.7353 - accuracy: 0.4433 - val_loss: 1.0853 - val_accuracy: 0.3654\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6095 - accuracy: 0.4721 - val_loss: 1.0902 - val_accuracy: 0.3654\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.6136 - accuracy: 0.4873 - val_loss: 1.0928 - val_accuracy: 0.3462\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5511 - accuracy: 0.4630 - val_loss: 1.0961 - val_accuracy: 0.3654\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5664 - accuracy: 0.4727 - val_loss: 1.1001 - val_accuracy: 0.3846\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.6804 - accuracy: 0.4926 - val_loss: 1.1028 - val_accuracy: 0.3846\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.6785 - accuracy: 0.4714 - val_loss: 1.1051 - val_accuracy: 0.3654\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.7348 - accuracy: 0.4535 - val_loss: 1.1068 - val_accuracy: 0.3846\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6810 - accuracy: 0.4906 - val_loss: 1.1072 - val_accuracy: 0.3846\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.6700 - accuracy: 0.4832 - val_loss: 1.1078 - val_accuracy: 0.3846\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6972 - accuracy: 0.4770 - val_loss: 1.1082 - val_accuracy: 0.3846\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.5704 - accuracy: 0.4753 - val_loss: 1.1088 - val_accuracy: 0.3846\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.6253 - accuracy: 0.5309 - val_loss: 1.1090 - val_accuracy: 0.3462\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6257 - accuracy: 0.5501 - val_loss: 1.1087 - val_accuracy: 0.3462\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6237 - accuracy: 0.4802 - val_loss: 1.1085 - val_accuracy: 0.3654\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 1.04; accuracy of 38.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.04 - Accuracy: 0.35%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.04 - Accuracy: 0.4%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.04 - Accuracy: 0.38%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0):\n",
      "> Accuracy: 0.38 (+- 0.02)\n",
      "> Loss: 1.04 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 22/25 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.2\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 315ms/step - loss: 2.2056 - accuracy: 0.1234 - val_loss: 1.0721 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.8342 - accuracy: 0.2306 - val_loss: 1.0456 - val_accuracy: 0.4808\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.7295 - accuracy: 0.3121 - val_loss: 1.0415 - val_accuracy: 0.3846\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.7411 - accuracy: 0.3937 - val_loss: 1.0424 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7033 - accuracy: 0.3958 - val_loss: 1.0464 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.6533 - accuracy: 0.3390 - val_loss: 1.0476 - val_accuracy: 0.3846\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.5907 - accuracy: 0.4334 - val_loss: 1.0505 - val_accuracy: 0.4038\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.6829 - accuracy: 0.4223 - val_loss: 1.0530 - val_accuracy: 0.4038\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7327 - accuracy: 0.4535 - val_loss: 1.0527 - val_accuracy: 0.3654\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7949 - accuracy: 0.4809 - val_loss: 1.0547 - val_accuracy: 0.3654\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.7621 - accuracy: 0.4801 - val_loss: 1.0581 - val_accuracy: 0.3846\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.6988 - accuracy: 0.5395 - val_loss: 1.0594 - val_accuracy: 0.4038\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6153 - accuracy: 0.4866 - val_loss: 1.0619 - val_accuracy: 0.4038\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6145 - accuracy: 0.5004 - val_loss: 1.0643 - val_accuracy: 0.3846\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.5196 - accuracy: 0.5373 - val_loss: 1.0671 - val_accuracy: 0.3654\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6837 - accuracy: 0.5142 - val_loss: 1.0679 - val_accuracy: 0.3654\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.7384 - accuracy: 0.4854 - val_loss: 1.0697 - val_accuracy: 0.3269\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5998 - accuracy: 0.5263 - val_loss: 1.0703 - val_accuracy: 0.3654\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.5908 - accuracy: 0.4476 - val_loss: 1.0721 - val_accuracy: 0.3654\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.6393 - accuracy: 0.5031 - val_loss: 1.0746 - val_accuracy: 0.3846\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6416 - accuracy: 0.5344 - val_loss: 1.0762 - val_accuracy: 0.3846\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6054 - accuracy: 0.4483 - val_loss: 1.0772 - val_accuracy: 0.3654\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.5309 - accuracy: 0.4997 - val_loss: 1.0783 - val_accuracy: 0.3654\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 1.04; accuracy of 32.69%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 317ms/step - loss: 2.1116 - accuracy: 0.1407 - val_loss: 1.0793 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.8911 - accuracy: 0.2328 - val_loss: 1.0546 - val_accuracy: 0.4808\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 2.0495 - accuracy: 0.2454 - val_loss: 1.0432 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.6388 - accuracy: 0.3889 - val_loss: 1.0477 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6614 - accuracy: 0.3437 - val_loss: 1.0570 - val_accuracy: 0.4423\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6483 - accuracy: 0.4551 - val_loss: 1.0618 - val_accuracy: 0.4231\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6447 - accuracy: 0.3900 - val_loss: 1.0619 - val_accuracy: 0.4231\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.6639 - accuracy: 0.4403 - val_loss: 1.0637 - val_accuracy: 0.4038\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.7332 - accuracy: 0.4014 - val_loss: 1.0652 - val_accuracy: 0.4231\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.6658 - accuracy: 0.4740 - val_loss: 1.0690 - val_accuracy: 0.4231\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6631 - accuracy: 0.4527 - val_loss: 1.0723 - val_accuracy: 0.4423\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6363 - accuracy: 0.4302 - val_loss: 1.0762 - val_accuracy: 0.4231\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5979 - accuracy: 0.5308 - val_loss: 1.0803 - val_accuracy: 0.4231\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.7414 - accuracy: 0.4846 - val_loss: 1.0852 - val_accuracy: 0.4231\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7033 - accuracy: 0.5176 - val_loss: 1.0892 - val_accuracy: 0.4423\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.6110 - accuracy: 0.5230 - val_loss: 1.0938 - val_accuracy: 0.4615\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5255 - accuracy: 0.4502 - val_loss: 1.0976 - val_accuracy: 0.4423\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5441 - accuracy: 0.5188 - val_loss: 1.1020 - val_accuracy: 0.4231\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6307 - accuracy: 0.5244 - val_loss: 1.1061 - val_accuracy: 0.4231\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.6066 - accuracy: 0.5354 - val_loss: 1.1096 - val_accuracy: 0.4231\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.5518 - accuracy: 0.5242 - val_loss: 1.1133 - val_accuracy: 0.4231\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.5399 - accuracy: 0.5446 - val_loss: 1.1168 - val_accuracy: 0.4038\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 1.5024 - accuracy: 0.4635 - val_loss: 1.1193 - val_accuracy: 0.4423\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 1.03; accuracy of 34.62%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 306ms/step - loss: 2.1184 - accuracy: 0.1459 - val_loss: 1.0950 - val_accuracy: 0.3846\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.9800 - accuracy: 0.2370 - val_loss: 1.0592 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.9756 - accuracy: 0.3045 - val_loss: 1.0515 - val_accuracy: 0.4231\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.9288 - accuracy: 0.3562 - val_loss: 1.0557 - val_accuracy: 0.4038\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6383 - accuracy: 0.4442 - val_loss: 1.0631 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.8350 - accuracy: 0.3803 - val_loss: 1.0679 - val_accuracy: 0.3654\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 1.7416 - accuracy: 0.4032 - val_loss: 1.0687 - val_accuracy: 0.3846\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.7268 - accuracy: 0.4182 - val_loss: 1.0725 - val_accuracy: 0.3654\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.7238 - accuracy: 0.4533 - val_loss: 1.0768 - val_accuracy: 0.3654\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6345 - accuracy: 0.4749 - val_loss: 1.0825 - val_accuracy: 0.3654\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.7033 - accuracy: 0.4527 - val_loss: 1.0834 - val_accuracy: 0.3846\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5256 - accuracy: 0.5156 - val_loss: 1.0884 - val_accuracy: 0.4038\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6467 - accuracy: 0.4361 - val_loss: 1.0898 - val_accuracy: 0.4038\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5593 - accuracy: 0.4950 - val_loss: 1.0923 - val_accuracy: 0.3846\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.4913 - accuracy: 0.5436 - val_loss: 1.0943 - val_accuracy: 0.4231\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.6534 - accuracy: 0.4880 - val_loss: 1.0949 - val_accuracy: 0.4231\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6113 - accuracy: 0.5399 - val_loss: 1.0968 - val_accuracy: 0.4231\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.4870 - accuracy: 0.5015 - val_loss: 1.0970 - val_accuracy: 0.4231\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.4761 - accuracy: 0.5335 - val_loss: 1.0970 - val_accuracy: 0.4038\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.4204 - accuracy: 0.5475 - val_loss: 1.0974 - val_accuracy: 0.4231\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5805 - accuracy: 0.5127 - val_loss: 1.0968 - val_accuracy: 0.3846\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5059 - accuracy: 0.5366 - val_loss: 1.0963 - val_accuracy: 0.3846\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.4912 - accuracy: 0.5206 - val_loss: 1.0958 - val_accuracy: 0.4038\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 1.03; accuracy of 38.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.04 - Accuracy: 0.33%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.03 - Accuracy: 0.35%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.03 - Accuracy: 0.38%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.2):\n",
      "> Accuracy: 0.35 (+- 0.02)\n",
      "> Loss: 1.03 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 23/25 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 303ms/step - loss: 2.1081 - accuracy: 0.1277 - val_loss: 1.0469 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.9332 - accuracy: 0.2746 - val_loss: 1.0329 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.7762 - accuracy: 0.3979 - val_loss: 1.0316 - val_accuracy: 0.3654\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.7691 - accuracy: 0.4421 - val_loss: 1.0336 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5511 - accuracy: 0.4333 - val_loss: 1.0323 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7449 - accuracy: 0.4483 - val_loss: 1.0394 - val_accuracy: 0.3846\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.7501 - accuracy: 0.4358 - val_loss: 1.0297 - val_accuracy: 0.3846\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6001 - accuracy: 0.4868 - val_loss: 1.0292 - val_accuracy: 0.3846\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6503 - accuracy: 0.4776 - val_loss: 1.0304 - val_accuracy: 0.3846\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.6130 - accuracy: 0.4846 - val_loss: 1.0205 - val_accuracy: 0.4038\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.5704 - accuracy: 0.5413 - val_loss: 1.0220 - val_accuracy: 0.4038\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4704 - accuracy: 0.5694 - val_loss: 1.0303 - val_accuracy: 0.4038\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5618 - accuracy: 0.5792 - val_loss: 1.0112 - val_accuracy: 0.4231\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.5033 - accuracy: 0.6192 - val_loss: 1.0171 - val_accuracy: 0.4038\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2976 - accuracy: 0.6239 - val_loss: 1.0148 - val_accuracy: 0.4231\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.4325 - accuracy: 0.6280 - val_loss: 1.0136 - val_accuracy: 0.4231\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 1.4170 - accuracy: 0.5817 - val_loss: 0.9990 - val_accuracy: 0.4423\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 1.3398 - accuracy: 0.6538 - val_loss: 1.0054 - val_accuracy: 0.4231\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.3681 - accuracy: 0.6449 - val_loss: 1.0068 - val_accuracy: 0.4231\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.2246 - accuracy: 0.6669 - val_loss: 1.0043 - val_accuracy: 0.4231\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.2663 - accuracy: 0.7078 - val_loss: 0.9984 - val_accuracy: 0.4231\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.2265 - accuracy: 0.7045 - val_loss: 0.9935 - val_accuracy: 0.4038\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.1942 - accuracy: 0.7180 - val_loss: 0.9816 - val_accuracy: 0.4038\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.2078 - accuracy: 0.6737 - val_loss: 0.9775 - val_accuracy: 0.4038\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.1498 - accuracy: 0.7259 - val_loss: 0.9717 - val_accuracy: 0.4038\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1886 - accuracy: 0.7363 - val_loss: 0.9599 - val_accuracy: 0.4615\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.1207 - accuracy: 0.7974 - val_loss: 0.9579 - val_accuracy: 0.4231\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.0899 - accuracy: 0.8116 - val_loss: 0.9482 - val_accuracy: 0.4615\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.1404 - accuracy: 0.8159 - val_loss: 0.9438 - val_accuracy: 0.4615\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1499 - accuracy: 0.7700 - val_loss: 0.9398 - val_accuracy: 0.4808\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.0489 - accuracy: 0.8786 - val_loss: 0.9256 - val_accuracy: 0.5769\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.1623 - accuracy: 0.7680 - val_loss: 0.9153 - val_accuracy: 0.5962\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.9914 - accuracy: 0.8019 - val_loss: 0.9195 - val_accuracy: 0.5769\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.0500 - accuracy: 0.8195 - val_loss: 0.9182 - val_accuracy: 0.5962\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.0228 - accuracy: 0.8364 - val_loss: 0.9122 - val_accuracy: 0.5962\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.0067 - accuracy: 0.8654 - val_loss: 0.9052 - val_accuracy: 0.5962\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9754 - accuracy: 0.8068 - val_loss: 0.9016 - val_accuracy: 0.5962\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9520 - accuracy: 0.8673 - val_loss: 0.8966 - val_accuracy: 0.5962\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9581 - accuracy: 0.8294 - val_loss: 0.8919 - val_accuracy: 0.5962\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.8959 - accuracy: 0.8722 - val_loss: 0.8807 - val_accuracy: 0.6154\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9028 - accuracy: 0.8497 - val_loss: 0.8799 - val_accuracy: 0.6154\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8807 - accuracy: 0.8811 - val_loss: 0.8779 - val_accuracy: 0.6154\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8509 - accuracy: 0.8355 - val_loss: 0.8753 - val_accuracy: 0.6346\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.9502 - accuracy: 0.8411 - val_loss: 0.8690 - val_accuracy: 0.6346\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.8610 - accuracy: 0.8987 - val_loss: 0.8604 - val_accuracy: 0.6346\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.8236 - accuracy: 0.8751 - val_loss: 0.8608 - val_accuracy: 0.6346\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.8067 - accuracy: 0.8564 - val_loss: 0.8617 - val_accuracy: 0.6346\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8485 - accuracy: 0.8575 - val_loss: 0.8548 - val_accuracy: 0.6346\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7435 - accuracy: 0.8933 - val_loss: 0.8540 - val_accuracy: 0.6346\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8130 - accuracy: 0.8637 - val_loss: 0.8489 - val_accuracy: 0.6346\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.8021 - accuracy: 0.9024 - val_loss: 0.8419 - val_accuracy: 0.6346\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.7590 - accuracy: 0.9051 - val_loss: 0.8412 - val_accuracy: 0.6346\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.7962 - accuracy: 0.9045 - val_loss: 0.8332 - val_accuracy: 0.6346\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.7575 - accuracy: 0.8567 - val_loss: 0.8319 - val_accuracy: 0.6346\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.7204 - accuracy: 0.9258 - val_loss: 0.8308 - val_accuracy: 0.6346\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6774 - accuracy: 0.8743 - val_loss: 0.8263 - val_accuracy: 0.6346\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7466 - accuracy: 0.9100 - val_loss: 0.8244 - val_accuracy: 0.6346\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.7281 - accuracy: 0.9132 - val_loss: 0.8248 - val_accuracy: 0.6346\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.6467 - accuracy: 0.9227 - val_loss: 0.8177 - val_accuracy: 0.6346\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6858 - accuracy: 0.9316 - val_loss: 0.8157 - val_accuracy: 0.6346\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6714 - accuracy: 0.9204 - val_loss: 0.8139 - val_accuracy: 0.6538\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6498 - accuracy: 0.9243 - val_loss: 0.8098 - val_accuracy: 0.6538\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6257 - accuracy: 0.8934 - val_loss: 0.8042 - val_accuracy: 0.6538\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6119 - accuracy: 0.9305 - val_loss: 0.8029 - val_accuracy: 0.6538\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5901 - accuracy: 0.9161 - val_loss: 0.8007 - val_accuracy: 0.6538\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.6289 - accuracy: 0.8972 - val_loss: 0.8027 - val_accuracy: 0.6538\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6088 - accuracy: 0.9352 - val_loss: 0.8000 - val_accuracy: 0.6538\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.6280 - accuracy: 0.9238 - val_loss: 0.7967 - val_accuracy: 0.6538\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.6476 - accuracy: 0.9261 - val_loss: 0.7907 - val_accuracy: 0.6538\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5809 - accuracy: 0.9274 - val_loss: 0.7864 - val_accuracy: 0.6538\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5644 - accuracy: 0.9185 - val_loss: 0.7868 - val_accuracy: 0.6538\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.5830 - accuracy: 0.8984 - val_loss: 0.7845 - val_accuracy: 0.6538\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.5483 - accuracy: 0.9358 - val_loss: 0.7843 - val_accuracy: 0.6538\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.5236 - accuracy: 0.9369 - val_loss: 0.7814 - val_accuracy: 0.6538\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.5354 - accuracy: 0.9139 - val_loss: 0.7755 - val_accuracy: 0.6346\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.5479 - accuracy: 0.9443 - val_loss: 0.7731 - val_accuracy: 0.6346\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.5269 - accuracy: 0.9470 - val_loss: 0.7697 - val_accuracy: 0.6346\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.5326 - accuracy: 0.9457 - val_loss: 0.7714 - val_accuracy: 0.6731\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5066 - accuracy: 0.9221 - val_loss: 0.7679 - val_accuracy: 0.6731\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5766 - accuracy: 0.9171 - val_loss: 0.7668 - val_accuracy: 0.6731\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.4796 - accuracy: 0.9343 - val_loss: 0.7644 - val_accuracy: 0.6731\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.4537 - accuracy: 0.9685 - val_loss: 0.7635 - val_accuracy: 0.6731\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4614 - accuracy: 0.9799 - val_loss: 0.7626 - val_accuracy: 0.6923\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4693 - accuracy: 0.9563 - val_loss: 0.7614 - val_accuracy: 0.6923\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.4591 - accuracy: 0.9570 - val_loss: 0.7558 - val_accuracy: 0.6346\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4839 - accuracy: 0.9369 - val_loss: 0.7564 - val_accuracy: 0.6731\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4342 - accuracy: 0.9621 - val_loss: 0.7559 - val_accuracy: 0.6923\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4852 - accuracy: 0.9308 - val_loss: 0.7557 - val_accuracy: 0.6923\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4510 - accuracy: 0.9576 - val_loss: 0.7546 - val_accuracy: 0.6923\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4492 - accuracy: 0.9496 - val_loss: 0.7518 - val_accuracy: 0.6923\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4408 - accuracy: 0.9796 - val_loss: 0.7546 - val_accuracy: 0.6923\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4304 - accuracy: 0.9617 - val_loss: 0.7493 - val_accuracy: 0.6731\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4136 - accuracy: 0.9501 - val_loss: 0.7502 - val_accuracy: 0.6923\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4485 - accuracy: 0.9527 - val_loss: 0.7502 - val_accuracy: 0.6923\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3907 - accuracy: 0.9494 - val_loss: 0.7451 - val_accuracy: 0.6923\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3800 - accuracy: 0.9691 - val_loss: 0.7438 - val_accuracy: 0.6923\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.4119 - accuracy: 0.9374 - val_loss: 0.7419 - val_accuracy: 0.6923\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3897 - accuracy: 0.9564 - val_loss: 0.7442 - val_accuracy: 0.6923\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.3680 - accuracy: 0.9566 - val_loss: 0.7429 - val_accuracy: 0.6923\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4893 - accuracy: 0.9493 - val_loss: 0.7399 - val_accuracy: 0.6923\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.3693 - accuracy: 0.9916 - val_loss: 0.7362 - val_accuracy: 0.6923\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.3819 - accuracy: 0.9534 - val_loss: 0.7379 - val_accuracy: 0.6923\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3770 - accuracy: 0.9324 - val_loss: 0.7369 - val_accuracy: 0.6923\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4100 - accuracy: 0.9718 - val_loss: 0.7367 - val_accuracy: 0.6923\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3727 - accuracy: 0.9751 - val_loss: 0.7322 - val_accuracy: 0.6923\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.3810 - accuracy: 0.9515 - val_loss: 0.7318 - val_accuracy: 0.6923\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.3866 - accuracy: 0.9528 - val_loss: 0.7323 - val_accuracy: 0.6923\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3585 - accuracy: 0.9903 - val_loss: 0.7289 - val_accuracy: 0.6923\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3303 - accuracy: 0.9731 - val_loss: 0.7285 - val_accuracy: 0.6923\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.3214 - accuracy: 0.9765 - val_loss: 0.7277 - val_accuracy: 0.6923\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2997 - accuracy: 0.9818 - val_loss: 0.7281 - val_accuracy: 0.6923\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3457 - accuracy: 0.9698 - val_loss: 0.7269 - val_accuracy: 0.6923\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2855 - accuracy: 0.9867 - val_loss: 0.7268 - val_accuracy: 0.6923\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3252 - accuracy: 0.9839 - val_loss: 0.7234 - val_accuracy: 0.6923\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3194 - accuracy: 0.9846 - val_loss: 0.7209 - val_accuracy: 0.6923\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3259 - accuracy: 0.9800 - val_loss: 0.7232 - val_accuracy: 0.6923\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3033 - accuracy: 0.9693 - val_loss: 0.7221 - val_accuracy: 0.6923\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3172 - accuracy: 0.9681 - val_loss: 0.7205 - val_accuracy: 0.6923\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3067 - accuracy: 0.9763 - val_loss: 0.7191 - val_accuracy: 0.6923\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2991 - accuracy: 0.9728 - val_loss: 0.7192 - val_accuracy: 0.6923\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3024 - accuracy: 0.9534 - val_loss: 0.7188 - val_accuracy: 0.6923\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2865 - accuracy: 0.9786 - val_loss: 0.7188 - val_accuracy: 0.6923\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2689 - accuracy: 0.9723 - val_loss: 0.7190 - val_accuracy: 0.6923\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2955 - accuracy: 0.9799 - val_loss: 0.7190 - val_accuracy: 0.6923\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3098 - accuracy: 0.9922 - val_loss: 0.7182 - val_accuracy: 0.6923\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2727 - accuracy: 0.9853 - val_loss: 0.7181 - val_accuracy: 0.6923\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2816 - accuracy: 0.9760 - val_loss: 0.7181 - val_accuracy: 0.6923\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3133 - accuracy: 0.9861 - val_loss: 0.7148 - val_accuracy: 0.6923\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2501 - accuracy: 0.9957 - val_loss: 0.7154 - val_accuracy: 0.6923\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2380 - accuracy: 0.9964 - val_loss: 0.7141 - val_accuracy: 0.6923\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2670 - accuracy: 0.9879 - val_loss: 0.7152 - val_accuracy: 0.6923\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2693 - accuracy: 0.9662 - val_loss: 0.7161 - val_accuracy: 0.6923\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2932 - accuracy: 0.9602 - val_loss: 0.7137 - val_accuracy: 0.6923\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2577 - accuracy: 0.9842 - val_loss: 0.7146 - val_accuracy: 0.6923\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2504 - accuracy: 0.9915 - val_loss: 0.7129 - val_accuracy: 0.6923\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2569 - accuracy: 0.9895 - val_loss: 0.7122 - val_accuracy: 0.6923\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2549 - accuracy: 0.9900 - val_loss: 0.7145 - val_accuracy: 0.6923\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2265 - accuracy: 0.9935 - val_loss: 0.7132 - val_accuracy: 0.6923\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2253 - accuracy: 0.9913 - val_loss: 0.7138 - val_accuracy: 0.6923\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2353 - accuracy: 0.9845 - val_loss: 0.7136 - val_accuracy: 0.6923\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2118 - accuracy: 0.9836 - val_loss: 0.7125 - val_accuracy: 0.6923\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2665 - accuracy: 0.9891 - val_loss: 0.7115 - val_accuracy: 0.6923\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2204 - accuracy: 0.9903 - val_loss: 0.7119 - val_accuracy: 0.6923\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2565 - accuracy: 0.9826 - val_loss: 0.7109 - val_accuracy: 0.6923\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2392 - accuracy: 0.9687 - val_loss: 0.7113 - val_accuracy: 0.6923\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2722 - accuracy: 0.9845 - val_loss: 0.7107 - val_accuracy: 0.6923\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2216 - accuracy: 0.9932 - val_loss: 0.7100 - val_accuracy: 0.6923\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2434 - accuracy: 0.9798 - val_loss: 0.7099 - val_accuracy: 0.6923\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2083 - accuracy: 0.9907 - val_loss: 0.7098 - val_accuracy: 0.6923\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2291 - accuracy: 0.9717 - val_loss: 0.7103 - val_accuracy: 0.6923\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2336 - accuracy: 0.9795 - val_loss: 0.7101 - val_accuracy: 0.6923\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2206 - accuracy: 0.9967 - val_loss: 0.7093 - val_accuracy: 0.6923\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2128 - accuracy: 0.9909 - val_loss: 0.7107 - val_accuracy: 0.6923\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2293 - accuracy: 0.9792 - val_loss: 0.7097 - val_accuracy: 0.6923\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2193 - accuracy: 0.9946 - val_loss: 0.7101 - val_accuracy: 0.6923\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2308 - accuracy: 0.9819 - val_loss: 0.7096 - val_accuracy: 0.6923\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.2118 - accuracy: 0.9888 - val_loss: 0.7093 - val_accuracy: 0.6923\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2045 - accuracy: 0.9816 - val_loss: 0.7087 - val_accuracy: 0.6923\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2075 - accuracy: 0.9831 - val_loss: 0.7088 - val_accuracy: 0.6923\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1897 - accuracy: 0.9957 - val_loss: 0.7091 - val_accuracy: 0.6923\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2217 - accuracy: 0.9758 - val_loss: 0.7089 - val_accuracy: 0.6923\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1949 - accuracy: 0.9967 - val_loss: 0.7087 - val_accuracy: 0.6923\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2085 - accuracy: 0.9880 - val_loss: 0.7084 - val_accuracy: 0.6923\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2123 - accuracy: 0.9904 - val_loss: 0.7080 - val_accuracy: 0.6923\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1963 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.6923\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2111 - accuracy: 0.9873 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2172 - accuracy: 0.9932 - val_loss: 0.7082 - val_accuracy: 0.6923\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2335 - accuracy: 0.9828 - val_loss: 0.7088 - val_accuracy: 0.6923\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2143 - accuracy: 0.9975 - val_loss: 0.7088 - val_accuracy: 0.6923\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2060 - accuracy: 0.9957 - val_loss: 0.7089 - val_accuracy: 0.6923\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2427 - accuracy: 0.9828 - val_loss: 0.7086 - val_accuracy: 0.6923\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2041 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.6923\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1963 - accuracy: 0.9982 - val_loss: 0.7086 - val_accuracy: 0.6923\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2478 - accuracy: 0.9719 - val_loss: 0.7086 - val_accuracy: 0.6923\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1847 - accuracy: 0.9934 - val_loss: 0.7083 - val_accuracy: 0.6923\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.1947 - accuracy: 0.9774 - val_loss: 0.7082 - val_accuracy: 0.6923\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1751 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.6923\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2013 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.6923\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1979 - accuracy: 0.9982 - val_loss: 0.7081 - val_accuracy: 0.6923\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1998 - accuracy: 0.9949 - val_loss: 0.7080 - val_accuracy: 0.6923\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2328 - accuracy: 0.9946 - val_loss: 0.7081 - val_accuracy: 0.6923\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2102 - accuracy: 0.9932 - val_loss: 0.7079 - val_accuracy: 0.6923\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2074 - accuracy: 0.9932 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.1999 - accuracy: 0.9731 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2080 - accuracy: 0.9760 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1881 - accuracy: 0.9913 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2000 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2145 - accuracy: 0.9913 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1861 - accuracy: 0.9885 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2013 - accuracy: 0.9888 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2030 - accuracy: 0.9774 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1937 - accuracy: 0.9932 - val_loss: 0.7076 - val_accuracy: 0.6923\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2069 - accuracy: 0.9873 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2161 - accuracy: 0.9913 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1942 - accuracy: 0.9946 - val_loss: 0.7080 - val_accuracy: 0.6923\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1936 - accuracy: 0.9946 - val_loss: 0.7080 - val_accuracy: 0.6923\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2086 - accuracy: 0.9940 - val_loss: 0.7080 - val_accuracy: 0.6923\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1814 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.6923\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2038 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.6923\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1996 - accuracy: 0.9975 - val_loss: 0.7080 - val_accuracy: 0.6923\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.7079 - val_accuracy: 0.6923\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1918 - accuracy: 0.9826 - val_loss: 0.7079 - val_accuracy: 0.6923\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2217 - accuracy: 0.9816 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1906 - accuracy: 0.9957 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1982 - accuracy: 0.9949 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2058 - accuracy: 0.9780 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2037 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2028 - accuracy: 0.9913 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2044 - accuracy: 0.9932 - val_loss: 0.7076 - val_accuracy: 0.6923\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2029 - accuracy: 0.9988 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2194 - accuracy: 0.9924 - val_loss: 0.7078 - val_accuracy: 0.6923\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2320 - accuracy: 0.9913 - val_loss: 0.7077 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 305ms/step - loss: 2.1405 - accuracy: 0.1388 - val_loss: 1.0569 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.9621 - accuracy: 0.2353 - val_loss: 1.0380 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.7492 - accuracy: 0.3404 - val_loss: 1.0394 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.6403 - accuracy: 0.4334 - val_loss: 1.0465 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.7464 - accuracy: 0.3730 - val_loss: 1.0571 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.6761 - accuracy: 0.4131 - val_loss: 1.0547 - val_accuracy: 0.4231\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.7135 - accuracy: 0.4292 - val_loss: 1.0565 - val_accuracy: 0.4231\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6572 - accuracy: 0.5409 - val_loss: 1.0460 - val_accuracy: 0.4038\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.4991 - accuracy: 0.5190 - val_loss: 1.0463 - val_accuracy: 0.4231\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.6272 - accuracy: 0.4388 - val_loss: 1.0522 - val_accuracy: 0.4423\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.5286 - accuracy: 0.5267 - val_loss: 1.0515 - val_accuracy: 0.4231\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.3966 - accuracy: 0.5771 - val_loss: 1.0596 - val_accuracy: 0.4231\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4097 - accuracy: 0.5533 - val_loss: 1.0638 - val_accuracy: 0.4231\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 1.4739 - accuracy: 0.4977 - val_loss: 1.0642 - val_accuracy: 0.4231\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.5456 - accuracy: 0.4984 - val_loss: 1.0690 - val_accuracy: 0.4231\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4755 - accuracy: 0.5119 - val_loss: 1.0722 - val_accuracy: 0.4615\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.4265 - accuracy: 0.5549 - val_loss: 1.0772 - val_accuracy: 0.4615\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4328 - accuracy: 0.5719 - val_loss: 1.0815 - val_accuracy: 0.4423\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.5267 - accuracy: 0.5946 - val_loss: 1.0845 - val_accuracy: 0.4231\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4041 - accuracy: 0.5118 - val_loss: 1.0882 - val_accuracy: 0.4231\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 1.3680 - accuracy: 0.6486 - val_loss: 1.0923 - val_accuracy: 0.4231\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.4117 - accuracy: 0.6280 - val_loss: 1.0946 - val_accuracy: 0.4038\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 1.02; accuracy of 36.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 321ms/step - loss: 2.1093 - accuracy: 0.1004 - val_loss: 1.0678 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.8041 - accuracy: 0.2830 - val_loss: 1.0434 - val_accuracy: 0.4231\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.6937 - accuracy: 0.3353 - val_loss: 1.0507 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.7105 - accuracy: 0.4210 - val_loss: 1.0528 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6818 - accuracy: 0.4660 - val_loss: 1.0611 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.7649 - accuracy: 0.4245 - val_loss: 1.0618 - val_accuracy: 0.3846\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.6476 - accuracy: 0.4880 - val_loss: 1.0512 - val_accuracy: 0.4231\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.6012 - accuracy: 0.5216 - val_loss: 1.0564 - val_accuracy: 0.3846\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.5487 - accuracy: 0.5239 - val_loss: 1.0590 - val_accuracy: 0.3846\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5272 - accuracy: 0.5471 - val_loss: 1.0585 - val_accuracy: 0.4231\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.4753 - accuracy: 0.5564 - val_loss: 1.0590 - val_accuracy: 0.4615\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.4870 - accuracy: 0.6714 - val_loss: 1.0633 - val_accuracy: 0.4615\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.4417 - accuracy: 0.5908 - val_loss: 1.0689 - val_accuracy: 0.4423\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.5141 - accuracy: 0.5137 - val_loss: 1.0675 - val_accuracy: 0.4423\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.5678 - accuracy: 0.5617 - val_loss: 1.0714 - val_accuracy: 0.4423\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.5680 - accuracy: 0.5165 - val_loss: 1.0699 - val_accuracy: 0.4423\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.3793 - accuracy: 0.5749 - val_loss: 1.0692 - val_accuracy: 0.4038\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.4820 - accuracy: 0.5447 - val_loss: 1.0698 - val_accuracy: 0.4038\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.4942 - accuracy: 0.5724 - val_loss: 1.0673 - val_accuracy: 0.4038\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4523 - accuracy: 0.5613 - val_loss: 1.0678 - val_accuracy: 0.4231\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.4742 - accuracy: 0.5643 - val_loss: 1.0683 - val_accuracy: 0.4038\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.4619 - accuracy: 0.5000 - val_loss: 1.0678 - val_accuracy: 0.4231\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 1.03; accuracy of 34.62%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.02 - Accuracy: 0.37%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.03 - Accuracy: 0.35%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.5):\n",
      "> Accuracy: 0.46 (+- 0.14)\n",
      "> Loss: 0.94 (+- 0.12)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 24/25 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.8\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 323ms/step - loss: 2.1984 - accuracy: 0.1587 - val_loss: 1.0249 - val_accuracy: 0.4038\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.8663 - accuracy: 0.4101 - val_loss: 1.0097 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.9718 - accuracy: 0.3715 - val_loss: 1.0199 - val_accuracy: 0.3846\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5410 - accuracy: 0.5066 - val_loss: 0.9962 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.7684 - accuracy: 0.5412 - val_loss: 1.0182 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.4157 - accuracy: 0.5253 - val_loss: 0.9760 - val_accuracy: 0.4038\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.3334 - accuracy: 0.5626 - val_loss: 0.9711 - val_accuracy: 0.4038\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.3633 - accuracy: 0.5890 - val_loss: 0.9924 - val_accuracy: 0.4231\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.3342 - accuracy: 0.6288 - val_loss: 0.9578 - val_accuracy: 0.4615\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.2294 - accuracy: 0.7135 - val_loss: 0.9545 - val_accuracy: 0.4615\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.2407 - accuracy: 0.7676 - val_loss: 0.9651 - val_accuracy: 0.4615\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.0285 - accuracy: 0.8303 - val_loss: 0.9133 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.0333 - accuracy: 0.8470 - val_loss: 0.9630 - val_accuracy: 0.4808\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.9939 - accuracy: 0.7570 - val_loss: 0.9172 - val_accuracy: 0.5192\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.0661 - accuracy: 0.8225 - val_loss: 0.9306 - val_accuracy: 0.5000\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.9638 - accuracy: 0.8530 - val_loss: 0.8874 - val_accuracy: 0.5769\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.9476 - accuracy: 0.8767 - val_loss: 0.8829 - val_accuracy: 0.5192\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9356 - accuracy: 0.8801 - val_loss: 0.8742 - val_accuracy: 0.5577\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.8555 - accuracy: 0.8829 - val_loss: 0.8584 - val_accuracy: 0.5577\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.8599 - accuracy: 0.9163 - val_loss: 0.8680 - val_accuracy: 0.5385\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.8055 - accuracy: 0.8671 - val_loss: 0.8473 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7434 - accuracy: 0.9017 - val_loss: 0.8361 - val_accuracy: 0.5769\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.7238 - accuracy: 0.9180 - val_loss: 0.8362 - val_accuracy: 0.5962\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7013 - accuracy: 0.9066 - val_loss: 0.8257 - val_accuracy: 0.6154\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.6610 - accuracy: 0.9247 - val_loss: 0.8318 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6815 - accuracy: 0.8771 - val_loss: 0.8113 - val_accuracy: 0.6154\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6494 - accuracy: 0.9494 - val_loss: 0.8181 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.6182 - accuracy: 0.9478 - val_loss: 0.7951 - val_accuracy: 0.6346\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5800 - accuracy: 0.9373 - val_loss: 0.7874 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5530 - accuracy: 0.9256 - val_loss: 0.7835 - val_accuracy: 0.6538\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5854 - accuracy: 0.9292 - val_loss: 0.7787 - val_accuracy: 0.6538\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5597 - accuracy: 0.9152 - val_loss: 0.7847 - val_accuracy: 0.6731\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5163 - accuracy: 0.9777 - val_loss: 0.7722 - val_accuracy: 0.6731\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5243 - accuracy: 0.9363 - val_loss: 0.7589 - val_accuracy: 0.6538\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4698 - accuracy: 0.9603 - val_loss: 0.7601 - val_accuracy: 0.6731\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4533 - accuracy: 0.9483 - val_loss: 0.7674 - val_accuracy: 0.6538\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4383 - accuracy: 0.9646 - val_loss: 0.7475 - val_accuracy: 0.6538\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4914 - accuracy: 0.9560 - val_loss: 0.7427 - val_accuracy: 0.6538\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4411 - accuracy: 0.9701 - val_loss: 0.7456 - val_accuracy: 0.6923\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4622 - accuracy: 0.9331 - val_loss: 0.7447 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3948 - accuracy: 0.9532 - val_loss: 0.7387 - val_accuracy: 0.6923\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3867 - accuracy: 0.9705 - val_loss: 0.7366 - val_accuracy: 0.6923\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3808 - accuracy: 0.9617 - val_loss: 0.7403 - val_accuracy: 0.6731\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3486 - accuracy: 0.9846 - val_loss: 0.7276 - val_accuracy: 0.6731\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.3453 - accuracy: 0.9806 - val_loss: 0.7239 - val_accuracy: 0.6731\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3268 - accuracy: 0.9830 - val_loss: 0.7230 - val_accuracy: 0.6923\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2952 - accuracy: 0.9864 - val_loss: 0.7332 - val_accuracy: 0.6731\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3415 - accuracy: 0.9661 - val_loss: 0.7321 - val_accuracy: 0.6731\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3321 - accuracy: 0.9717 - val_loss: 0.7222 - val_accuracy: 0.6923\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2834 - accuracy: 0.9914 - val_loss: 0.7164 - val_accuracy: 0.6923\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3108 - accuracy: 0.9806 - val_loss: 0.7247 - val_accuracy: 0.6731\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2975 - accuracy: 0.9733 - val_loss: 0.7329 - val_accuracy: 0.6923\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3174 - accuracy: 0.9867 - val_loss: 0.7108 - val_accuracy: 0.6923\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3368 - accuracy: 0.9518 - val_loss: 0.7160 - val_accuracy: 0.6731\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2619 - accuracy: 0.9676 - val_loss: 0.7140 - val_accuracy: 0.6731\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2385 - accuracy: 0.9901 - val_loss: 0.7123 - val_accuracy: 0.6731\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2639 - accuracy: 0.9932 - val_loss: 0.7125 - val_accuracy: 0.6731\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2427 - accuracy: 0.9899 - val_loss: 0.7251 - val_accuracy: 0.6923\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2249 - accuracy: 0.9798 - val_loss: 0.7196 - val_accuracy: 0.6923\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2288 - accuracy: 0.9740 - val_loss: 0.7137 - val_accuracy: 0.6731\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2235 - accuracy: 0.9913 - val_loss: 0.7102 - val_accuracy: 0.6731\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2329 - accuracy: 0.9913 - val_loss: 0.7092 - val_accuracy: 0.6731\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2043 - accuracy: 0.9964 - val_loss: 0.7111 - val_accuracy: 0.6731\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2072 - accuracy: 0.9914 - val_loss: 0.7099 - val_accuracy: 0.6731\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1894 - accuracy: 0.9942 - val_loss: 0.7095 - val_accuracy: 0.6731\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1915 - accuracy: 0.9982 - val_loss: 0.7145 - val_accuracy: 0.6923\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2057 - accuracy: 0.9932 - val_loss: 0.7115 - val_accuracy: 0.6731\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2159 - accuracy: 0.9967 - val_loss: 0.7098 - val_accuracy: 0.6731\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1965 - accuracy: 0.9914 - val_loss: 0.7099 - val_accuracy: 0.6731\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2087 - accuracy: 0.9828 - val_loss: 0.7101 - val_accuracy: 0.6731\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2092 - accuracy: 0.9946 - val_loss: 0.7102 - val_accuracy: 0.6923\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.2016 - accuracy: 0.9828 - val_loss: 0.7101 - val_accuracy: 0.6731\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1847 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.6923\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2020 - accuracy: 0.9885 - val_loss: 0.7106 - val_accuracy: 0.6731\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.6731\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1814 - accuracy: 0.9982 - val_loss: 0.7104 - val_accuracy: 0.6731\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1849 - accuracy: 0.9895 - val_loss: 0.7112 - val_accuracy: 0.6731\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1885 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.6731\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1815 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.6731\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1836 - accuracy: 0.9932 - val_loss: 0.7104 - val_accuracy: 0.6731\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2001 - accuracy: 0.9946 - val_loss: 0.7105 - val_accuracy: 0.6731\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1949 - accuracy: 0.9932 - val_loss: 0.7102 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 308ms/step - loss: 2.1292 - accuracy: 0.1715 - val_loss: 1.0227 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.7284 - accuracy: 0.4927 - val_loss: 1.0458 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.8100 - accuracy: 0.3901 - val_loss: 1.0376 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.6262 - accuracy: 0.4680 - val_loss: 1.0049 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.6582 - accuracy: 0.5172 - val_loss: 1.0240 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.4841 - accuracy: 0.5994 - val_loss: 0.9951 - val_accuracy: 0.5192\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.3185 - accuracy: 0.6886 - val_loss: 0.9920 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.2745 - accuracy: 0.6056 - val_loss: 1.0001 - val_accuracy: 0.4423\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.2104 - accuracy: 0.6777 - val_loss: 1.0059 - val_accuracy: 0.4808\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1446 - accuracy: 0.7621 - val_loss: 0.9750 - val_accuracy: 0.4423\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.1321 - accuracy: 0.7630 - val_loss: 0.9822 - val_accuracy: 0.4615\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.1818 - accuracy: 0.7652 - val_loss: 0.9836 - val_accuracy: 0.4808\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.9989 - accuracy: 0.8730 - val_loss: 0.9414 - val_accuracy: 0.4423\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.9943 - accuracy: 0.7846 - val_loss: 0.9719 - val_accuracy: 0.4615\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.9349 - accuracy: 0.8629 - val_loss: 0.9578 - val_accuracy: 0.4231\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.0323 - accuracy: 0.8282 - val_loss: 0.9454 - val_accuracy: 0.4615\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.9421 - accuracy: 0.8754 - val_loss: 0.9315 - val_accuracy: 0.4423\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.8801 - accuracy: 0.8571 - val_loss: 0.9469 - val_accuracy: 0.4423\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.7524 - accuracy: 0.8624 - val_loss: 0.9384 - val_accuracy: 0.4423\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.7562 - accuracy: 0.8787 - val_loss: 0.9467 - val_accuracy: 0.4423\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6927 - accuracy: 0.8939 - val_loss: 0.9379 - val_accuracy: 0.4231\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.7648 - accuracy: 0.9019 - val_loss: 0.9382 - val_accuracy: 0.4423\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6703 - accuracy: 0.8816 - val_loss: 0.9098 - val_accuracy: 0.4808\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6722 - accuracy: 0.8970 - val_loss: 0.9136 - val_accuracy: 0.4808\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6633 - accuracy: 0.9095 - val_loss: 0.9193 - val_accuracy: 0.4615\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6288 - accuracy: 0.9033 - val_loss: 0.9150 - val_accuracy: 0.5192\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.6533 - accuracy: 0.8754 - val_loss: 0.9173 - val_accuracy: 0.4808\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5867 - accuracy: 0.9219 - val_loss: 0.9100 - val_accuracy: 0.5000\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6259 - accuracy: 0.9063 - val_loss: 0.9087 - val_accuracy: 0.5000\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6234 - accuracy: 0.9296 - val_loss: 0.9080 - val_accuracy: 0.5000\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.6464 - accuracy: 0.8759 - val_loss: 0.9110 - val_accuracy: 0.5000\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5906 - accuracy: 0.9062 - val_loss: 0.9079 - val_accuracy: 0.5192\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5867 - accuracy: 0.9476 - val_loss: 0.9079 - val_accuracy: 0.5192\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5676 - accuracy: 0.9332 - val_loss: 0.9056 - val_accuracy: 0.5192\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5511 - accuracy: 0.9344 - val_loss: 0.9036 - val_accuracy: 0.5192\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.5540 - accuracy: 0.9376 - val_loss: 0.9036 - val_accuracy: 0.5385\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5666 - accuracy: 0.9307 - val_loss: 0.9050 - val_accuracy: 0.5385\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.5610 - accuracy: 0.9406 - val_loss: 0.9039 - val_accuracy: 0.5385\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5172 - accuracy: 0.9326 - val_loss: 0.9007 - val_accuracy: 0.5385\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4828 - accuracy: 0.9697 - val_loss: 0.9011 - val_accuracy: 0.5385\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6038 - accuracy: 0.9074 - val_loss: 0.9031 - val_accuracy: 0.5385\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.6765 - accuracy: 0.9506 - val_loss: 0.9077 - val_accuracy: 0.5385\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5179 - accuracy: 0.9403 - val_loss: 0.9015 - val_accuracy: 0.5385\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5112 - accuracy: 0.9165 - val_loss: 0.8976 - val_accuracy: 0.5385\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5260 - accuracy: 0.9449 - val_loss: 0.9007 - val_accuracy: 0.5385\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5100 - accuracy: 0.9215 - val_loss: 0.8971 - val_accuracy: 0.5385\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5259 - accuracy: 0.9551 - val_loss: 0.8972 - val_accuracy: 0.5385\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5006 - accuracy: 0.9412 - val_loss: 0.8968 - val_accuracy: 0.5385\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.4906 - accuracy: 0.9310 - val_loss: 0.8959 - val_accuracy: 0.5385\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4801 - accuracy: 0.9476 - val_loss: 0.8963 - val_accuracy: 0.5385\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.5115 - accuracy: 0.9307 - val_loss: 0.8936 - val_accuracy: 0.5385\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4856 - accuracy: 0.9583 - val_loss: 0.8924 - val_accuracy: 0.5385\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4552 - accuracy: 0.9591 - val_loss: 0.8909 - val_accuracy: 0.5385\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4844 - accuracy: 0.9497 - val_loss: 0.8907 - val_accuracy: 0.5385\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4174 - accuracy: 0.9594 - val_loss: 0.8884 - val_accuracy: 0.5385\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4315 - accuracy: 0.9499 - val_loss: 0.8881 - val_accuracy: 0.5385\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4519 - accuracy: 0.9431 - val_loss: 0.8871 - val_accuracy: 0.5192\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4450 - accuracy: 0.9852 - val_loss: 0.8878 - val_accuracy: 0.5192\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.4583 - accuracy: 0.9492 - val_loss: 0.8893 - val_accuracy: 0.5577\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4435 - accuracy: 0.9541 - val_loss: 0.8876 - val_accuracy: 0.5385\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4440 - accuracy: 0.9459 - val_loss: 0.8859 - val_accuracy: 0.5385\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4646 - accuracy: 0.9200 - val_loss: 0.8885 - val_accuracy: 0.5192\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4291 - accuracy: 0.9734 - val_loss: 0.8838 - val_accuracy: 0.5385\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4026 - accuracy: 0.9644 - val_loss: 0.8845 - val_accuracy: 0.5385\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4199 - accuracy: 0.9527 - val_loss: 0.8824 - val_accuracy: 0.5192\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3878 - accuracy: 0.9732 - val_loss: 0.8874 - val_accuracy: 0.5385\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4381 - accuracy: 0.9563 - val_loss: 0.8860 - val_accuracy: 0.5385\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3972 - accuracy: 0.9780 - val_loss: 0.8851 - val_accuracy: 0.5385\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4174 - accuracy: 0.9569 - val_loss: 0.8854 - val_accuracy: 0.5385\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4044 - accuracy: 0.9831 - val_loss: 0.8833 - val_accuracy: 0.5385\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4309 - accuracy: 0.9507 - val_loss: 0.8843 - val_accuracy: 0.5385\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3989 - accuracy: 0.9603 - val_loss: 0.8833 - val_accuracy: 0.5385\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3919 - accuracy: 0.9711 - val_loss: 0.8836 - val_accuracy: 0.5577\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3783 - accuracy: 0.9756 - val_loss: 0.8829 - val_accuracy: 0.5385\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3889 - accuracy: 0.9640 - val_loss: 0.8825 - val_accuracy: 0.5385\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3951 - accuracy: 0.9631 - val_loss: 0.8838 - val_accuracy: 0.5577\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4095 - accuracy: 0.9524 - val_loss: 0.8842 - val_accuracy: 0.5577\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3786 - accuracy: 0.9822 - val_loss: 0.8835 - val_accuracy: 0.5385\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3851 - accuracy: 0.9555 - val_loss: 0.8834 - val_accuracy: 0.5577\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4307 - accuracy: 0.9506 - val_loss: 0.8837 - val_accuracy: 0.5577\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3687 - accuracy: 0.9741 - val_loss: 0.8835 - val_accuracy: 0.5577\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4168 - accuracy: 0.9683 - val_loss: 0.8838 - val_accuracy: 0.5385\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.3739 - accuracy: 0.9670 - val_loss: 0.8839 - val_accuracy: 0.5577\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4025 - accuracy: 0.9278 - val_loss: 0.8840 - val_accuracy: 0.5577\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3685 - accuracy: 0.9669 - val_loss: 0.8835 - val_accuracy: 0.5385\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.81; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 325ms/step - loss: 2.0119 - accuracy: 0.1962 - val_loss: 1.0226 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.7492 - accuracy: 0.4924 - val_loss: 1.0304 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.7275 - accuracy: 0.4884 - val_loss: 1.0321 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 1.6638 - accuracy: 0.4804 - val_loss: 1.0038 - val_accuracy: 0.4038\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.4340 - accuracy: 0.5957 - val_loss: 1.0175 - val_accuracy: 0.4808\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4947 - accuracy: 0.5777 - val_loss: 1.0276 - val_accuracy: 0.4615\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.4590 - accuracy: 0.6076 - val_loss: 0.9895 - val_accuracy: 0.4808\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2869 - accuracy: 0.7403 - val_loss: 0.9888 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2310 - accuracy: 0.7510 - val_loss: 0.9909 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2155 - accuracy: 0.6741 - val_loss: 0.9801 - val_accuracy: 0.5192\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1669 - accuracy: 0.7372 - val_loss: 0.9722 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1222 - accuracy: 0.7852 - val_loss: 0.9591 - val_accuracy: 0.5385\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1396 - accuracy: 0.7508 - val_loss: 0.9536 - val_accuracy: 0.5385\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.9503 - accuracy: 0.8242 - val_loss: 0.9349 - val_accuracy: 0.5577\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.9255 - accuracy: 0.8176 - val_loss: 0.9490 - val_accuracy: 0.5385\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.9452 - accuracy: 0.8344 - val_loss: 0.9515 - val_accuracy: 0.5385\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8534 - accuracy: 0.8286 - val_loss: 0.9080 - val_accuracy: 0.5962\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.8348 - accuracy: 0.8312 - val_loss: 0.9151 - val_accuracy: 0.6154\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.8113 - accuracy: 0.8097 - val_loss: 0.8943 - val_accuracy: 0.5962\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.7760 - accuracy: 0.9083 - val_loss: 0.9014 - val_accuracy: 0.6154\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7444 - accuracy: 0.8715 - val_loss: 0.8851 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.7215 - accuracy: 0.9057 - val_loss: 0.8971 - val_accuracy: 0.5769\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7325 - accuracy: 0.9093 - val_loss: 0.8730 - val_accuracy: 0.5962\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.6445 - accuracy: 0.9429 - val_loss: 0.8609 - val_accuracy: 0.6154\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.6070 - accuracy: 0.9288 - val_loss: 0.8561 - val_accuracy: 0.5962\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.6376 - accuracy: 0.9159 - val_loss: 0.8508 - val_accuracy: 0.6346\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.6217 - accuracy: 0.9118 - val_loss: 0.8376 - val_accuracy: 0.6346\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5183 - accuracy: 0.9726 - val_loss: 0.8369 - val_accuracy: 0.6154\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5178 - accuracy: 0.8926 - val_loss: 0.8262 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.5010 - accuracy: 0.9736 - val_loss: 0.8273 - val_accuracy: 0.5962\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4854 - accuracy: 0.9706 - val_loss: 0.8211 - val_accuracy: 0.6346\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.4775 - accuracy: 0.9473 - val_loss: 0.8150 - val_accuracy: 0.6154\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4194 - accuracy: 0.9785 - val_loss: 0.8190 - val_accuracy: 0.6346\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4363 - accuracy: 0.9559 - val_loss: 0.8106 - val_accuracy: 0.6346\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4032 - accuracy: 0.9698 - val_loss: 0.8125 - val_accuracy: 0.6154\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3846 - accuracy: 0.9895 - val_loss: 0.8102 - val_accuracy: 0.6538\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3837 - accuracy: 0.9762 - val_loss: 0.8051 - val_accuracy: 0.6346\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.3956 - accuracy: 0.9731 - val_loss: 0.8095 - val_accuracy: 0.6346\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.4102 - accuracy: 0.9518 - val_loss: 0.8078 - val_accuracy: 0.6346\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3709 - accuracy: 0.9817 - val_loss: 0.8004 - val_accuracy: 0.6346\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3536 - accuracy: 0.9921 - val_loss: 0.8000 - val_accuracy: 0.6346\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3683 - accuracy: 0.9831 - val_loss: 0.8021 - val_accuracy: 0.6154\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3256 - accuracy: 0.9694 - val_loss: 0.7994 - val_accuracy: 0.6154\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3314 - accuracy: 0.9720 - val_loss: 0.8044 - val_accuracy: 0.6346\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3160 - accuracy: 0.9816 - val_loss: 0.7999 - val_accuracy: 0.6154\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2785 - accuracy: 0.9895 - val_loss: 0.8038 - val_accuracy: 0.6154\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2901 - accuracy: 0.9870 - val_loss: 0.8055 - val_accuracy: 0.6154\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2643 - accuracy: 0.9842 - val_loss: 0.8021 - val_accuracy: 0.6154\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2835 - accuracy: 0.9772 - val_loss: 0.8040 - val_accuracy: 0.6154\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2643 - accuracy: 0.9946 - val_loss: 0.8041 - val_accuracy: 0.6154\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2431 - accuracy: 0.9913 - val_loss: 0.8061 - val_accuracy: 0.6154\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2796 - accuracy: 0.9904 - val_loss: 0.8018 - val_accuracy: 0.6346\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2419 - accuracy: 0.9932 - val_loss: 0.8046 - val_accuracy: 0.6346\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2381 - accuracy: 0.9946 - val_loss: 0.8063 - val_accuracy: 0.6154\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.2588 - accuracy: 0.9935 - val_loss: 0.8057 - val_accuracy: 0.6346\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2566 - accuracy: 0.9881 - val_loss: 0.8062 - val_accuracy: 0.6154\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2522 - accuracy: 0.9907 - val_loss: 0.8062 - val_accuracy: 0.6154\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2526 - accuracy: 0.9828 - val_loss: 0.8050 - val_accuracy: 0.6154\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2239 - accuracy: 0.9886 - val_loss: 0.8056 - val_accuracy: 0.6154\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.8059 - val_accuracy: 0.6154\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2844 - accuracy: 0.9922 - val_loss: 0.8062 - val_accuracy: 0.6154\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2290 - accuracy: 0.9988 - val_loss: 0.8068 - val_accuracy: 0.6154\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2464 - accuracy: 0.9828 - val_loss: 0.8069 - val_accuracy: 0.6154\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.81 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.8):\n",
      "> Accuracy: 0.63 (+- 0.0)\n",
      "> Loss: 0.79 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 25/25 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 302ms/step - loss: 2.0821 - accuracy: 0.1671 - val_loss: 1.0073 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.9809 - accuracy: 0.3622 - val_loss: 1.0517 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.6038 - accuracy: 0.5034 - val_loss: 0.9809 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.4037 - accuracy: 0.5918 - val_loss: 0.9547 - val_accuracy: 0.4808\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.2600 - accuracy: 0.6761 - val_loss: 0.9821 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.2300 - accuracy: 0.7408 - val_loss: 0.9504 - val_accuracy: 0.4038\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.1451 - accuracy: 0.7412 - val_loss: 0.8975 - val_accuracy: 0.5385\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.0696 - accuracy: 0.7931 - val_loss: 0.9252 - val_accuracy: 0.4423\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.9347 - accuracy: 0.8494 - val_loss: 0.8822 - val_accuracy: 0.5577\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.8846 - accuracy: 0.8712 - val_loss: 0.8640 - val_accuracy: 0.5577\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.8264 - accuracy: 0.8493 - val_loss: 0.8779 - val_accuracy: 0.5192\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7639 - accuracy: 0.8977 - val_loss: 0.8307 - val_accuracy: 0.5577\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.7242 - accuracy: 0.8422 - val_loss: 0.8308 - val_accuracy: 0.5577\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7031 - accuracy: 0.8988 - val_loss: 0.8317 - val_accuracy: 0.5769\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6596 - accuracy: 0.8864 - val_loss: 0.7827 - val_accuracy: 0.5769\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5801 - accuracy: 0.9158 - val_loss: 0.7897 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5598 - accuracy: 0.9432 - val_loss: 0.7908 - val_accuracy: 0.6154\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.4900 - accuracy: 0.9489 - val_loss: 0.7498 - val_accuracy: 0.6346\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4938 - accuracy: 0.9256 - val_loss: 0.7724 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4483 - accuracy: 0.9129 - val_loss: 0.7605 - val_accuracy: 0.6538\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4064 - accuracy: 0.9657 - val_loss: 0.7446 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.3771 - accuracy: 0.9729 - val_loss: 0.7331 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4279 - accuracy: 0.9729 - val_loss: 0.7699 - val_accuracy: 0.7115\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3849 - accuracy: 0.9554 - val_loss: 0.7223 - val_accuracy: 0.6923\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3384 - accuracy: 0.9431 - val_loss: 0.7175 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2812 - accuracy: 0.9891 - val_loss: 0.7486 - val_accuracy: 0.7115\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.3043 - accuracy: 0.9562 - val_loss: 0.7293 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2536 - accuracy: 0.9924 - val_loss: 0.7168 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2427 - accuracy: 0.9873 - val_loss: 0.7224 - val_accuracy: 0.6923\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2236 - accuracy: 0.9899 - val_loss: 0.7057 - val_accuracy: 0.7115\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2281 - accuracy: 0.9791 - val_loss: 0.7242 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1951 - accuracy: 0.9977 - val_loss: 0.7146 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2019 - accuracy: 0.9982 - val_loss: 0.7092 - val_accuracy: 0.6731\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1790 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.6538\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1929 - accuracy: 0.9957 - val_loss: 0.7162 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1892 - accuracy: 0.9949 - val_loss: 0.7192 - val_accuracy: 0.7115\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1675 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.7115\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1524 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.7115\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1713 - accuracy: 0.9988 - val_loss: 0.7113 - val_accuracy: 0.6923\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1412 - accuracy: 0.9935 - val_loss: 0.7090 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1488 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.6923\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1446 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.6923\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1504 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.6923\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1362 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.6923\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1331 - accuracy: 1.0000 - val_loss: 0.7116 - val_accuracy: 0.6923\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.6923\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1381 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.6923\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1293 - accuracy: 0.9967 - val_loss: 0.7125 - val_accuracy: 0.6923\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1210 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.6923\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1142 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.6923\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.6731\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.6731\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1350 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.6731\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1475 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.6731\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.6731\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.1376 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.6731\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.6731\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 12s 313ms/step - loss: 2.0856 - accuracy: 0.1460 - val_loss: 1.0173 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 1.7297 - accuracy: 0.4245 - val_loss: 1.0189 - val_accuracy: 0.4808\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.7287 - accuracy: 0.4805 - val_loss: 1.0434 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.4424 - accuracy: 0.5818 - val_loss: 0.9647 - val_accuracy: 0.5192\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.3504 - accuracy: 0.6851 - val_loss: 1.0122 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 1.2221 - accuracy: 0.7174 - val_loss: 0.9630 - val_accuracy: 0.4423\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.0965 - accuracy: 0.7870 - val_loss: 0.9361 - val_accuracy: 0.5192\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.0599 - accuracy: 0.7908 - val_loss: 0.9685 - val_accuracy: 0.4615\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.8884 - accuracy: 0.8263 - val_loss: 0.9234 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.8159 - accuracy: 0.8346 - val_loss: 0.9138 - val_accuracy: 0.4231\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.7326 - accuracy: 0.9362 - val_loss: 0.9016 - val_accuracy: 0.4615\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7302 - accuracy: 0.9055 - val_loss: 0.9061 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.7062 - accuracy: 0.8978 - val_loss: 0.8765 - val_accuracy: 0.5000\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6320 - accuracy: 0.8824 - val_loss: 0.8914 - val_accuracy: 0.4808\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.5476 - accuracy: 0.9481 - val_loss: 0.8685 - val_accuracy: 0.4808\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.5075 - accuracy: 0.9397 - val_loss: 0.8731 - val_accuracy: 0.5385\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.5054 - accuracy: 0.9629 - val_loss: 0.8646 - val_accuracy: 0.5385\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4515 - accuracy: 0.9656 - val_loss: 0.8624 - val_accuracy: 0.5385\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4535 - accuracy: 0.9351 - val_loss: 0.8418 - val_accuracy: 0.5577\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3910 - accuracy: 0.9517 - val_loss: 0.8664 - val_accuracy: 0.5577\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3754 - accuracy: 0.9583 - val_loss: 0.8458 - val_accuracy: 0.5769\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.3432 - accuracy: 0.9521 - val_loss: 0.8405 - val_accuracy: 0.5769\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.3507 - accuracy: 0.9872 - val_loss: 0.8509 - val_accuracy: 0.5962\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.3276 - accuracy: 0.9651 - val_loss: 0.8569 - val_accuracy: 0.5962\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.3060 - accuracy: 0.9842 - val_loss: 0.8545 - val_accuracy: 0.5577\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2658 - accuracy: 0.9975 - val_loss: 0.8697 - val_accuracy: 0.5769\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2575 - accuracy: 0.9957 - val_loss: 0.8657 - val_accuracy: 0.5769\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2197 - accuracy: 0.9921 - val_loss: 0.8753 - val_accuracy: 0.5962\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2446 - accuracy: 0.9805 - val_loss: 0.8778 - val_accuracy: 0.5962\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2667 - accuracy: 0.9795 - val_loss: 0.8664 - val_accuracy: 0.5577\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2822 - accuracy: 0.9670 - val_loss: 0.8744 - val_accuracy: 0.5769\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.2412 - accuracy: 0.9885 - val_loss: 0.8705 - val_accuracy: 0.5769\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2323 - accuracy: 0.9816 - val_loss: 0.8686 - val_accuracy: 0.5385\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2188 - accuracy: 0.9975 - val_loss: 0.8675 - val_accuracy: 0.5385\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2037 - accuracy: 0.9982 - val_loss: 0.8697 - val_accuracy: 0.5385\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1876 - accuracy: 0.9946 - val_loss: 0.8721 - val_accuracy: 0.5385\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2329 - accuracy: 0.9885 - val_loss: 0.8773 - val_accuracy: 0.5577\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2041 - accuracy: 0.9957 - val_loss: 0.8780 - val_accuracy: 0.5577\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2247 - accuracy: 0.9955 - val_loss: 0.8773 - val_accuracy: 0.5769\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1902 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.5577\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.1745 - accuracy: 0.9982 - val_loss: 0.8766 - val_accuracy: 0.5577\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.2083 - accuracy: 0.9975 - val_loss: 0.8779 - val_accuracy: 0.5577\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.78; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 9s 305ms/step - loss: 2.0799 - accuracy: 0.1666 - val_loss: 1.0133 - val_accuracy: 0.4808\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 1.6369 - accuracy: 0.5805 - val_loss: 0.9969 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.9074 - accuracy: 0.4834 - val_loss: 1.0860 - val_accuracy: 0.3462\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 1.5284 - accuracy: 0.4118 - val_loss: 0.9829 - val_accuracy: 0.4808\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.2393 - accuracy: 0.7219 - val_loss: 0.9649 - val_accuracy: 0.4808\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.2162 - accuracy: 0.7228 - val_loss: 0.9942 - val_accuracy: 0.4808\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 1.1469 - accuracy: 0.6853 - val_loss: 0.9559 - val_accuracy: 0.5192\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 1.0203 - accuracy: 0.7506 - val_loss: 0.9193 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.9248 - accuracy: 0.8203 - val_loss: 0.9247 - val_accuracy: 0.5192\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.7956 - accuracy: 0.8998 - val_loss: 0.9093 - val_accuracy: 0.5577\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.7824 - accuracy: 0.8945 - val_loss: 0.8885 - val_accuracy: 0.5577\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.6902 - accuracy: 0.8932 - val_loss: 0.8707 - val_accuracy: 0.5962\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.6551 - accuracy: 0.9325 - val_loss: 0.8786 - val_accuracy: 0.5577\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.6182 - accuracy: 0.9109 - val_loss: 0.8669 - val_accuracy: 0.5769\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.5815 - accuracy: 0.9528 - val_loss: 0.8431 - val_accuracy: 0.5962\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.5635 - accuracy: 0.9577 - val_loss: 0.8455 - val_accuracy: 0.6154\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.4902 - accuracy: 0.9166 - val_loss: 0.8405 - val_accuracy: 0.5962\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4935 - accuracy: 0.9559 - val_loss: 0.8297 - val_accuracy: 0.5962\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4252 - accuracy: 0.9867 - val_loss: 0.8269 - val_accuracy: 0.6346\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4085 - accuracy: 0.9654 - val_loss: 0.8179 - val_accuracy: 0.6346\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3522 - accuracy: 0.9846 - val_loss: 0.8214 - val_accuracy: 0.6154\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3593 - accuracy: 0.9673 - val_loss: 0.8134 - val_accuracy: 0.6346\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.3282 - accuracy: 0.9880 - val_loss: 0.8117 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3233 - accuracy: 0.9673 - val_loss: 0.8145 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2654 - accuracy: 0.9982 - val_loss: 0.8192 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.2771 - accuracy: 0.9769 - val_loss: 0.8106 - val_accuracy: 0.6346\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2471 - accuracy: 0.9852 - val_loss: 0.8152 - val_accuracy: 0.6346\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2360 - accuracy: 0.9933 - val_loss: 0.8129 - val_accuracy: 0.6346\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2379 - accuracy: 1.0000 - val_loss: 0.8179 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2553 - accuracy: 1.0000 - val_loss: 0.8187 - val_accuracy: 0.6154\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.2339 - accuracy: 0.9880 - val_loss: 0.8120 - val_accuracy: 0.6346\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1998 - accuracy: 0.9828 - val_loss: 0.8153 - val_accuracy: 0.6346\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1733 - accuracy: 0.9982 - val_loss: 0.8173 - val_accuracy: 0.6346\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1893 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.6346\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1794 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.6346\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.1842 - accuracy: 0.9957 - val_loss: 0.8196 - val_accuracy: 0.6346\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.1747 - accuracy: 0.9828 - val_loss: 0.8205 - val_accuracy: 0.6154\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1589 - accuracy: 1.0000 - val_loss: 0.8193 - val_accuracy: 0.6154\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.1584 - accuracy: 1.0000 - val_loss: 0.8192 - val_accuracy: 0.6154\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.1650 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.6154\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.8197 - val_accuracy: 0.6154\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1638 - accuracy: 0.9946 - val_loss: 0.8203 - val_accuracy: 0.6154\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.1581 - accuracy: 0.9913 - val_loss: 0.8200 - val_accuracy: 0.6154\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1423 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.6154\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1405 - accuracy: 0.9988 - val_loss: 0.8210 - val_accuracy: 0.6154\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.6154\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.79; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.78 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.79 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.9):\n",
      "> Accuracy: 0.65 (+- 0.02)\n",
      "> Loss: 0.78 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_rate = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "momentum = [0, 0.2, 0.5, 0.8, 0.9]\n",
    "\n",
    "tot_comb = len(learn_rate) * len(momentum)\n",
    "glob_param = np.empty([tot_comb, 2])\n",
    "\n",
    "history_list = []\n",
    "scores_glob_array = np.empty([tot_comb, n_folds, 2])\n",
    "\n",
    "for idx, x in enumerate(itertools.product(learn_rate, momentum)):\n",
    "    learn_rate = x[0]\n",
    "    momentum = x[1]\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for combination {idx + 1}/{tot_comb} ...')\n",
    "    print(f'Learning rate = {learn_rate}')\n",
    "    print(f'Momentum = {momentum}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    history_array = np.array([])\n",
    "    scores_array = np.empty([n_folds, 2])\n",
    "\n",
    "    glob_param[idx, 0] = learn_rate\n",
    "    glob_param[idx, 1] = momentum\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold + 1}/{n_folds} ...')\n",
    "        print('------------------------------------------------------------------------')\n",
    "\n",
    "        # Generate the fold sample for train-test\n",
    "        X_train, Y_train, X_test, Y_test = part_traintest(X_traintest, Y_traintest, rand_seed + fold, frac_test)\n",
    "        \n",
    "        # Define the model architecture\n",
    "        model_1rama = DenseNet_1Rama(vista, input_dim, rand_seed, learn_rate, momentum)\n",
    "        \n",
    "        # Fit data to model\n",
    "        history = model_1rama.fit(X_train, Y_train,\n",
    "                                  batch_size = batch_size,\n",
    "                                  epochs = no_epochs,\n",
    "                                  validation_data = (X_test, Y_test),\n",
    "                                  class_weight = class_weight,\n",
    "                                  verbose = 1,\n",
    "                                  callbacks = [early_stopping, reduce_lr])\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        scores_array[fold, :] = model_1rama.evaluate(X_val, Y_val, verbose = 0)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Score for fold {fold + 1}: {model_1rama.metrics_names[0]} of {round(scores_array[fold, 0], 2)}; {model_1rama.metrics_names[1]} of {round(scores_array[fold, 1]*100, 2)}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('')\n",
    "        \n",
    "        # Append history callback into array\n",
    "        history_array = np.append(history_array, [history])\n",
    "        \n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, scores_array.shape[0]):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i + 1} - Loss: {round(scores_array[i, 0], 2)} - Accuracy: {round(scores_array[i, 1], 2)}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Average scores for all folds (LR = {learn_rate}, mtm = {momentum}):')\n",
    "    print(f'> Accuracy: {round(np.mean(scores_array[:, 1]), 2)} (+- {round(np.std(scores_array[:, 1]), 2)})')\n",
    "    print(f'> Loss: {round(np.mean(scores_array[:, 0]), 2)} (+- {round(np.std(scores_array[:, 0]), 2)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "    idx_best_hist = np.argmax(scores_array[:, 1])\n",
    "    history_list.append(history_array[idx_best_hist])\n",
    "    \n",
    "    scores_glob_array[idx, :, :] = scores_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-drawing",
   "metadata": {
    "id": "super-progressive"
   },
   "source": [
    "## Representación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-library",
   "metadata": {
    "id": "streaming-recruitment"
   },
   "source": [
    "Definimos una serie de funciones auxiliares para facilitar la visualización de resultados (representación de la evolución de las métricas durante el proceso de entrenamiento y resultados de la matriz de confusión finalmente obtenida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "australian-madrid",
   "metadata": {
    "executionInfo": {
     "elapsed": 4556854,
     "status": "ok",
     "timestamp": 1621168815233,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "published-lingerie"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    \"\"\"\n",
    "    Function that plots the metrics from the training process\n",
    "        - history is the output from the training process\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"\n",
    "    Credit to:\n",
    "    https://gist.github.com/zachguo/10296432\n",
    "    \n",
    "    Function that makes a pretty print for confusion matrixes\n",
    "        - cm is the array of histories generated during the training process\n",
    "        - labels is number of epochs fixed for the training process\n",
    "        - hide_zeroes is a boolean that allows the user to hide the zeroes in the matrix\n",
    "        - hide_diagonal is a boolean that allows the user to hide the diagonal in the matrix\n",
    "        - hide_threshold is a number that allows the user to hide results in the matrix below that value\n",
    "    \"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-village",
   "metadata": {
    "id": "Ke1958iX09Uy"
   },
   "source": [
    "Mostramos por pantalla los resultados medios de todas las combinaciones de parámetros y elegimos el modelo que mejores resultados ofrece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "logical-leone",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4556864,
     "status": "ok",
     "timestamp": 1621168815247,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "J9yHfG1O09KQ",
    "outputId": "01f98299-8573-46bf-b8ed-124fc1154f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados promedios del entrenamiento DenseNet-CC:\n",
      "- LR=0.01 / mom=0.0:\tAcc=0.7 (+- 0.04) - Loss=0.77 (+- 0.09)\n",
      "- LR=0.01 / mom=0.2:\tAcc=0.65 (+- 0.07) - Loss=0.82 (+- 0.03)\n",
      "- LR=0.01 / mom=0.5:\tAcc=0.68 (+- 0.09) - Loss=0.82 (+- 0.05)\n",
      "- LR=0.01 / mom=0.8:\tAcc=0.64 (+- 0.07) - Loss=0.95 (+- 0.05)\n",
      "- LR=0.01 / mom=0.9:\tAcc=0.51 (+- 0.07) - Loss=1.32 (+- 0.45)\n",
      "- LR=0.005 / mom=0.0:\tAcc=0.63 (+- 0.04) - Loss=0.76 (+- 0.01)\n",
      "- LR=0.005 / mom=0.2:\tAcc=0.65 (+- 0.02) - Loss=0.79 (+- 0.03)\n",
      "- LR=0.005 / mom=0.5:\tAcc=0.67 (+- 0.02) - Loss=0.76 (+- 0.04)\n",
      "- LR=0.005 / mom=0.8:\tAcc=0.6 (+- 0.1) - Loss=0.85 (+- 0.07)\n",
      "- LR=0.005 / mom=0.9:\tAcc=0.6 (+- 0.03) - Loss=1.31 (+- 0.63)\n",
      "- LR=0.001 / mom=0.0:\tAcc=0.62 (+- 0.02) - Loss=0.8 (+- 0.02)\n",
      "- LR=0.001 / mom=0.2:\tAcc=0.64 (+- 0.03) - Loss=0.79 (+- 0.02)\n",
      "- LR=0.001 / mom=0.5:\tAcc=0.65 (+- 0.02) - Loss=0.78 (+- 0.03)\n",
      "- LR=0.001 / mom=0.8:\tAcc=0.67 (+- 0.01) - Loss=0.76 (+- 0.02)\n",
      "- LR=0.001 / mom=0.9:\tAcc=0.65 (+- 0.0) - Loss=0.79 (+- 0.02)\n",
      "- LR=0.0005 / mom=0.0:\tAcc=0.63 (+- 0.02) - Loss=0.79 (+- 0.01)\n",
      "- LR=0.0005 / mom=0.2:\tAcc=0.65 (+- 0.03) - Loss=0.79 (+- 0.01)\n",
      "- LR=0.0005 / mom=0.5:\tAcc=0.63 (+- 0.02) - Loss=0.79 (+- 0.01)\n",
      "- LR=0.0005 / mom=0.8:\tAcc=0.66 (+- 0.02) - Loss=0.78 (+- 0.01)\n",
      "- LR=0.0005 / mom=0.9:\tAcc=0.65 (+- 0.01) - Loss=0.77 (+- 0.01)\n",
      "- LR=0.0001 / mom=0.0:\tAcc=0.38 (+- 0.02) - Loss=1.04 (+- 0.0)\n",
      "- LR=0.0001 / mom=0.2:\tAcc=0.35 (+- 0.02) - Loss=1.03 (+- 0.0)\n",
      "- LR=0.0001 / mom=0.5:\tAcc=0.46 (+- 0.14) - Loss=0.94 (+- 0.12)\n",
      "- LR=0.0001 / mom=0.8:\tAcc=0.63 (+- 0.0) - Loss=0.79 (+- 0.02)\n",
      "- LR=0.0001 / mom=0.9:\tAcc=0.65 (+- 0.02) - Loss=0.78 (+- 0.01)\n",
      "\n",
      "El mejor resultado para la DenseNet-CC se obtiene para LR = 0.01 y momentum = 0.0.\n"
     ]
    }
   ],
   "source": [
    "print(f'Resultados promedios del entrenamiento DenseNet-{vista}:')\n",
    "for i in range(len(glob_param)):\n",
    "    print(f'- LR={glob_param[i, 0]} / mom={glob_param[i, 1]}:\\tAcc={round(np.mean(scores_glob_array[i, :, 1]), 2)} (+- {round(np.std(scores_glob_array[i, :, 1]), 2)}) - Loss={round(np.mean(scores_glob_array[i, :, 0]), 2)} (+- {round(np.std(scores_glob_array[i, :, 0]), 2)})')\n",
    "\n",
    "idx_best = np.argmax(np.mean(scores_glob_array, 1)[:, 1])\n",
    "history_best = history_list[idx_best]\n",
    "model_best = history_best.model\n",
    "print(f'\\nEl mejor resultado para la DenseNet-{vista} se obtiene para LR = {glob_param[idx_best, 0]} y momentum = {glob_param[idx_best, 1]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-marsh",
   "metadata": {
    "executionInfo": {
     "elapsed": 2276,
     "status": "ok",
     "timestamp": 1620075964551,
     "user": {
      "displayName": "Duun V",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GipsnLzW9bWFJbKNrxY-F-xi7XKh0HhowJGi0hF9A=s64",
      "userId": "10921869077997462696"
     },
     "user_tz": -120
    },
    "id": "marked-decimal"
   },
   "source": [
    "Visualizamos la evolución de las métricas durante el proceso de entrenamiento de la red con mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elder-reception",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 4557345,
     "status": "ok",
     "timestamp": 1621168815734,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "racial-tribute",
    "outputId": "48532542-a4c8-4638-9fd0-9b9d8e85d47f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-advocacy",
   "metadata": {
    "id": "t_0z4ogBWHxS"
   },
   "source": [
    "Mostramos la matriz de confusión de la última iteración por pantalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "balanced-integrity",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4559008,
     "status": "ok",
     "timestamp": 1621168817405,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "relevant-technique",
    "outputId": "38abde2e-f807-4cad-94a2-c9a0bc34fbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            benigno seguimiento  maligno \n",
      "    benigno    24.0         1.0      3.0 \n",
      "seguimiento     3.0         0.0      1.0 \n",
      "    maligno     5.0         0.0     15.0 \n"
     ]
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1))\n",
    "print_cm(conf_matrix, list(dict_valores.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-symphony",
   "metadata": {
    "id": "viral-constitutional"
   },
   "source": [
    "Mostramos las métricas de resultados según categoría para poder evaluar el desempeño de la red en cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "capable-farmer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4559257,
     "status": "ok",
     "timestamp": 1621168817659,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "gross-aaron",
    "outputId": "ad6f00d1-ae0d-4b48-ebac-3d84a1b9b281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.75      0.86      0.80        28\n",
      " seguimiento       0.00      0.00      0.00         4\n",
      "     maligno       0.79      0.75      0.77        20\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.51      0.54      0.52        52\n",
      "weighted avg       0.71      0.75      0.73        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif_report = metrics.classification_report(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1),\n",
    "                                               target_names = list(dict_valores.keys()))\n",
    "print(classif_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-cross",
   "metadata": {
    "id": "heavy-company"
   },
   "source": [
    "Guardamos el modelo entrenado para su uso en pasos posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "closing-constant",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4611469,
     "status": "ok",
     "timestamp": 1621168869876,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "foreign-teens",
    "outputId": "735c6cb9-5630-44af-dc05-33271832b253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Colab Notebooks/model_best_CC/assets\n"
     ]
    }
   ],
   "source": [
    "if google_colab:\n",
    "    file_path = '/content/gdrive/MyDrive/Colab Notebooks/' + 'model_best_' + vista\n",
    "else:\n",
    "    file_path = './model_best_' + vista\n",
    "K.models.save_model(model_best, file_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Optimización_DenseNet_1Rama.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
